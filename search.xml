<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>DETR</title>
    <url>/2022/03/04/DETR/</url>
    <content><![CDATA[<p>论文：[<a href="https://arxiv.org/abs/2010.04159">2010.04159] Deformable DETR: Deformable Transformers for End-to-End Object Detection (arxiv.org)</a></p>
<span id="more"></span>
<h1 id="前人的工作"><a href="#前人的工作" class="headerlink" title="前人的工作"></a>前人的工作</h1><h2 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h2><p>注意力机制可以理解为，计算机视觉系统在模拟人类视觉系统中可以迅速高效地关注到重点区域的特性。<br>$$<br>Attention&#x3D;f(g(x),x)<br>$$<br>g(x)表示对输入特征进行处理并产生注意力的过程，f(g(x),x)表示结合注意力对输入特征进行处理的过程</p>
<p>self-attention模型：<br>$$<br>Q,K,V&#x3D;Linear(x)\<br>g(x)&#x3D;Softmax(QK)\<br>f(g(x),x)&#x3D;g(x)V<br>$$<br>senet模型:<br>$$<br>g(x)&#x3D;Sigmoid(MLP(GAP(x)))\<br>f(g(x),x)&#x3D;g(x)x<br>$$</p>
<p>注意力又可以细分为：通道注意力、空间注意力、时间注意力、分支注意力以及两种组合注意力：通道-空间注意力、空间-时间注意力</p>
<p><strong>通道注意力：</strong>将输入的特征图，经过<strong>基于宽度与高度</strong>的global max pooling 和global average pooling，然后分别经过MLP。将MLP输出的特征进行基于element-wise的加和操作，再经过sigmoid激活操作，生成最终的channel attention featuremap。将该channel attention featuremap和input featuremap做element-wise乘法操作，生成Spatial attention模块需要的输入特征。</p>
<p><strong>空间注意力：</strong>将Channel attention模块输出的特征图作为本模块的输入特征图。首先做一个<strong>基于channel</strong>的global max pooling 和global average pooling，然后将这2个结果基于channel 做concat操作。然后经过一个卷积操作，降维为1个channel。再经过sigmoid生成spatial attention feature。最后将该feature和该模块的输入feature做乘法，得到最终生成的特征。</p>
<p>Transformers网络包含self-attention和cross-attention机制，其主要的问题是时间开销、内存开销过高。现有许多思路来解决这个问题</p>
<ol>
<li>使用预定义的稀疏注意力模式，最直接的范式就是将注意力模式限制到固定的局部窗口。而这种方法会丧失全局信息。为了补偿对全局信息的提取，可以增加关键元素的接受域，或是允许少量特殊令牌访问所有关键元素，或是添加一些预定义的稀疏注意模式，直接注意远处的关键元素</li>
<li>学习数据依赖的稀疏注意力，基于注意力的局部敏感数据哈希算法，将查询和关键元素散列到不同的容器中，或是使用k-means找到最相关的关键元素，或是学习block-wise稀疏注意力的block排序</li>
<li>探索自我注意力的低秩性质，通过尺寸维度而不是通道维度的线性投影来减少关键元素数量，或是通过内核化近似重新计算自注意力</li>
</ol>
<p>本篇论文使用的可变性注意力是受可变性卷积启发，属于第二类，只关注从查询元素的特征中预测一个小的固定采样点集合。在相同FLOPS下，变形注意力要比传统卷积略慢。</p>
<h2 id="目标检测的多尺度特征表示"><a href="#目标检测的多尺度特征表示" class="headerlink" title="目标检测的多尺度特征表示"></a>目标检测的多尺度特征表示</h2><p>在目标检测任务中，一张图像内真实对象的尺寸差别巨大，这也成为目标检测的一大困难。现代物体检测器通常利用多尺度特征来解决。FPN提出一个自顶向下路径融合多尺度特征；PANet进一步添加一条自底向上的路径到FPN顶部；或是结合通过一个全局注意力操作提取出的从所有尺寸中的特则；或是使用U型模型来融合多尺度特征。最近，NAS-FPN、Auto-FPN提出通过神经网络搜索自动设计交叉注意力联系；BiFPN是PANet的重复简化版本</p>
<p>本篇论文使用多尺度可变性的注意力模块可以通过注意力机制自然的将多尺度特征累加起来，无需借助特征金字塔网络</p>
<h2 id="Transformers中的多头检测"><a href="#Transformers中的多头检测" class="headerlink" title="Transformers中的多头检测"></a>Transformers中的多头检测</h2><p>Transformers是基于机器翻译的注意力机制的网络架构。为了使模型能够关注不同表示子空间和不同位置的内容，将不同注意力头的输出以可学习的权值线性聚合。</p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>DETR基于Transformer encoder-decoder框架，合并了set-based 匈牙利算法，通过二分图匹配，强制每一个ground-truth box都有唯一的预测结果（通过该算法找优化方向，哪个ground-truth由哪个slot负责）</p>
<h2 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h2><ol>
<li>DETR训练周期长，到达收敛状态的时间长，初始化时，图上各个位置的权重相同，而在训练结束时，权重只集中在图像中出现物体的位置，这里权重的更新似乎需要经过很多轮训练才能达到收敛</li>
<li>对小目标物体检测不友好，DETR使用多尺度特征处理小目标，而高分辨率的特征图会大大提高DETR复杂度</li>
</ol>
<h2 id="关键过程"><a href="#关键过程" class="headerlink" title="关键过程"></a>关键过程</h2><ol>
<li>通过CNN骨干网络将输入特征提取出来。DETR利用标准的Transformer编码器-解码器体系结构将输入特征映射转换为一组对象查询的特征。在目标查询特征(由解码器产生)上添加一个三层前馈神经网络(FFN)和一个线性投影作为检测头。</li>
<li>对于DETR的编码器，查询和关键元素都是特征图中的像素。编码器输入是ReaNet特征图，自注意的计算复杂度为O(h^2w^2c)，随空间大小呈二次型增长。</li>
<li>对于DETR解码器，输入包括编码器中的特征图和N个由可学习位置嵌入表示的对象查询。解码器中存在两类注意模块，即<strong>交叉注意模块</strong>和<strong>自我注意模块</strong>。在交叉注意模块中，对象查询从特征映射中提取特征。查询元素是对象查询的元素，关键元素是编码器的输出特征映射的元素。复杂度随特征映射的空间大小呈线性增长。在自注意模块中，对象查询相互交互，以捕获它们之间的关系。查询和关键元素都是对象查询。因此，对于适度数量的对象查询，复杂性是可以接受的。</li>
</ol>
<h1 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h1><p><img src="/%5Cimages%5Cimage-20220119220603117.png" alt="image-20220119220603117"></p>
<h2 id="端到端适用于目标检测的可变性transformers模型"><a href="#端到端适用于目标检测的可变性transformers模型" class="headerlink" title="端到端适用于目标检测的可变性transformers模型"></a>端到端适用于目标检测的可变性transformers模型</h2><p>模型使用ResNet-50作预训练</p>
<h2 id="可变性注意力模块"><a href="#可变性注意力模块" class="headerlink" title="可变性注意力模块"></a>可变性注意力模块</h2><p>不同于传统注意力模块注意图像中的所有位置，可变性注意力模块只关注参考点周围一小组关键采样点，无需考虑特征图的空间大小，即为每个查询只分配少量固定数量的关键点。<br>$$<br>DeformAttn(z_q,p_q,x)&#x3D;\sum^M_{m&#x3D;1}W_m[\sum^K_{k&#x3D;1}A_{mqk}\times W^{‘}<em>mx(p_q+\Delta p</em>{mqk})],<br>$$<br>输入特征是C×H×W维的；q表示具有Zq个上下文特征、二维参考点Pq的查询元素；m表示注意力头；k表示采样的关键点的索引，K为采样关键点的总数，Δp和A分别为检测头的采样偏移量和权重</p>
<h2 id="多尺度可变性注意力模块"><a href="#多尺度可变性注意力模块" class="headerlink" title="多尺度可变性注意力模块"></a>多尺度可变性注意力模块</h2><p>$$<br>MSDeformAttn(z_q,\hat{p_q},{x^l}^L_{l&#x3D;1})&#x3D;\sum^M_{m&#x3D;1}W_m[\sum^L_{l&#x3D;1}\sum^K_{k&#x3D;1}A_{mlqk}\times W^{‘}<em>m x^l (\phi_l(\hat{p_q})+\Delta p</em>{mlqk})],<br>$$</p>
<p>x是多尺度特征输入图，l是输入特征的等级，k为采样点。多尺度变形注意与之前的单尺度版本非常相似，不同的是它从多尺度特征映射中采样LK点，而不是从单尺度特征映射中采样K点。Φ将归一化坐标重新转换为第l层的特征图。</p>
<p>可变形卷积是为单尺度输入而设计的，每个注意力头只关注一个采样点。然而，多尺度变形注意从多尺度输入中查看多个采样点。所提出的(多尺度)可变形注意模块也可以被视为Transformer注意的有效变体，其中可变形采样位置引入了<strong>预滤波机制</strong>（预先过滤不重要的点，降低计算复杂度）。当采样点遍历所有可能的位置时，所提出的注意模块相当于Transformer注意。</p>
<h2 id="可变性transformer编码器"><a href="#可变性transformer编码器" class="headerlink" title="可变性transformer编码器"></a>可变性transformer编码器</h2><p>我们用提出的多尺度可变形注意模块替换DETR中的Transformer注意模块处理特征映射。该编码器的输入和输出都是具有相同分辨率的多尺度特征图。关键元素和查询元素都是多尺度特征图中的像素。对于每个查询像素，参考点就是它本身。为了确定每个查询像素所处的特征级别，除了位置嵌入之外，我们还在特征表示中添加了尺度级嵌入(记作el)。与固定编码的位置嵌入不同，尺度级嵌入{el}Ll&#x3D;1是随机初始化并与网络联合训练的。可变形变压器编码器的参数在不同的特征层之间共享。</p>
<h2 id="可变性transformer解码器"><a href="#可变性transformer解码器" class="headerlink" title="可变性transformer解码器"></a>可变性transformer解码器</h2><p>解码器中存在交叉注意模块和自注意模块。两种类型的注意模块的查询元素都是对象查询。在交叉注意模块中，对象查询从特征映射中提取特征，其中关键元素是编码器的输出特征映射。在自注意模块中，对象查询相互交互，其中的关键元素是对象查询。（这里和DETR网络相似）由于提出的变形注意模块是为处理卷积特征映射作为关键元素而设计的，所以只将每个交叉注意模块替换为多尺度变形注意模块，而保持自我注意模块不变。</p>
<p>由于多尺度可变形注意模块提取参考点周围的图像特征，通过让检测头相对于参考点的偏移量预测边界盒，可以进一步降低优化难度。</p>
<p>通过将DETR中的Transformer注意模块替换为可变形注意模块，建立了一个高效、快速收敛的检测系统，称为可变形DETR</p>
<h2 id="迭代边界框优化"><a href="#迭代边界框优化" class="headerlink" title="迭代边界框优化"></a>迭代边界框优化</h2><p>为了提高检测性能，作者建立了一种简单有效的迭代边界盒优化机制。这里，每个解码器层都根据前一层的预测来细化边界框。</p>
<h2 id="两阶段可变性DETR"><a href="#两阶段可变性DETR" class="headerlink" title="两阶段可变性DETR"></a>两阶段可变性DETR</h2><p>在原始DETR中，解码器中的对象查询与当前图像无关。作者使用两阶段目标检测思想，第一阶段使用可变性DETR生成区域建议，生成的区域建议将作为对象查询提供给解码器以进一步细化，形成一个两阶段的可变形DETR。</p>
<p>在第一阶段，为了实现高召回建议，多尺度特征图中的每个像素都将作为对象查询。然而，直接将对象查询设置为像素会给解码器中的自注意模块带来不可接受的计算和内存开销。为了避免这个问题，去掉了解码器，并形成了一个只有编码器的可变形DETR来生成区域建议。即每个像素被赋值为一个对象查询，直接预测一个边界框。得分最高的边界框被选为区域建议。在将区域建议提交到第二阶段之前，不应用NMS。</p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p><img src="/%5Cimages%5Cimage-20220120132237764.png" alt="image-20220120132237764"></p>
]]></content>
      <tags>
        <tag>deep learning</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>Fast-RCNN</title>
    <url>/2022/02/25/Fast-RCNN/</url>
    <content><![CDATA[<p>论文：<a href="https://openaccess.thecvf.com/content_iccv_2015/html/Girshick_Fast_R-CNN_ICCV_2015_paper.html">ICCV 2015 Open Access Repository (thecvf.com)</a></p>
<span id="more"></span>

<img src="\images\image-20220105165859553.png" alt="image-20220105165859553" style="zoom:150%;" />



<h1 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h1><p>Fast-RCNN是将RCNN与SPPNet相融合提出的一种新的网络。</p>
<h2 id="RoI层"><a href="#RoI层" class="headerlink" title="RoI层"></a>RoI层</h2><p><img src="/%5Cimages%5Cimage-20220105171915109.png" alt="image-20220105171915109"></p>
<p>Fast-RCNN设计了一个RoI层用来对<strong>整张图像</strong>进行特征提取，再根据候选区域在原图中的位置挑选特征。</p>
<p>SPPNet提出了Spatial pyramid pooling技术可以将一张图像中卷积所得<strong>的不同尺寸的ROI映射为固定范围</strong>（H×W）的特征图，其中H、W是超参数。每个RoI都是由一个矩形窗口转化为一个卷积特征图。RoI有一个四元组（r,c,h,w）定义（r，c指定左上角坐标；h、w定义其高度和宽度）。</p>
<p><em>RoI max pooling工作原理：将h×w的RoI窗口分割为一个H×W网格，每个网格窗口大小为(h&#x2F;H)×(w&#x2F;W),每个子窗口值最大池化到相应的输出网格单元中。</em></p>
<h2 id="预训练网络"><a href="#预训练网络" class="headerlink" title="预训练网络"></a>预训练网络</h2><p>预训练网络转换为Fast-RCNN网络经过三个转变</p>
<ol>
<li>最后被最大的池化层被RoI层替代，通过设置H、W与网络的第一个全连接层兼容</li>
<li>网络最后的全连接层和softmax被一个全连接层超过K+1类别的softmax和一个特定类别的限定框回归器所代替</li>
<li>该网络接受两个数据输入：一个图像列表和这些图像中的RoI列表</li>
</ol>
<h2 id="微调检测"><a href="#微调检测" class="headerlink" title="微调检测"></a>微调检测</h2><p>在Fast-RCNN网络中，反向传播训练参数是一项重要的功能。（它客服了SPPNet不能更新空间金字塔层以下权值的问题）。由于SPPNet网络的每个训练样本（RoI）来自不同的图像时，SPP层的反向传播是非常低效的。</p>
<p>作者提出了一种更加有效的训练方法，利用了训练过程中的特征共享。即对随机梯度下降进行小批量的分级采样。首先对N幅图像进行采样，然后对每幅图像进行R&#x2F;N个RoI采样。重要的是，对于来自相同图像的RoI在向前和向后传递时共享计算和内存。不过这种训练方法存在训练收敛较慢的问题。（N&#x3D;2，R&#x3D;128时效果最好）</p>
<p>同时，在分层采样中，作者的一个精细调整阶段联合优化softmax分类器和边界框回归器，而不是用三个独立的阶段寻训练softmax分类器、支持向量机、回归器。</p>
<h2 id="多任务损失"><a href="#多任务损失" class="headerlink" title="多任务损失"></a>多任务损失</h2><p>$$<br>L(p,u,t^u,v)&#x3D;L_{cls}(p,u)+\lambda[u\ge 1]L_{loc}(t^u,v)<br>$$</p>
<h2 id="最小批次采样"><a href="#最小批次采样" class="headerlink" title="最小批次采样"></a>最小批次采样</h2><p>实验中，作者使用最小batch为128，对每张图像采样64个RoI。接着从这些proposals中获取区IoU大于等于的0.5的RoI(这些RoI中包含对象标记，u大于等于1)，剩余的RoI从IoU处于[0.1~0.5]的RoI中选取。再将IoU小于0.1的当作背景例子，标记u&#x3D;0.</p>
<p>这里也可以将IoU小于0.1的样本作为hard样本进行训练；训练过程中，图像以0.5的概率翻转，除此没有别的数据增强。</p>
<h2 id="通过RoI池层的反向传播"><a href="#通过RoI池层的反向传播" class="headerlink" title="通过RoI池层的反向传播"></a>通过RoI池层的反向传播</h2><h2 id="SGD超参数"><a href="#SGD超参数" class="headerlink" title="SGD超参数"></a>SGD超参数</h2><p>用于softmax分类和边界框回归的全连接层使用标准偏差为0.01和0.001的零均值高斯分布初始化zero-mean Gaussian distributions。所有层的加权学习率为1，偏差学习率为2，整体学习率为0.001</p>
<h2 id="尺度不变性"><a href="#尺度不变性" class="headerlink" title="尺度不变性"></a>尺度不变性</h2><p>作者探索了两种不同的尺度不变目标检测的实现，一是暴力计算，二是使用图像金字塔</p>
<ol>
<li>暴力计算：在训练和测试中，每幅图像都按照预先定义的像素大小进行处理</li>
<li>图像金字塔：在测试过程中，使用图像金字塔对每个目标建议进行近似尺度归一化，作为数据增强的一种。</li>
</ol>
<p><img src="/%5Cimages%5Cimage-20220106111519294.png" alt="image-20220106111519294"></p>
<p>作者通过实验发现，卷积网络擅长直接学习尺度不变，并且多尺度方法耗费了大量的时间成本只将mAP提升了很小一部分</p>
<h2 id="目标检测过程"><a href="#目标检测过程" class="headerlink" title="目标检测过程"></a>目标检测过程</h2><p>Fast-RCNN网络一旦完成微调，检测过程相当于运行一个前向传递（假设proposal已经提提前算好）。网络将一个图像和一个R对象列表（通常为2k左右）作为输入进行评分。当使用图像金字塔后，每个RoI接近224×224个像素</p>
<p>对于每个RoI r，前向传递输出一个类别的后验概率分布p与一组相对于r 的预测边界框位置偏移。然后使用RCNN算法对每个类单独执行非极大值抑制。</p>
<h2 id="截断SVD"><a href="#截断SVD" class="headerlink" title="截断SVD"></a><strong>截断SVD</strong></h2><p>对于整张图像的分类，全连接层的计算时间要比卷积层处理的时间更少。但是，对于检测来说，由于需要处理的RoI数量很大，几乎一半的前向传递时间都花费在计算全连接层上。因此，作者使用truncated SVD技术来加速全连接层的计算。truncated SVD可以减少30%的探测时间，而只减少0.3%的mAP，并且无需在模型压缩后执行额外的微调。在深层的网络中，对RoI池化层的训练是非常有必要的。</p>
<p>同时，作者提到在深度较浅的网络中，conv1是处理一般性的与任务独立的。因此对conv1训练的意义不大。对卷积层的更新会增加训练时间，并且导致GPU内存溢出的问题，而带来的mAP提升很少。</p>
<p><img src="/%5Cimages%5Cimage-20220106100757776.png" alt="image-20220106100757776"></p>
<p>SVD原理可参考<a href="https://www.cnblogs.com/pinard/p/6251584.html">奇异值分解(SVD)原理与在降维中的应用 - 刘建平Pinard - 博客园 (cnblogs.com)</a></p>
<h2 id="更多的训练数据有利于提升mAP"><a href="#更多的训练数据有利于提升mAP" class="headerlink" title="更多的训练数据有利于提升mAP"></a>更多的训练数据有利于提升mAP</h2><p>作者将VOC07加入VOC12后，mAP由66.9%提升到70.0%。</p>
<p>作者构建了有VOC07的训练集与测试集与VOC12的训练集组成的图像数据集，发现mAP也得到了提升。</p>
<h2 id="softmax相比于SVM的优势"><a href="#softmax相比于SVM的优势" class="headerlink" title="softmax相比于SVM的优势"></a><strong>softmax相比于SVM的优势</strong></h2><p><img src="/%5Cimages%5Cimage-20220106112058344.png" alt="image-20220106112058344"></p>
<p>实验表明softmax在S、L、M三种网络中性能均优于SVM。尽管性能提升不大，但是“one-shot”微调已经足够了。不同于一对一的SVM，softmax在评估RoI时还引入了类别间的竞争。</p>
<h2 id="proposals数量对结果的影响"><a href="#proposals数量对结果的影响" class="headerlink" title="proposals数量对结果的影响"></a><strong>proposals数量对结果的影响</strong></h2><p><img src="/%5Cimages%5Cimage-20220205113749198.png" alt="image-20220205113749198"></p>
<p>作者使用了两种目标检测方法。一是稀疏集proposal（如selective search ）；二是稠密集proposal（如DPM）。</p>
<p>对稀疏peoposal进行分类是一种级联，会先拒绝大量候选区域，只留一小部分给分类器评估。而应用DPM检测时，级联提高了检测精度。</p>
<p>实验表明，随着proposal数量增加，mAP会先上升再下降。所以过多的proposal对分类器并没有帮助。</p>
<p>作者在文章中还介绍了一种测量对象proposal质量的技术：平均召回AR。当每幅图像使用固定数量的proposal时AR与mAP有良好的相关性。但是在图像proposal数量不同时，由于更多proposal而提高的AR，并不意味着mAP会提高。但是在M网络中训练与测试只需要2.5小时，这使得fast-rcnn能够高效、直接评估对象proposal的mAP。</p>
<h1 id="做出的贡献"><a href="#做出的贡献" class="headerlink" title="做出的贡献"></a>做出的贡献</h1><ol>
<li>比RCNN与SPPNet更高的探测质量mAP</li>
<li>训练是单阶段的，使用了multi-task loss</li>
<li>训练时可以对网络中的所有层都进行更新</li>
<li>特征缓存时不需要磁盘空间，Fast-RCNN网络将特征提取器、分类器、回归器合并，使得训练过程不需要再将每阶段结果保存磁盘单独训练，可以一次性完成训练，加快了训练速度</li>
</ol>
]]></content>
      <tags>
        <tag>deep learning</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>Faster-RCNN</title>
    <url>/2022/03/04/Faster-RCNN/</url>
    <content><![CDATA[<p><strong>论文：</strong><a href="https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (neurips.cc)</a></p>
<span id="more"></span>
<h1 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h1><img src="\images\image-20220206101136285.png" alt="image-20220206101136285" style="zoom:75%;" />

<p>目前，先进的目标检测算法都是依赖于区域建议算法去假设物体位置的，区域建议的计算成为目标检测算法的瓶颈。而Faster-RCNN引入了<strong>区域建议网络RPN</strong>，该网络与检测网络共享全图像卷积特征，从而实现<strong>几乎无成本的区域建议</strong>。引入RPN网络也使得Faster-RCNN成为了一个完全的end-to-end的CNN目标检测模型。</p>
<h2 id="区域生成网络RPN"><a href="#区域生成网络RPN" class="headerlink" title="区域生成网络RPN"></a>区域生成网络RPN</h2><p>RPN网络代替了Fast-RCNN模型中的selective search（SS）。它先通过对应关系把特征图的点映射回原图，在每个对应的原图设计不同的固定尺度窗口bbox，根据该窗口的ground truth的IoU给它标记正负标签，让它学习里面是否有目标。通过一个简单的交替优化，RPN和Fast-RCNN可以共享卷积特征。为了使RPN与Fast-RCNN相统一，作者提出了一个训练方案，该方案在区域建议任务和目标检测任务间交替进行微调，同时保证proposal的稳定。这种方案收敛很快，并且使两个网络可以共享数据。而SS是使用CPU计算，因而计算时间较慢，也没法共享计算。</p>
<p>在RPN中只需要找出物体的大致地方，因此作者对bbox做了三个固定：固定尺度变化（三种尺度）、固定scale ratio变化（三种ratio），固定采样方式（只在特征图的每个点在原图中的对应RoI上采样）</p>
<p>作者在Fast-RCNN的基础上增加了两个卷积层来构建RPN：一个将每个conv map编码到一个短的特征向量上，另一个卷积层在每个conv map上输出客观性的评分以及关于k个涉及到不同的尺度和纵横比的区域建议的回归边界（通常取k为9）</p>
<h2 id="RPN工作原理"><a href="#RPN工作原理" class="headerlink" title="RPN工作原理"></a>RPN工作原理</h2><p><img src="/%5Cimages%5Cimage-20220106213651479.png" alt="image-20220106213651479"></p>
<p>RPN以一副图像（任意大小）作为输入并输出一组矩形对象建议并给出得分。为了生成区域建议，一个小network滑过最后一个共享的卷积层输出的特征图。该网络最后全连接到输入的卷积特征图的一个n×n的空间窗口中。每个滑动窗口都映射到一个低维向量上。这个向量被提供给两个同级的全连接层（边界框回归层reg、分类层cls）。</p>
<p>该体系结构由一个n×n的卷积层、和两个兄弟级的1×1层（reg、cls）并将ReLUs应用于n×n转换层的输出。</p>
<p>RPN最终输出的proposals会出现部分重叠。为了减少冗余，作者根据proposal的cls分数对proposal进行非极大抑制NMS（IoU阈值为0.7）。这使得每幅图像最终有大约2k个proposal。NMS之后，再对前n个proposal进行检测。实验证明，NMS在大幅减少proposal数量的情况下，不会损害最终的检测精度。</p>
<h2 id="Anchor"><a href="#Anchor" class="headerlink" title="Anchor"></a><strong>Anchor</strong></h2><p>Anchor是特征图中的每个点在原图中的对应位置，也就是初始检测框。</p>
<p>在每个滑动窗口位置上，作者同时预测<strong>k个区域proposal</strong>（一个点对应k个anchor），因此reg有4k个输出，来标记k个box的坐标；而cls有2k个输出来评估每个proposal是对象或不是对象的概率。这k个proposal是k个box的参数表示，即上面的Anchors。每个anchor是其滑动窗口的中心位置，并于比例和宽高比相关联。作者使用了3个尺度与3个纵横比，因此每个滑动位置放置9个anchor。一个W×H的卷积特征图就总共有W×H×k个anchor。因为anchor具有<strong>平移不变特性</strong>，对anchor的计算就是对对应该anchor的proposal的计算.和不是平移不变的 MultiBox 方法相比，该方法使参数减少了一个数量级。</p>
<p>作者对每个anchor使用128、256、512三个尺度以及一比一、一比二、二比一三个纵横比，发现即使物体比底层的接受域还要大，该算法仍然可以检测出物体。在实际中，人们也可以只通过观察物体的中间位置来感知物体。这也就作者的解决方案不需要使用多尺度特征或多尺度滑动窗口来预测大的物体，节省大量运行时间。</p>
<p>对于跨越图像边界的anchor。训练中，作者忽略所有跨越图像边界的anchor，以避免带来极大的误差，使得结果无法收敛。在测试中，对于这些anchor，作者只保留其图像中的部分</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>作者将anchor打上正负标签。正标签：与ground-truth box重叠程度IoU最高的区域；或者IoU大于0.7的anchor。负标签:对于所有的ground-truth box其IoU都小于0.3的anchor。不属于正负样本的样本对于目标检测没有帮助。</p>
<p>根据这些定义，作者最小化Fast-RCNN中的多任务损失目标函数<br>$$</p>

L(\{p_i\},\{t_i\})=\frac{1}{N_{cls} }\sum{L_{cls}(p_i,p_i^{*})}+\lambda\frac{1}{N_{reg} }\sum{p_i^{*}L_{reg}(t_i,t_i^{*})}

<p>$$<br>此处的i为该batch中anchor的索引，pi是anchor为对象的概率，如果anchor为正pi*&#x3D;1，如果anchor为负pi*&#x3D;0；ti为预测边界框四个参数化坐标，ti*是与一个正anchor相关的ground-truth box。</p>
<p>Lcls（分类损失）：使用log loss；Lreg（回归损失）：使用smooth L1(R)，而只有anchor为正时，Lreg才会被激活。<br>$$<br>L_{reg}(t_i,t_i^{<em>})&#x3D;R(t_i,t_i^{</em>})<br>$$<br>作者使用Ncls、Nreg两项进行归一化，并使用lambda作为平衡因子。</p>
<p><img src="/%5Cimages%5Cimage-20220108211045368.png" alt="image-20220108211045368"></p>
<p>在回归时，要对4个坐标参数化。其中x,y,w,h为边界框box的中心位置、宽与高。x，xa，x*是预测box、anchor box、ground-truth box的参数。</p>
<p>不同于其他对任意大小区域进行特征池化（回归权值由所有区域大小共享）的边界回归，作者的回归特征在特征图上具有相同的大小。为了适用于不同的大小，作者设置了一组k边界回归器。每个回归器负责一个尺度和一个纵横比，并且这k个回归器不共享权重。</p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>RPN网络是以图像为中心的。每个batch中都含有正负样本，对所有参数的优化会使得结果偏向负样本。因此作者随机对256个anchor进行采样，尽量使得正负样本的比例达到一比一（如果正样本小于128再用负样本填充）。</p>
<p>并且作者通过标准偏差为0.01的零均值高斯分布中提取权重来初始化所有层，所有层的初始化从一个ImageNet分类模型中获得，并且调优ZF网络、VGG的jconv3_1以节省内存</p>
<h2 id="将RPN应用于目标检测"><a href="#将RPN应用于目标检测" class="headerlink" title="将RPN应用于目标检测"></a>将RPN应用于目标检测</h2><p>作者将Fast-RCNN与RPN相结合，使得二者的卷积层计算可以共享。由于Fast-RCNN依赖于固定的对象proposal并且如果在学习 Fast R-CNN 的同时更改proposal机制，尚不清楚先验是否会收敛。因此作者没有简单的定义一个包含RPN与Fast-RCNN的网络，而是通过交替优化学习共享特征。</p>
<ol>
<li>使用ImageNet预训练模型初始化，并对区域建议任务做端到端的微调（<strong>训练RPN网络</strong>）</li>
<li>利用第一步生成的区域建议，训练一个独立的检测网络，该检测网络也使用ImageNet预训练模型初始化（<strong>训练FRCNN网络</strong>）</li>
<li><strong>使用检测网络对RPN网络进行初始化，但固定两个网络共有的层，只微调RPN网络特有的层。</strong>此时，两个网络共享卷积层（<strong>训练RPN网络</strong>）</li>
<li>固定共享的卷积层，微调Fast-RCNN的全连接层。（由此形成一个统一的网络）（<strong>训练FRCNN网络</strong>）</li>
</ol>
<p>在这里的训练过程类似于一种“迭代”的过程，不过只迭代了两次，因为迭代次数再增加不会带来性能上的提升。</p>
<h1 id="做出的贡献"><a href="#做出的贡献" class="headerlink" title="做出的贡献"></a>做出的贡献</h1><ol>
<li>设计卷积网络处理区域建议RPN，使得目标检测系统实现完全的end to end</li>
<li>使用多任务损失函数</li>
</ol>
]]></content>
      <tags>
        <tag>deep learning</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>PointNet</title>
    <url>/2022/03/04/PointNet/</url>
    <content><![CDATA[<p>论文：<a href="https://openaccess.thecvf.com/content_cvpr_2017/html/Qi_PointNet_Deep_Learning_CVPR_2017_paper.html">CVPR 2017 Open Access Repository (thecvf.com)</a></p>
<span id="more"></span>
<h1 id="前人的贡献"><a href="#前人的贡献" class="headerlink" title="前人的贡献"></a>前人的贡献</h1><p>传统的目标检测算法中对于数据格式有着严格的要求，将点云数据转换为符合要求的数据格式会使得数据规模扩大，影响计算效率。</p>
<p>点云数据由<strong>无序</strong>的数据点构成一个<strong>集合</strong>来表示。因此，在使用图像识别任务的深度学习模型处理点云数据之前，需要对点云数据进行一些处理。目前采用的方式主要有两种：</p>
<blockquote>
<p>1、将点云数据投影到二维平面。此种方式不直接处理三维的点云数据，而是先将点云投影到某些特定视角再处理，如<strong>前视视角和鸟瞰视角</strong>。同时，也可以融合使用来自相机的图像信息。通过将这些不同视角的数据相结合，来实现点云数据的认知任务。比较典型的算法有MV3D和AVOD。</p>
<p>2、将点云数据划分到有空间依赖关系的voxel。此种方式通过分割三维空间，引入空间依赖关系到点云数据中，再使用3D卷积等方式来进行处理。这种方法的精度依赖于三维空间的分割细腻度，而且<strong>3D卷积</strong>的运算复杂度也较高。</p>
</blockquote>
<h2 id="点集的性质"><a href="#点集的性质" class="headerlink" title="点集的性质"></a>点集的性质</h2><ol>
<li>无序：三维N个点的数据需要N！个排列组合</li>
<li>点之间相互作用：点云中的点不是独立存在的，模型需要提取局部信息</li>
<li>转换不变性：作为一个几何物体，对物体进行变换不应该改变物体的某些特征</li>
</ol>
<h1 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h1><p><img src="/%5Cimages%5Cimage-20220116120541325.png" alt="image-20220116120541325"></p>
<p>PointNet主要用于点云数据分类问题，即在点云数据中找到属于一个物体的所有点云。</p>
<p>该分类网络以n个点作为输入，进行输入和特征转换，然后通过最大池法对点特征进行聚合。输出是k个类别的分类分数。分割网络是分类网络的延伸。它连接全局和局部特征，并输出每个分数。” mlp  “表示多层感知器，括号中的数字表示层大小。Batchnorm用于所有带有ReLU的层。在分类网的最后一个mlp中使用了Dropout层。</p>
<p>PointNet更多的是为CV领域提供了一种新的研究方向，拓展了对于原始数据处理的思路，后续的Frustum PoinNet等是对于PointNet在目标检测方面的特定研究，以及其他网络会将其作为网络设计的一部分充分的发挥其网络结构简单，计算简单的特点。</p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p> 作用于无序输入的对称函数</p>
<p>不改变模型的输入排序有三种方法：将输入按正则序排序（在高维空间中很难实现）；将输入作为序列来训练RNN（会增加训练数据）；使用一个<strong>对称函数</strong>来聚合每个点的信息（如+、*）</p>
<p>作者的主要思想是通过对一个点集中的变换<br>元素应用一个对称函数来逼近一个定义在点集上的一般函数：<br>$$<br>f({x_1,x_2,…,x_n})\approx g(h(x_1),…,h(x_n))\<br>f:2^{\mathbb{R}^N}\rightarrow \mathbb{R} ,h:\mathbb{R} ^N\rightarrow \mathbb{R} ^K,g:\mathbb{R} ^K\times …\times\mathbb{R} ^K\rightarrow \mathbb{R} (g为对称函数)<br>$$<br>根据经验，使用一个多层感知器网络近似h（mlp），使用一个单变量函数和一个最大池化函数组合近似g。通过h，可以学习到f中的不同性质,最后输出一个k维向量，表示数据的全局特征。</p>
<p> 局部全局的数据增强</p>
<p>根据上面网络得到的k维向量，可以训练SVM或是多层感知分类器对具有全局特征进行分类。</p>
<p>在计算全局点云特征向量后，通过连接全局特征和每个点的特征，将其反馈给每个点。接着基于集合的点特征提取每个点的新特征（此时每个点特征同时拥有局部特征与全局特征）。</p>
<p>之后，网络可以基于局部几何特性和全局语义预测每个点的数量。</p>
<p> 联合定位网络</p>
<p>作者通过一个微型网络T-Net预测一个仿射变换矩阵并且直接将这种变换应用到输入点的坐标上。</p>
<p>这种思想同时适用于特征空间的对齐，通过在点特征上插入另一个对齐网络，并预测一个特征转换矩阵来对齐来自不同输入点云的特征。但是特征空间中的变换矩阵比空间变换矩阵的维数高很多，这会增加优化难度。因此在softmax训练损失中增加一个<strong>正则化项</strong>，将特征变换矩阵约束为接近<strong>正交矩阵</strong>，以获得了较好的效果。<br>$$<br>L_{reg}&#x3D;    \Vert I-AA^T    \Vert^2_F(A是由T-Net预测的特征对齐矩阵)<br>$$</p>
<h2 id="理论研究"><a href="#理论研究" class="headerlink" title="理论研究"></a>理论研究</h2><ol>
<li>PointNet神经网络对于连续集函数具有很好的逼近能力。即输入点集的小扰动不会对函数数值造成很大的改变。所以即使在最坏的情况下，网络也可以通过将空间划分为等大小的voxel来探索空间。</li>
</ol>
<p><img src="/%5Cimages%5Cimage-20220116233004972.png" alt="image-20220116233004972"></p>
<ol start="2">
<li>即使输入有数据被损坏或是带有噪声，模型都具有鲁棒性；关键集的数据多少由maxpooling操作输出数据的维度K给出上界</li>
</ol>
<p>因此，该网络通过稀疏的关键点集合来总结一个形状。</p>
<h2 id="关键流程"><a href="#关键流程" class="headerlink" title="关键流程"></a>关键流程</h2><ol>
<li>输入为一帧的全部点云数据的集合，表示为一个n×3的二维 tensor，其中n代表点云数量，3对应xyz坐标。</li>
<li>输入数据先通过和一个T-Net学习到的转换矩阵相乘来对齐，保证了模型的对特定空间转换的不变性。</li>
<li>通过多次mlp对各点云数据进行特征提取后，再用一个T-Net对特征进行对齐。</li>
<li>在特征的各个维度上执行maxpooling操作来得到最终的全局特征。</li>
<li>对分类任务，将全局特征通过mlp来预测最后的分类分数；对分割任务，将全局特征和之前学习到的各点云的局部特征进行串联，再通过mlp得到每个数据点的分类结果。</li>
</ol>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p><img src="/%5Cimages%5Cimage-20220116234754228.png" alt="image-20220116234754228"></p>
<h1 id="做出的贡献"><a href="#做出的贡献" class="headerlink" title="做出的贡献"></a>做出的贡献</h1><ol>
<li>设计一种新的深度网络结构，适用于三维空间中的无序点集</li>
<li>展示这样的网络如何执行三维形状分类、形状部分分割和场景语义解析任务</li>
<li>对这种方法的稳定性和有效性进行深入的实证和理论分析</li>
<li>举例说明网络中选定的神经元三维特征，研究其性能的直观解释</li>
</ol>
]]></content>
      <tags>
        <tag>deep learning</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/02/25/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>RCNN</title>
    <url>/2022/02/25/RCNN/</url>
    <content><![CDATA[<p><strong>论文：<a href="https://openaccess.thecvf.com/content_cvpr_2014/html/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html">CVPR 2014 Open Access Repository (thecvf.com)</a></strong></p>
<span id="more"></span>

<h2 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h2><h3 id="RCNN算法4个步骤"><a href="#RCNN算法4个步骤" class="headerlink" title="RCNN算法4个步骤"></a>RCNN算法4个步骤</h3><ol>
<li>候选区域生成： 一张图像生成1K~2K个候选区域 （采用Selective Search 方法）</li>
<li>特征提取： 对每个候选区域，使用深度卷积网络提取特征 （CNN）</li>
<li>类别判断： 特征送入每一类的SVM 分类器，判别是否属于该类</li>
<li>位置精修： 使用回归器精细修正候选框位置</li>
</ol>
<h3 id="RCNN网络结构（三个模块）"><a href="#RCNN网络结构（三个模块）" class="headerlink" title="RCNN网络结构（三个模块）"></a>RCNN网络结构（三个模块）</h3><ol>
<li>第一模块提出独立类别的区域建议，定义可供检测器使用的候选测试集</li>
<li>第二模块大型卷积神经网络，从每个区域提取固定长度的特征向量</li>
<li>第三模块一组特定类别的线性支持向量机</li>
</ol>
<h3 id="区域建议-region-proposals"><a href="#区域建议-region-proposals" class="headerlink" title="区域建议(region proposals)"></a>区域建议(region proposals)</h3><p>region proposals就是从图像中选取2k个候选区域的过程.</p>
<p>现有的生成策略独立的region proposals： objectness, selective search ,category-independent object proposals , constrained parametric min-cuts (CPMC), multiscale combinatorial grouping </p>
<p>在本篇论文中，作者使用<strong>selective search方法</strong></p>
<p><strong>主要思想</strong>：</p>
<ol>
<li>使用一种过分割手段，将图像分割成小区域 (1k~2k 个)</li>
<li>查看现有小区域，按照合并规则合并可能性最高的相邻两个区域。重复直到整张图像合并成一个区域位置</li>
<li>输出所有曾经存在过的区域，所谓候选区域</li>
</ol>
<p><strong>合并策略</strong>：优先合并以下四种区域：颜色（颜色直方图）相近的；纹理（梯度直方图）相近的；合并后总面积小的： 保证合并操作的尺度较为均匀，避免一个大区域陆续“吃掉”其他小区域；合并后，总面积在其BBOX中所占比例大的： 保证合并后形状规则。</p>
<p>在具体的测试中，对于图像中的所有得分区域，我们应用贪婪的非最大抑制（对每个类独立）。如果该区域与得分高于学习阈值的选定区域有交叉合并（IoU）重叠，则拒绝该区域。</p>
<p>由于所有CNN参数在所有类别中共享，并且与其他常见算法相比，CNN的特征向量是低维的。因此相比与诸如UVA检测系统，CNN网络计算区域建议和特征花费的时间与所耗内存都有极大的优化。并且RCNN可以扩展到数以千计的对象类，而无需借助近似技术。</p>
<h3 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h3><p>作者使用了Krizhevsky等人描述的CNN的<strong>Caffe</strong>实现，从每个区域提取一个<strong>4096维</strong>的特征向量，将一个图像去均值的227  × 227的RGB图像通过5个卷积层和2个完全连通层前向传播来计算特征。因此，必须先将该区域的图像数据转换为与CNN兼容的形式（无论候选区域大小或宽高比如何，直接转换为227*227大小,在warp前作者还会对box进行扩张,使得在wrap处的box中有p个像素）</p>
<p>在实验中,作者发现RCNN可以扩展到数以千计的对象,而无需使用近似技术.</p>
<h3 id="有监督预训练"><a href="#有监督预训练" class="headerlink" title="有监督预训练"></a>有监督预训练</h3><p>作者使用开源的Caffe CNN库来进行预训练.</p>
<h3 id="特定领域微调fine-tuning"><a href="#特定领域微调fine-tuning" class="headerlink" title="特定领域微调fine-tuning"></a>特定领域微调fine-tuning</h3><p>为了使RCNN适应新的任务和新的领域，作者的随机梯度下降SGD训练的CNN参数仅来自于VOC数据集。分类器是随机初始化的21路分类层（VOC中的20个类与背景），其他CNN架构没有改变。</p>
<p>分类器会将IoU大于等于0.5的 region proposals，视为积极的，其余则视为消极的。</p>
<p>SGD学习率为0.001，并且在每次SGD迭代中，使用32个正样本，与96个背景样本，组成一个128大小的batch。同时为了使结果更好预测正样本，采样也偏向正样本。</p>
<h3 id="对象类别分类"><a href="#对象类别分类" class="headerlink" title="对象类别分类"></a>对象类别分类</h3><p>作者在文章中用检测的汽车的例子，如果使用二分类器检测汽车，那么一个紧紧包围汽车的box是正例子，而与汽车无关的背景区域是反面例子。现在的问题在于，我们如何去标记一个部分包含汽车的例子。作者在此使用0.3的IoU阈值，只有大于0.3IoU的区域才是积极。作者同时强调，这个阈值的设置对整个算法结果的影响极大。</p>
<p>同时为了解决训练数据过大的问题，作者使用standard hard negative mining method技术，该技术在实验中，只需要遍历所有图像一次就可以使mAP停止增长。</p>
<blockquote>
<p>standard hard negative mining method：</p>
<p>用hard negative的样本反复训练，初始的样本保证一定的正负样本比例。在每次训练中，将预测为positive的负样本（即hard negative样本）加入负样本训练集中。</p>
</blockquote>
<p>作者在补充材料中说明了使用SVM作为分类器的原因，SVM与CNN对于正负样本的定义不同，导致CNN的分类效果不如SVM。</p>
<h3 id="过滤器First-layerfilters"><a href="#过滤器First-layerfilters" class="headerlink" title="过滤器First-layerfilters"></a>过滤器First-layerfilters</h3><p>作者使用了一种简单的非参数的反卷积方法捕捉有方向的边缘和对立的颜色。</p>
<p>主要思想：在网络中挑选出一个特定的单元（特征），并将其作为自身的对象检测i器。也就是，我们在一个大规模的held-out region proposals上计算单元的激活情况，并按得分由高到低排序，通过执行非极大值抑制nonmaximum suppression，使得被选中的区域“不言自明”。</p>
<h3 id="pool5层"><a href="#pool5层" class="headerlink" title="pool5层"></a>pool5层</h3><p>pool5的 feature map是9216维（6×6×256）的，从实验结果来看仅使用pool5的效果不如加入fc6、fc7效果好。作者认为这是因为目标检测的过程中，一些经过分类调整的特征与形状、纹理、颜色等在全连接层处理过后会更好的将这些特征融合学习。</p>
<p>fc6是pool5的全连接层，为了计算特征，它将4096×9216的权重矩阵乘以pool5的feature map，再添加一个偏差向量。</p>
<p>而fc7则是将fc6的输出作为输入，乘以4096×4096的权重矩阵并添加一个偏差矩阵。</p>
<p>作者还进行了多组对照实验得到了许多令人感到意外的结论：</p>
<ol>
<li>在不进行微调的情况下，fc7的结果反而不如fc6，这表明了在不降低mAP的情况下有29%的CNN参数可以被去除。并且去除了两个全连接层的结果也是可以接受的，需要注意的是，此时只使用pool5（即仅6%的参数）。说明对目标检测结果有效的参数大多数来源于卷积层，而不是全连接层。</li>
<li>进行微调的情况下，微调普遍使实验结果提高了8%，并且在全连接层上的微调要比在pool5上的微调更有效果。这说明pool5学习的特征是通用的，微调的大部分改进是通过学习特定领域的非线性分类器获得的。</li>
</ol>
<h3 id="边界框回归"><a href="#边界框回归" class="headerlink" title="边界框回归"></a>边界框回归</h3><p>作者通过训练一个线性回归模型来预测一个新的检测窗口，用于selective search的区域建议。</p>
<h2 id="做出的贡献"><a href="#做出的贡献" class="headerlink" title="做出的贡献"></a>做出的贡献</h2><p>这篇论文首次表明，与基于更简单的hog特征的系统相比，CNN可以在PASCAL VOC上带来更高的对象检测性能。并且主要解决一下两个问题</p>
<ol>
<li>将高容量卷积神经网络(cnn)应用于<strong>自底向上的区域</strong>建议，以定位和分割对象</li>
</ol>
<p>其中为了定位物体localizing onbject，传统方法一是使用回归方法（但是在实践中的表现并不好），二是构建滑动窗口检测器（但是由于网络中接受域与step过大，图像的精确定位存在困难）</p>
<p>因此作者使用“区域识别”模式解决CNN定位问题。在实验中，作者的方法会先将输入图像划分为2k个类别无关的区域，使用CNN从每个区域提取固定长度的特征向量，然后使用类别特定的线性支持向量机SVM对每个区域进行分类</p>
<ol start="2">
<li>当标注的训练数据稀缺时，对辅助任务进行有监督的预训练，然后进行领域特定的微调，可以产生显著的性能提升。</li>
</ol>
]]></content>
      <tags>
        <tag>deep learning</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>CenterPoint</title>
    <url>/2022/03/08/CenterPoint/</url>
    <content><![CDATA[<p>论文：<a href="https://arxiv.org/pdf/2006.11275.pdf">2006.11275.pdf (arxiv.org)</a></p>
<span id="more"></span>
<h1 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h1><p>centerpoint是通过关键点检测来查询物体的中间位置和其特征，用<strong>两阶段</strong>的目标检测，第一阶段使用经典基于雷达激光的骨干网络如：VoxelNet、PointPillars来对输入点云进行处理，然后将表示转换为<strong>鸟瞰图</strong>，并使用标准的<strong>基于图像</strong>的关键点检测器来查找<strong>对象中心</strong>。这样对于每个检测中心可以通过中心位置的点特征来回归物体诸如三维大小、速度等特征。在第二阶段是轻量级的来<strong>细化对象位置</strong>。第二阶段提取估计对象三维box的每个面的三维中心点特征（具体来说只有四个向外的面）。该算法可以恢复由于步长和受限制的视野域带来的局部几何信息的丢失，以较小的成本带来了较好的性能提升。</p>
<p><img src="/%5Cimages%5Cimage-20220121125306002.png" alt="image-20220121125306002"></p>
<p>对于<strong>每一个点</strong>，使用<strong>双线性插值</strong>从地图视角的主干网输出中提取一个特征。接着，将提取的点特征连接起来，并将他们通过一个<strong>MLP</strong>传递。第二阶段在第一阶段的预测结果上预测一个与类无关的<strong>信心分数</strong>和对于box进一步细化。</p>
<p>可信得分：<br>$$<br>I&#x3D;\min(1,\max{(0,2\times IoU_t-0.5}))<br>$$<br>IoUt是第t个proposal box与ground-truth间的IoU</p>
<p>二元交叉熵损失：<br>$$<br>L_{socre}&#x3D;-I_t\log(\hat{I_t})-(1-I_t)\log(1-\hat{I_t})<br>$$<br>It即为可信得分</p>
<p>对于<strong>框回归</strong>，模型预测在第一阶段建议之上的细化，用L1损失训练模型。两阶段CenterPoint简化并加速了之前计算复杂度较高的的基于PointNet特征提取器和RoIAlign操作的两阶段3D检测器。</p>
<h2 id="Center-heatmap-head"><a href="#Center-heatmap-head" class="headerlink" title="Center heatmap head"></a>Center heatmap head</h2><p>Center heatmap head的目标就是在任何被探测的物体中心位置产生一个<strong>热力图峰值</strong>，Center heatmap head最终会产生一个k通道的热力图，一个通道代表了K类物体中的一种。在训练过程中，它将标注的box的三维中心投影到地图视图中，以生成二维高斯目标。使用<strong>focal loss</strong>。地图视角有图像视角不具备的优势，例如在地图视角下，汽车所占的比例很小，而在image视角下所占的比例可能会很大。此外，透视投影中对深度的压缩使得物体间的中心距离比image视角下更加接近。作者还通过放大每个ground truth的中心位置的高斯峰值来增强目标热力图的正监督，来抵消CenterNet带来的监督信号稀疏问题（使得大多数位置被认为是背景）。模型可以从附近的像素中得到更密集的监督。</p>
<h2 id="Regression-heads"><a href="#Regression-heads" class="headerlink" title="Regression heads"></a>Regression heads</h2><p>对象的中心有如下几个特征：子体素o、高度h、三维大小s以及一个偏向旋转角度。子体素位置减少了骨干网的体素化和步长带来的误差。高度h帮助在三维中定位对象，并添加被地图视角删除的高度信息。方向预测使用sin、cos作为一个连续的回归目标。结合框的大小，这些Regression heads可以提供完整的物体状态信息。每个输出使用他自己的head，作者使用L1损失训练。在推理时，通过在每个对象的峰值位置对索引密集回归头输出来提取所有属性。</p>
<h2 id="Velocity-head-and-tracking"><a href="#Velocity-head-and-tracking" class="headerlink" title="Velocity head and tracking"></a>Velocity head and tracking</h2><p>为了通过时间来跟踪物体，作者使用二维速度进行估计，并作为一个额外的回归输出。同时将前一帧中的点转换并归并到当前参考帧中，并通过时间差(速度)来预测当前和过去参考帧中物体位置的差异，来构建时间点云序列。作者对于速度回归也使用L1损失进行训练。</p>
<p>在推理时，使用贪心策略通过偏移量将当前检测与过去检测关联起来。即通过应用负速度估计将当前帧中目标中心投影回前一帧，然后通过最近距离匹配将其与跟踪目标进行匹配。</p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p><img src="/%5Cimages%5Cimage-20220121125338945.png" alt="image-20220121125338945"></p>
]]></content>
      <tags>
        <tag>deep learning</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>F-PointNet</title>
    <url>/2022/03/08/F-PointNet/</url>
    <content><![CDATA[<p>论文：<a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Qi_Frustum_PointNets_for_CVPR_2018_paper.html">CVPR 2018 Open Access Repository (thecvf.com)</a></p>
<span id="more"></span>

<h1 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h1><p><img src="/%5Cimages%5Cimage-20220117100417479.png" alt="image-20220117100417479"></p>
<p>每个对象都由一个类（k个预定义类）和一个模态三维box表示。即使对象的一部分被遮挡或是截断，模态框也会得到完整的对象。</p>
<h2 id="关键流程"><a href="#关键流程" class="headerlink" title="关键流程"></a>关键流程</h2><ol>
<li>利用一个二维CNN对象检测器提取二维区域并对内容进行分类</li>
<li>将二维区域提升到三维，并形成截锥方案</li>
<li>通过对截锥中每个点二值分类，对对象实例进行分割（截锥点云：n×c、n个点、c个通道）</li>
<li>基于分割后的点云（m×c），使用T-Net平移对齐点，使得质心接近模态盒中心</li>
<li>使用框估计网络估计得出模态三维box</li>
</ol>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><h3 id="截锥建议"><a href="#截锥建议" class="headerlink" title="截锥建议"></a>截锥建议</h3><p><img src="/%5Cimages%5Cimage-20220117115726571.png" alt="image-20220117115726571"></p>
<p>由于现有的实时深度探测器得到的分辨率要低于RGB图像，因此先使用RGB图像通过二维目标检测框出目标物体的box，再通过投影矩阵，将二维box提升为三维搜索空间的截锥。接着收集截锥内部的所有点云，形成<strong>锥形体点云</strong>。还需要通过将圆台旋转到中心视图来对圆台进行<strong>归一化</strong>，使得圆台的中轴与图像平面正交（上图b）。这种归一化有利于提高算法发旋转不变性。</p>
<p>二维的目标检测网络使用在ImageNet分类数据集和COCO对象检测数据集上预先训练的模型权重，并且在KITTI二维对象检测数据集上进一步调整模型权重，以对二维box进行分类和预测。</p>
<h3 id="三维实例分割"><a href="#三维实例分割" class="headerlink" title="三维实例分割"></a>三维实例分割</h3><p>获得二维box和对应的三维截锥后，有几种可以获取对象三维坐标的方法</p>
<ol>
<li>直接通过深度图使用二维CNN网络，进行三维位置的回归。容易与遮挡物体或是背景噪声混淆</li>
<li>在三维点云中进行分割处理，使用<strong>基于PointNet的网络</strong>处理截锥内的点</li>
</ol>
<p>本篇文献采用的是第二种方法，从截锥中获取点云并预测每个点的概率分数，该分数表示该点属于某个对象的可能性有多大。而一个点只可能属于一个特定的对象，此时其他点属于无关点。同时，该网路还学习遮挡与噪声对目标检测的影响。</p>
<p>在多类检测任务中，还利用二维检测器的信息提供更好的实例分割。例如，二维检测器检测出对象是行人后，网络会特别的针对类似人的特征进行检测。实际中，是通过将语义类别编码为一个one-hot的k维类向量（代表希望检测的k个对象），并将这个向量连接到中间点云特征中。</p>
<p>三维实例分割出来后，提取出来被分类为感兴趣的对象的点。对这些点再进一步归一化（上图c），以提高坐标的平移不变性。需要注意的是，此处没有进行点云的缩放，因为对象的大小对于框的估计也有重要的作用，</p>
<h3 id="模态三维盒估计"><a href="#模态三维盒估计" class="headerlink" title="模态三维盒估计"></a>模态三维盒估计</h3><p>尽管使用了特征对齐，该网路仍存在坐标系的原点仍然离模态盒中心很远。在使用一个轻量化的PointNet（T-Net）来重新估计完整对象的真实中心，然后转换坐标，使预测中心成为原点。这里的T-Net可以看作为新的一种空间transformer网络，并且明确的监督平移网络来预测mask坐标原点到真实物体中心的<strong>中心残差</strong>。该网路结构与PointNet和PointNet++相似，不过输出的是三维box的参数。</p>
<p>估计box中心时使用残差方法，将box估计网络预测的中心和T-Net以及遮挡点形心得到的预测中心相结合获得绝对中心<br>$$<br>C_{pred}&#x3D;C_{mask}+\Delta C_{T-Net}+\Delta C_{box-net}<br>$$<br>对于box的尺寸和朝向，使用Faster r-cnn的预测朝向方法来进行预测。即预定义了NS个模板和NH个等分割角度的box。网络将这些分类到预定义的类别中，并预测每个类别的参差数</p>
<h2 id="多任务训练损失"><a href="#多任务训练损失" class="headerlink" title="多任务训练损失"></a>多任务训练损失</h2><p><img src="/%5Cimages%5Cimage-20220118222715021.png" alt="image-20220118222715021"></p>
<p><strong>角损</strong>对于网络结果的影响还是很大的，本质上，角损时预测框和ground truth box八个角的距离之和。由于角点位置由中心、大小和方向共同决定，因此角点损失能够对这些参数的多任务训练进行正则化。<br>$$</p>

L_{corner}=\sum^{NS}_{i=1}\sum^{NH}_{j=1}\delta_{ij}\min{\{\sum^8_{k=1}\parallel p_k^{ij}-p^{*}_k \parallel,\sum^8_{k=1}\parallel p_k^{ij}-p^{**}_k \parallel\} }

<p>$$<br>构造NS×NH个包含所有尺寸和朝向的anchors,取值时使用原始和翻转情况最小的值，避免由于翻转航向造成较大损失。δ是ground truth的大小&#x2F;朝向类，是一个二维掩码用来选择距离项。</p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p><img src="/%5Cimages%5Cimage-20220117114100396.png" alt="image-20220117114100396"></p>
<p>该网络的优势：</p>
<ol>
<li>对于合理距离内的非遮挡物体的情况，可以得出非常精确的三维box</li>
<li>并且对于部分获取到的点数很少的物体（平行停放的汽车）也可以正确的预测三维box</li>
<li>在二维box相互重叠的情况下，转换到三维空间后处理起来就容易了许多。</li>
</ol>
<p>同时，实验也暴露出该网路存在的一些问题：</p>
<ol>
<li>由于稀疏点云，造成不准确的姿态和大小估计。这个可以通过对图像特征的进一步提取解决</li>
<li>如果截锥中有同一类别的多个实例（两个人站在一起），因为网络假设的是一个截锥只有一个对象，所以出现多个对象的时候，可能会产生混淆，从而输出混合分割结果。可以通过在每个截锥中设置多个三维box缓解</li>
<li>二维检测器会因为湖南的灯光或强遮挡错过目标，如果二位检测没有检测到物体，转换到三维空间时自然会忽略该物体。因此可以借助与BEV图像缓解。</li>
</ol>
<h1 id="做出的贡献"><a href="#做出的贡献" class="headerlink" title="做出的贡献"></a>做出的贡献</h1><ol>
<li>提出一种基于RGB-D数据的三维目标检测算法</li>
<li>提供广泛的定量评估来验证该算法的设计选择，以及丰富的定性结果来理解该方法的优势和局限性</li>
<li>展示了如何在该框架下训练3D对象检测器，并在标准的3D对象检测基准上实现最先进的性能。</li>
</ol>
<p>[^预测朝向方法]: A. Mousavian, D. Anguelov, J. Flynn, and J. Kosecka. 3d bounding box estimation using deep learning and geometry.、Faster r-cnn: Towards real-time object detection with region proposal networks.</p>
]]></content>
      <tags>
        <tag>deep learning</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>PointPillars</title>
    <url>/2022/03/08/PointPillars/</url>
    <content><![CDATA[<p>论文：<a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lang_PointPillars_Fast_Encoders_for_Object_Detection_From_Point_Clouds_CVPR_2019_paper.html">CVPR 2019 Open Access Repository (thecvf.com)</a></p>
<span id="more"></span>
<p><img src="/%5Cimages%5Cimage-20220114222458551.png" alt="image-20220114222458551"></p>
<h1 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h1><p>本篇文献主要解决将点云编码为适合更适合目标检测的格式的问题。作者没有预训练网络，所有权值随机使用均匀分布。</p>
<h2 id="特征解码网络"><a href="#特征解码网络" class="headerlink" title="特征解码网络"></a>特征解码网络</h2><p>将点云转换为稀疏的伪图像。</p>
<p>不同于voxelNet将整个点云分割为许多的voxel，PointPillar只在xOy面进行划分，整个点云空间被分割为若干个高度为点云图高度（在z方向上近似是无限的，因此不需要超参数控制z维度）的柱体。</p>
<p>与voxel类似，大部分的柱体都是空的。而对于包含点数过多N的柱体采用随机采样，对于包含点数过小的柱体应用零填充。并通过限制非空柱体的数量P，将整个点云用一个尺寸为(D,P,N)的密集张量。</p>
<p>接着使用简化的PointNet，对于每个点应用一个线性层（张量的1×1卷积）、一个BN层、一个ReLU层，产生一个尺寸为(C,P,N)的张量。（C&#x3D;64）然后对其进行max操作，创建一个尺寸为(C,P)的输出张量（将三维点云转换为二维数据）。因为作者是使用的柱体而非voxel，所以可以在卷积中间层避免三维卷积，极大的提升计算效率。</p>
<p>编码后特征被分散到原始位置，以创建一个大小为(C,H,W)的伪图像（H，W为画布的高度和宽度）    </p>
<h2 id="二维卷积骨干网络"><a href="#二维卷积骨干网络" class="headerlink" title="二维卷积骨干网络"></a>二维卷积骨干网络</h2><p>将伪图像转换为高层的表示。该网络又可以分解为两个小的网络</p>
<ol>
<li>自上而下网络：在越来越小的空间分辨率上产生特征</li>
<li>对自上而下的特征进行上采样和连接</li>
</ol>
<p>作者使用Block(S,L,F)来表示自顶向下的主干，每个block的操作步长为S（与初始的伪图像大小有关），每块都有一个二维卷积层L和输出通道F，以及一个BN层、一个ReLU层。</p>
<p>第一层卷积步长为S&#x2F;Sin，<em>以确保block在执行步长为Sin卷积操作后还可以执行步长为S的操作。</em>（对于汽车S&#x3D;2，对于行人、自行车S&#x3D;1）（The first convolution inside the layer has stride S&#x2F;Sin to ensure the block operates on tride S after receiving an input blob of stride Sin）。后续block上的卷积步长为1.</p>
<p>最终从每个自顶向下block得到的特征通过一定的上采样和拼接进行组合：</p>
<ol>
<li>对特征进行上采样Up(Sin,Sout,F)，初始步长Sin，最终步长Sout，利用转置二维卷积和F得到特征</li>
<li>使用 BatchNorm和ReLU 应用上采样特征，最终的输出特征是从不同步长级联得到的特征</li>
</ol>
<h2 id="Detection-Head"><a href="#Detection-Head" class="headerlink" title="Detection Head"></a>Detection Head</h2><p>检测三维box，并进行回归。这里的 Detection Head是模块化的，即对于不同的任务可以使用不同的 Detection Head。就像使用不同的镜头来拍摄不同的照片。</p>
<p>作者这里使用 Single Shot Detector (SSD)以来处理三维目标检测。同时，使用二维的IoU将ground truth与先验box相匹配。而将box高度与高度elevation作为额外的回归目标</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>回归残差：<br>$$</p>

\Delta x=\frac{x^{gt}-x^a}{d^a},
\Delta y=\frac{y^{gt}-y^a}{d^a},
\Delta z=\frac{z^{gt}-z^a}{d^a}\quad(d=\sqrt{(w^a)^2+(l^a)^2});\\
\Delta l=\log{\frac{l^{gt} }{l^a} },
\Delta w=\log{\frac{w^{gt} }{w^a} },
\Delta h=\log{\frac{h^{gt} }{h^a} },
\Delta\theta=\theta^{gt}-\theta^a;

<p>$$<br>定位损失：由于角度定位无法区分翻转的box，在离散化方向上使用softmax分类损失Ldir学习车辆前进方向<br>$$<br>L_{loc}&#x3D;\sum_{b\in(x,y,z,w,l,\theta)}SmoothL1(\Delta b)<br>$$<br>目标分类损失：p^a是锚点是类的概率，α&#x3D;0.25，γ&#x3D;2<br>$$<br>L_{cls}&#x3D;-\alpha_a(1-p^a)^\gamma\log{p^a},<br>$$</p>
<p>总损失函数：Npos为正锚点的数量、βloc&#x3D;2、βcls&#x3D;1、βdir&#x3D;0.2<br>$$</p>

L=\frac{1}{N_{pos} }(\beta_{loc}L_{loc}+\beta_{cls}L_{cls}+\beta_{dir}L_{dir}),

<p>$$<br>损失函数是以哦那个初始学习率为0.0002的Adam进行优化，每15个epoch减少0.8倍。用于验证与测试的epoch个数分别为160、320，batch大小分别为2、4.</p>
<h2 id="超参数设置"><a href="#超参数设置" class="headerlink" title="超参数设置"></a>超参数设置</h2><ul>
<li>xy分辨率：0.16m</li>
<li>点柱最大数量P：12000</li>
<li>点柱内最多点数N：100</li>
<li>轴对齐非极大抑制NMS的IoU阈值：0.5</li>
</ul>
<h3 id="汽车检测任务："><a href="#汽车检测任务：" class="headerlink" title="汽车检测任务："></a>汽车检测任务：</h3><ul>
<li><p>x,y,z检测范围：[(0, 70.4), (-40, 40), (-3, 1)]</p>
</li>
<li><p>锚点宽、长、高：(1.6, 3.9, 1.5)m，z中心：-1m</p>
</li>
<li><p>匹配正负阈值：0.6、0.45</p>
</li>
</ul>
<h3 id="行人、自行车检测任务："><a href="#行人、自行车检测任务：" class="headerlink" title="行人、自行车检测任务："></a>行人、自行车检测任务：</h3><ul>
<li><p>x,y,z检测范围：[(0, 48), (-20, 20), (-2.5, 0.5)]</p>
</li>
<li><p>行人锚点宽、长、高：(0.6, 0.8, 1.73)m，z中心：-0.6m</p>
</li>
<li><p>自行车锚点宽、长、高：(0.6, 1.76, 1.73)m，z中心：-0.6m</p>
</li>
<li><p>匹配正负阈值：0.5，0.35</p>
</li>
</ul>
<h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><ol>
<li>类似SECOND，创建一个查找表，其中包含所有类别的ground truth 3D boxes以及box中相关联的点云；对于每个样本随即选择若干个汽车、行人、自行车的真实样本将其放入当前环境中以提升对于不同环境下目标检测的能力</li>
<li>对所有 <strong>ground truth boxes独立的旋转、转换</strong>，进一步丰富训练集。</li>
<li>执行两个全局增强集合：随机沿x轴翻转并执行<strong>全局旋转和放缩</strong>、使用N(0,0,2)<strong>模拟噪声</strong>对x、y、z坐标转换</li>
</ol>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p><img src="/%5Cimages%5Cimage-20220115183322884.png" alt="image-20220115183322884"></p>
<p>实验发现该网络对于行人的检测仍有一些不足，行人与自行车会被误认为彼此。行人也容易被混淆为狭窄的带有垂直特性的物体，如树干、电线杆。</p>
<p>推理速度快也是该网络的一大优势，总的运行时间：16.2ms。主要推理过程如下：（ Intel i7 CPU and a 1080ti GPU）</p>
<ol>
<li>根据图像的可见性、范围加载、过滤点云1.4ms</li>
<li>将点分配到点柱并进行处理2.7ms</li>
<li>将点柱张量加载进GPU2.9ms、<strong>编码1.3ms</strong>、分散为伪图像0.1ms</li>
<li>由卷积骨干网、检测头处理7.7ms</li>
<li>NMS处理0.1ms（使用CPU）</li>
</ol>
<p><strong>编码阶段</strong>是该网络运行时间少的关键，VoxelNet的解码时间190ms、SECOND的编码时间50ms。同时该网络只使用一个PointNet网络进行编码，将pytorch的运行时间减少了2.5ms。将第一个block的尺寸缩减到64以匹配解码输出的尺寸，并将上采样特征层输出尺寸减半到128，这些都大幅减少了运行时间。</p>
<p>实验证明，当推理速度达到105Hz时，准确率只减少了一点。相比之下，激光雷达的工作频率为20Hz。但是需要注意的是，现在的实验是使用桌面级GPU，如果应用于实际，使用嵌入式GPU，计算效率会下降；一个可操作的AV需要查看完整的环境并处理全部点云，而实验使用的KITTI数据集中，只会使用10%的点云数据。实际中需要计算的数据量有很大区别。</p>
<h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><p>作者通过一系列消融实验得到以下结论：</p>
<ol>
<li>好的编码器明显优于固定的编码器，特别是对于更大的分辨率。</li>
<li>box增强并不会带来更大提升，反而在检测行人方面导致性能下降</li>
<li>更小的点柱使得定位更准确以及学习的特征更多，更大的点柱计算速度更快（更少的非空点柱）</li>
</ol>
<h1 id="做出的贡献"><a href="#做出的贡献" class="headerlink" title="做出的贡献"></a>做出的贡献</h1><ol>
<li>提出一个新的基于点云解码器和网络PointPliiar，适用于端到端的基于点云的三维目标检测网络的训练</li>
<li>将对点云的柱上的计算变为密集的二维卷积，使得推理速率到达62Hz</li>
<li>在KITTI数据集上的实验，该网络表现出对于汽车、自行车、行人检测最先进的结果</li>
<li>通过消融实验 ablation studies，发现对检测性能起到关键影响的因素</li>
<li>作者提出的点柱偏移Xp、Yp以及簇偏移Xc、Yc、Zc带来更好的检测效果</li>
</ol>
]]></content>
      <tags>
        <tag>deep learning</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>PointRCNN</title>
    <url>/2022/03/08/PointRCNN/</url>
    <content><![CDATA[<p>论文：<a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_PointRCNN_3D_Object_Proposal_Generation_and_Detection_From_Point_Cloud_CVPR_2019_paper.html">CVPR 2019 Open Access Repository (thecvf.com)</a></p>
<span id="more"></span>
<h1 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h1><p><img src="/%5Cimages%5Cimage-20220218103739679.png" alt="image-20220218103739679"></p>
<p>本篇论文使用两阶段的三维目标检测框架，并且直接应用于三维点云，实现了强大和准确的三位检测性能。</p>
<h2 id="第一阶段"><a href="#第一阶段" class="headerlink" title="第一阶段"></a>第一阶段</h2><p>第一阶段是生成自底向上的三维包围盒方案，分割前景，同时从分割点生成数量较少的box proposal，节省大量的计算量。具体来说，通过学习逐点特征来分割原始点云，并同时从分割的前景点生成3D提案。</p>
<p>对于训练集中的每个3D点云场景，我们从每个场景中抽取16,384个点作为输入。对于点数小于16,384的场景，我们随机重复这些点数，得到16,384点。对于stage-1子网络，我们遵循[28]的网络结构，其中使用四个具有多尺度分组的集抽象层，将点分组为大小为4096、1024、256、64的组。然后使用四个特征传播层来获取点特征向量，用于分割和生成建议。</p>
<p>鉴于骨干点云网络编码的逐点特征，通过附加一个分割头用于估计前景掩模和一个框回归头用于生成3D提案。对于点分割，ground-truth分割蒙版自然是由3D  ground-truth box提供的。对于大型户外场景，前景点的数量一般要比背景点的数量少得多。因此，我们使用焦点损失[19]来处理类不平衡问题<br>$$<br>L_{focal}(p_t)&#x3D;-\alpha_t(1-p_t)^\gamma\log(p_t),\<br>p_t&#x3D;\begin{cases} p \qquad for forground point \1-p \qquad otherwise\end{cases}<br>$$</p>
<h2 id="第二阶段"><a href="#第二阶段" class="headerlink" title="第二阶段"></a>第二阶段</h2><p>第二阶段进行规范的三维box框细化，生成proposal后，采用点云池化，将第一阶段学习到的点进行池化。</p>
<p>在LiDAR坐标系中，三维包围框表示为(x, y, z, h, w, l， θ)，其中(x, y, z)为目标中心位置，(h, w,  l)为目标大小，θ为从鸟瞰目标方向。为了约束生成的3D框建议，提出了基于bin的回归损失来估计对象的3D边界框。</p>
<p><img src="/%5Cimages%5Cimage-20220218183400653.png" alt="image-20220218183400653"></p>
<p>Fcls为交叉分类损失；Freg为平滑L1损失</p>
<p>同时为了消除冗余提案，通过基于鸟瞰图进行非最大抑制(non - maximum suppression,  NMS)，生成少量高质量提案。在训练方面，使用0.85作为IoU阈值，在NMS之后，保留stage-2子网培训建议的top  300的proposals。推理过程中，采用NMS，IoU阈值为0.8，只保留前100个建议对阶段2子网进行细化</p>
<p>对于框提案细化子网络，网络从每个提案的集合区域随机抽取512个点作为细化子网络的输入。使用三个单尺度分组集合抽象层(分组大小分别为128、32、1)生成单个特征向量，用于对象置信度分类和建议位置优化。</p>
<h2 id="点云区域池化"><a href="#点云区域池化" class="headerlink" title="点云区域池化"></a>点云区域池化</h2><p>在获得3D包围盒提案后，目标是在之前生成的box proposal的基础上细化box的位置和方向。为了了解每个方案更具体的局部特征，建议根据每个3D方案的位置，从stage-1集合3D点及其对应的点特征。</p>
<p>对于每个三维box，作者都会稍微放大尺寸得到一个新的三维box，从上下文编码额外的信息</p>
<p>对于每个点，通过内外测试确定点是否再扩大的box proposal中。</p>
<h2 id="规范的3D-box细化"><a href="#规范的3D-box细化" class="headerlink" title="规范的3D box细化"></a>规范的3D box细化</h2><h3 id="正则变换"><a href="#正则变换" class="headerlink" title="正则变换"></a>正则变换</h3><p>正则变换遵守如下规则：</p>
<ol>
<li>原点位于方框的中心</li>
<li>局部的X‘和Z’轴近似平行于地平面，X‘指向提案的头部方向，另一个Z‘轴垂直于X’</li>
<li>Y ’轴与激光雷达坐标系保持一致。</li>
</ol>
<p><img src="/%5Cimages%5Cimage-20220220120505467.png" alt="image-20220220120505467"></p>
<h3 id="改进box-proposal的特征学习"><a href="#改进box-proposal的特征学习" class="headerlink" title="改进box proposal的特征学习"></a>改进box proposal的特征学习</h3><p>细化子网络结合了变换后的局部空间点(特征)以及从阶段1进行进一步的盒和置信度细化得到的全局语义特征。</p>
<p>虽然正则变换能够实现鲁棒的局部空间特征学习，但它不可避免地会丢失每个对象的深度信息。为了补偿丢失的深度信息，将点到传感器的距离特征加入特征点p中。</p>
<p>对于每个提议，其关联点的局部空间特征和额外的特征首先连接并馈送给几个全连接层，将其局部特征编码为相同维的全局特征。然后将局部特征和全局特征串联并馈送到一个pointNet++结构的网络中，得到一个判别特征向量，用于后续的置信度分类和盒体细化。</p>
<h3 id="改进box-proposal的损失函数"><a href="#改进box-proposal的损失函数" class="headerlink" title="改进box proposal的损失函数"></a>改进box proposal的损失函数</h3><p>使用基于bin的回归损失来改进proposal，如果IoU大于0.55，则将ground-truth box 分配给三维box proposal，用于学习box的改进。（三维box proposal及其对应的ground-truth box 都被转换为标准坐标系）<br>$$</p>

L_{refine}=\frac{1}{\vert\vert B\vert\vert}\sum_{i\in B}F_{cls}(prob_i,label_i)+\frac{1}{\vert\vert B_{pos}\vert\vert}\sum_{i\in B_{pos} }(\hat{L}^{(i)}_{bin}+\hat{L}^{(i)}_{res})

<p>$$</p>
<p>B是阶段1的3D提案集合，Bpos存储回归的正提案，probi是bi的估计置信度，labeli是相应的标签，</p>
<p>对于box偏转方向，则将ground-truth box 与三维box proposal的IoU阈值为0.55。</p>
<h1 id="做出的贡献"><a href="#做出的贡献" class="headerlink" title="做出的贡献"></a>做出的贡献</h1><ol>
<li>提出了一种基于点云的自底向上的三维包围盒提案生成算法，该算法通过将点云分割成前景对象和背景，生成少量高质量的三维提案。从分割中学习到的点表示不仅擅长于提议的生成，而且对后续的框细化也有帮助。</li>
<li>所提出的规范3D包围盒细化利用了从阶段1生成的高召回量盒建议，并学会了在规范坐标中预测基于稳健盒基损耗的盒坐标细化。</li>
<li>提出的三维检测框架PointRCNN在仅使用点云作为输入的情况下，显著优于目前最先进的方法</li>
</ol>
]]></content>
      <tags>
        <tag>deep learning</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>second</title>
    <url>/2022/03/08/second/</url>
    <content><![CDATA[<p>论文：<a href="https://www.mdpi.com/1424-8220/18/10/3337">Sensors | Free Full-Text | SECOND: Sparsely Embedded Convolutional Detection (mdpi.com)</a></p>
<span id="more"></span>
<h1 id="前人贡献"><a href="#前人贡献" class="headerlink" title="前人贡献"></a>前人贡献</h1><p>使用<strong>RGB-D数据</strong>的二维表示的方法分为基于鸟瞰图、基于前景两种。</p>
<h2 id="Front-View-and-Image-Based-Methods"><a href="#Front-View-and-Image-Based-Methods" class="headerlink" title="Front-View- and Image-Based Methods"></a>Front-View- and Image-Based Methods</h2><p>在一般的<strong>基于图像</strong>的方法中，先生成二维box类语义、实例语义，再使用手工方法生成特征图。另一种方法使用CNN从图像中估计3Dbox，并使用专门设计的离散连续CNN估计物体运动方向。</p>
<p>对于基于激光雷达数据的方法包括将点云转换为前景的2D map，并应用2D探测器对前景视图中的图像进行定位、和其他方法相比，这些方法在BEV检测和三维检测方面都做得很差。</p>
<p>代表论文：<a href="https://openaccess.thecvf.com/content_cvpr_2017/html/Mousavian_3D_Bounding_Box_CVPR_2017_paper.html">CVPR 2017 Open Access Repository (thecvf.com)</a>、[<a href="https://arxiv.org/abs/1608.07916">1608.07916] Vehicle Detection from 3D Lidar Using Fully Convolutional Network (arxiv.org)</a></p>
<h2 id="Bird’s-Eye-View-Based-Methods"><a href="#Bird’s-Eye-View-Based-Methods" class="headerlink" title="Bird’s-Eye-View-Based Methods"></a>Bird’s-Eye-View-Based Methods</h2><p>这种方法将点云数据转换为<strong>多个切片</strong>得到height maps（按不同高度划分），再将height maps与intensity map、density map 结合得到多通道特征。这种方法的问题是在生成BEV图时，许多数据点被丢弃，导致垂直轴上信息损失很大，这种信息丢失会严重影响在3Dbox回归中的性能</p>
<p>如MV3D（首个将点云数据转换为BEV的方法）；ComplexYOLO使用YOLO网络和复杂角度编码方法来提高速度和定位性能、但在预测3D边界框时只能固定高度）；</p>
<p>代表文章：<a href="https://openaccess.thecvf.com/content_CVPRW_2019/html/WAD/Simon_Complexer-YOLO_Real-Time_3D_Object_Detection_and_Tracking_on_Semantic_Point_CVPRW_2019_paper.html">CVPR 2019 Open Access Repository (thecvf.com)</a>、<a href="https://openaccess.thecvf.com/content_CVPRW_2019/html/WAD/Simon_Complexer-YOLO_Real-Time_3D_Object_Detection_and_Tracking_on_Semantic_Point_CVPRW_2019_paper.html">CVPR 2019 Open Access Repository (thecvf.com)</a></p>
<h2 id="3D-Based-Methods"><a href="#3D-Based-Methods" class="headerlink" title="3D-Based Methods"></a>3D-Based Methods</h2><p>多数的3D-based方法或者<strong>直接使用</strong>点云数据、或者将数据转换为3Dvoxel（而不是BEV），然后采用一种<strong>卷积式的投票算法</strong>进行检测。这种方法利用点云数据的稀疏性，以特征中心的投票方案提高计算速度。但是是使用<strong>手工制作</strong>特征方式，无法适应自动驾驶的复杂环境。</p>
<p>之后又有人提出使用<strong>CNN网络、k-领域</strong>等方法从点云中学习局部空间信息。但是这些方法不能应用于大规模的点，需要用图像检测结果对原始数据点进行滤波。</p>
<p>CNN网络应用到点云也是目前的研究热门，其基本思想是基于CNN的检测器将点云转换为voxel，有下列一些方向：</p>
<ol>
<li>将点云数据离散为二值的voxel，然后进行三维卷积</li>
<li>将点云数据分组为voxel，提取voxel特征，再将这些特征转换为密集张量，利用3D或2D卷积网络进行处理</li>
</ol>
<p>这种方法的主要问题是3D CNN的高计算成本，而且3D CNN的计算复杂度随着voxel分辨率的增加而增加。因此，使用稀疏结构的卷积网络会降低计算复杂度。而 <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Graham_3D_Semantic_Segmentation_CVPR_2018_paper.html">CVPR 2018 Open Access Repository (thecvf.com)</a>提出了一种空间结构不变的3D CNN。这种网络已经应用于三维语义分割任务，但是还没有利用稀疏卷积进行检测的方法。</p>
<p>代表论文：[<a href="https://arxiv.org/abs/1505.02890">1505.02890] Sparse 3D convolutional neural networks (arxiv.org)</a>、<a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Graham_3D_Semantic_Segmentation_CVPR_2018_paper.html">CVPR 2018 Open Access Repository (thecvf.com)</a></p>
<h2 id="Fusion-Based-Methods"><a href="#Fusion-Based-Methods" class="headerlink" title="Fusion-Based Methods"></a>Fusion-Based Methods</h2><p>这种方法将<strong>相机图像与点云</strong>相结合。</p>
<ol>
<li>使用3维的RPN两个尺度不同的接受域产生三维proposal，然后将每个三维proposal的深度数据反馈到三维CNN并且将相应的二维的颜色补充到二维CNN网络来预测最终结果。</li>
<li>将点云数据转换为一个正视图和一个BEV，再从这两个图中提取特征图与图像特征图融合。但是它含有三个CNN网络并不适用于小心对象</li>
<li>将图像与BEV结合，使用一种新的结构生成高分辨率的特征图的三位对象proposal</li>
<li>使用二维检测结果过滤点云，PointNet就可以应用于三维box</li>
</ol>
<p>这些方法需要处理大量的数据，因此基于融合的方法运行缓慢。并且它对激光雷达的时间同步和校准摄像机的额外要求限制这种方法的使用环境，降低了鲁棒性。</p>
<p>代表论文：<a href="https://openaccess.thecvf.com/content_cvpr_2017/html/Chen_Multi-View_3D_Object_CVPR_2017_paper.html">CVPR 2017 Open Access Repository (thecvf.com)</a></p>
<h1 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h1><h2 id="SECOND-Detector"><a href="#SECOND-Detector" class="headerlink" title="SECOND Detector"></a>SECOND Detector</h2><p>SECOND Detector以原始点云作为输入，将其转换为voxel特征和坐标，并应用两个VFE层和一个线性层。然后使用稀疏CNN。最后应用RPN生成检测结果。</p>
<p><img src="/%5Cimages%5Cimage-20220111213034747.png" alt="image-20220111213034747"></p>
<p> 作者的Point Cloud Grouping、Voxel-wise Feature Extractor与VoxelNet的处理相同此处便不再赘述。</p>
<h3 id="稀疏卷积网络"><a href="#稀疏卷积网络" class="headerlink" title="稀疏卷积网络"></a>稀疏卷积网络</h3><p>作者的主要改进体现在引入了<strong>稀疏卷积网络</strong>，替代voxelNet中的三维卷积提取特征图。常规的稀疏卷积是如果没有相关的输入点，则不计算输出点。子簇卷积（常规卷积网络的替代）限制当且仅当相应的输入位置处于活动状态是，输出位置才处于活动状态，这可以避免生成过多的活动点，提升卷积速度。</p>
<h3 id="稀疏卷积算法"><a href="#稀疏卷积算法" class="headerlink" title="稀疏卷积算法"></a>稀疏卷积算法</h3><ol>
<li><p>将稀疏的<strong>输入特征</strong>通过gather操作获得<strong>密集的gather特征；</strong></p>
</li>
<li><p>然后使用GEMM对<strong>密集的gather特征</strong>进行卷积操作，获得<strong>密集的输出特征；</strong></p>
</li>
<li><p>通过预先构建的<strong>输入-输出索引规则矩阵</strong>，将<strong>密集的输出特征</strong>映射到<strong>稀疏的输出特征</strong>。</p>
</li>
</ol>
<p><img src="/%5Cimages%5Cimage-20220112105038074.png" alt="image-20220112105038074"></p>
<p>二维密集卷积算法中，W表示过滤元素，D表示图像元素。函数P(x,y)需要根据输出位置来计算输入位置。因此，卷积输出Y计算如下：<br>$$</p>

Y_{x,y,m}=\sum_{u,v\in P(x,y)}{\sum_{l}{W_{u-u_0,v-v_0,l,m}D_{u,v,l} } }\quad(1)

<p>$$<br>基于<strong>矩阵乘法GEMM算法</strong>可用于收集全部用于构建矩阵的数据，并执行GEMM本身。<br>$$</p>

Y_{x,y,m}={\sum_{l}{W_{*,l,m}\tilde{D}_{P(x,y),l} } }\quad(2)
{% rendrawaw %}
<p>$$<br>此处的W与上式的W相同，只是<strong>使用GEMM形式</strong>。对于稀疏数据D‘和相关联的输出Y’直接计算算法如下：<br>$$</p>
{% raw %}
Y_{x,y,m}=\sum_{i\in P'(j)}{\sum_{l}{W_{k,l,m}D'_{i,l} } }\quad(3)
{% endraw %}
<p>$$<br>其中p‘是获取输入索引和滤波器偏移量的函数。<strong>基于GEMM的版本</strong>为<br>$$</p>
{% raw %}
Y’_{j,m}={\sum_{l}{W_{*,l,m}\tilde{D'}_{P'(j),l} } }\quad(4)
{% endraw %}
<p>$$<br>因为D’中含有大量的零不用参与计算，因此引入<strong>规则矩阵R</strong>，指定输入索引i给出核偏移量k和输出索引j，公式如下：<br>$$</p>
{% raw %}
Y’_{j,m}=\sum_k{\sum_{l}{W_{k,l,m}\tilde{D'}_{R_{k,j},k,l} } }\quad(5)
{% endraw %}
<p>$$<br>而5式的inner sum无法通过GEMM的计算，因此还需要收集足够的数据构建矩阵来执行GEMM，再将数据分散回去。实际中可以利用预先构造的<strong>输入-输出索引规则矩阵</strong>从原始稀疏矩阵数据中收集数据</p>
<h3 id="生成规则算法"><a href="#生成规则算法" class="headerlink" title="生成规则算法"></a>生成规则算法</h3><p>常见的哈希表规则生成算法是基于CPU的，速度较慢，并且需要再CPU和GPU间进行数据传输。另一种方法是<strong>迭代输入点</strong>，找到每个输入点相关的输出，并将相应的索引存储到规则中。在迭代的过程中，需要使用一张表检查每个输出位置的存在性以决定是否使用全局输出索引计数器来累加数据，这也是制约并行计算在算法中使用的最大挑战。</p>
<p>作者设计了一种<strong>基于GPU的规则生成算法</strong>。</p>
<ol>
<li><strong>收集输入的索引和对应的空间索引</strong>而非输出索引（此阶段会重复获得输出索引）</li>
<li>在空间索引数据上使用一种独特的<strong>并行算法</strong>，以获得输出索引以及相关的空间索引。</li>
<li>根据前两步的结果生成一个<strong>与稀疏数据空间维度相同的缓冲区</strong>，用于下一步的表查找</li>
<li>对规则进行<strong>迭代</strong>，并使用存储的空间索引来获取每个输入索引的输出索引。</li>
</ol>
<p><img src="https://pic2.zhimg.com/80/v2-40a7e08f7a00a6e25ac4ff33a25fb849_1440w.jpg" alt="img"></p>
<h3 id="稀疏卷积中间提取器"><a href="#稀疏卷积中间提取器" class="headerlink" title="稀疏卷积中间提取器"></a>稀疏卷积中间提取器</h3><p>中间提取器用于学习z轴信息，并将稀疏的三维数据转换为二维BEV图像。它包含了稀疏卷积的两个阶段。每个阶段都有几个子流形卷积层和一个正常的稀疏卷积，用于在z轴进行下采样。在 z 维被下采样到一维或二维后，稀疏数据被转换为密集特征图。 然后，将数据简单地重新整形为类似图像的 2D 数据。</p>
<p><img src="/%5Cimages%5Cimage-20220112212134401.png" alt="image-20220112212134401"></p>
<blockquote>
<p>黄色表示稀疏卷积，白色表示子流形卷积，红色表示稀疏到密集层，图的上半部分是稀疏数据的空间维数。</p>
</blockquote>
<h3 id="Anchors与目标"><a href="#Anchors与目标" class="headerlink" title="Anchors与目标"></a>Anchors与目标</h3><p>作者的anchor size与<strong>VoxelNet</strong>中anchor size，对正负锚点的阈值选择都是一样。作者同时为每个锚点分配一个以分类为目标的one-hot向量、一个边界框回归为目标的7维向量、一个以方向分类为目标的one-hot向量。</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><h3 id="Sine-Error-Loss-for-Angle-Regression（方向回归）"><a href="#Sine-Error-Loss-for-Angle-Regression（方向回归）" class="headerlink" title="Sine-Error Loss for Angle Regression（方向回归）"></a>Sine-Error Loss for Angle Regression（方向回归）</h3><p>作者在RPN中增加了一个direction classifer分支，将车头是否区分正确直接通过一个softmax loss来进行约束。如果θ&gt;0则为正，θ&lt;0则为负，将其转换为了一个简单的二分类问题。<br>$$<br>L_{\theta}&#x3D;SmoothL1(\sin{(\theta_p-\theta_t)})<br>$$</p>
<p>它可以很好的解决0和Π两个角度的对抗样本问题，也可以根据角度偏移对IoU进行建模。</p>
<h3 id="Focal-Loss-for-Classification"><a href="#Focal-Loss-for-Classification" class="headerlink" title="Focal Loss for Classification"></a>Focal Loss for Classification</h3><p>该网络产生的约70k个锚点中，只有约4k~6k是有用的。作者引入RetinaNet中的单级损失single-stage loss，即focal loss<br>$$<br>FL(p_t)&#x3D;-\alpha_t(1-p_t)^{\gamma}\log(p_t)<br>$$<br>pt是模型的估计概率，α&#x3D;0.25，γ&#x3D;2.</p>
<h3 id="总训练损失"><a href="#总训练损失" class="headerlink" title="总训练损失"></a>总训练损失</h3><p>$$<br>L_{total}&#x3D;\beta_1L_{cls}+\beta_2(L_{reg-\theta}+L_{reg-other})+\beta_3L_{dir}<br>$$</p>
<p>第一个损失函数是分类损失，第二个损失函数是新角度损失，第三个损失函数是位置和尺寸回归损失，第四个损失函数是方向分类损失。β1&#x3D;1.0、β2&#x3D;2.0、β3&#x3D;0.2（将β3使用较小的值，避免网络难以识别物体发方向情况）</p>
<h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><h3 id="从数据库中采样Ground-Truths"><a href="#从数据库中采样Ground-Truths" class="headerlink" title="从数据库中采样Ground Truths"></a>从数据库中采样Ground Truths</h3><ol>
<li>从训练数据集生成一个包含所有Ground Truths及其相关点云数据（ground truths的三维box中所有点）</li>
<li>从数据库中随机选中几个ground truths，通过串联方式引入当前训练的点云中（可以增加训练中ground truths点的数量，以模拟不同环境中的物体）</li>
<li>进行碰撞测试，删除任何与其他物体碰撞的采样对象</li>
</ol>
<h3 id="目标噪音"><a href="#目标噪音" class="headerlink" title="目标噪音"></a>目标噪音</h3><p>作者使用voxelNet方法对每个ground truth与其中点云独立、随机的进行转变。</p>
<h3 id="全局旋转和放缩"><a href="#全局旋转和放缩" class="headerlink" title="全局旋转和放缩"></a>全局旋转和放缩</h3><p>作者对全部点云以及所有ground truth box进行全局放缩和旋转。从[0.95,1.05]的均匀分布提取局部噪音，从[-Π&#x2F;4,Π&#x2F;4]提取全局噪音</p>
<h2 id="网络细节"><a href="#网络细节" class="headerlink" title="网络细节"></a>网络细节</h2><p>作者使用一大一小两个网络，在摄像机视野外的点被舍弃。</p>
<h3 id="汽车检测任务"><a href="#汽车检测任务" class="headerlink" title="汽车检测任务"></a>汽车检测任务</h3><p>在SECOND中使用两个VFE层，即大型网络的VFE(32)和VFE(128)，较小的网络的VFE(32)和VFE(64)，在线性(128)层之后。因此，输出稀疏张量的维数对于大型网络为128  × 10 × 400 × 352，对于小型网络为128 × 10 × 320 ×  264。然后，我们使用两阶段稀疏CNN进行特征提取和降维。每个卷积层遵循一个BatchNorm层和一个ReLU层。所有稀疏卷积层都有一个64-output  feature map，核大小为(3,1,1)核大小，stride为(2,1,1)。对于大型网络，中间块的输出维数为64 × 2 × 400 ×  352。一旦输出被重塑为128 × 400 × 352，就可以应用RPN网络。我们使用Conv2D(cout, k,  s)来表示con2d - batchnorm - relu层，使用DeConv2D(cout, k, s)来表示DeConv2D- batchnorm -  relu层，其中cout为输出通道数，k为内核大小，s为stride。因为所有层在所有维度上都有相同的大小，所以我们对k和s使用标量值。所有Conv2D层都有相同的填充，所有DeConv2D层都有零填充。在我们的RPN的第一阶段，应用了三个Conv2D(128,  3,1(2))层。然后，在第二阶段和第三阶段分别应用5个Conv2D(128, 3, 1(2))层和5个Conv2D(256, 3,  1(2))层。在每一阶段中，只有第一卷积层的s &#x3D; 2;否则，s &#x3D; 1。我们对每个阶段的最后一次卷积应用一个单一的DeConv2D(128, 3,  s)层，三个阶段的s依次为1、2和4。</p>
<p><img src="/%5Cimages%5Cimage-20220112220946220.png" alt="image-20220112220946220"></p>
<h3 id="行人和骑自行车者检测任务"><a href="#行人和骑自行车者检测任务" class="headerlink" title="行人和骑自行车者检测任务"></a>行人和骑自行车者检测任务</h3><p>与汽车检测方面唯一的区别是RPN中第一个卷积层的步幅为1而不是2。</p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p>在KITTI的验证集上，该网络无论大小网络都具有极高的平均准确度，以及极快的处理速度。同时该网络的角度编码速度、收敛速度也是非常快的。</p>
<p><img src="/%5Cimages%5Cimage-20220112222654032.png" alt="image-20220112222654032"></p>
<h3 id="汽车检测任务-1"><a href="#汽车检测任务-1" class="headerlink" title="汽车检测任务"></a>汽车检测任务</h3><p>该网络在检测汽车时展示出了极强的性能，尤其是该网络可以有效的检测被遮挡的汽车。但是对于获得数据量较少的汽车任然无法做到准确检测，尤其是对于<strong>点数小于10的车辆</strong></p>
<h3 id="行人和骑自行车者检测任务-1"><a href="#行人和骑自行车者检测任务-1" class="headerlink" title="行人和骑自行车者检测任务"></a>行人和骑自行车者检测任务</h3><p>对行人和自行车的检测出现了更多的<strong>假阳性与假阴性</strong>，一些预测甚至出现在不合理的位置。这些问题可能归因于行人和自行车的实例包含的点更少，<strong>容易与其他点或是噪音混淆</strong>。此外，行人和自行车数量相对较少，导致包含他们的voxel数量较少，训练效果也就较差。过滤不相关信息并基于二维检测结果确定目标位置，应该会解决这个问题。</p>
<h1 id="做出的贡献"><a href="#做出的贡献" class="headerlink" title="做出的贡献"></a>做出的贡献</h1><ol>
<li>将稀疏卷积应用于基于激光雷达的目标检测</li>
<li>提出了一种改进的稀疏卷积方法，显著提升训练与推理的速度</li>
<li>引入一种新的<strong>角度损失回归</strong>方法</li>
<li>，提高收敛速度和性能</li>
</ol>
]]></content>
      <tags>
        <tag>deep learning</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统</title>
    <url>/2022/03/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>操作系统是对计算机资源进行管理的软件</p>
<span id="more"></span>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><ul>
<li><p>操作系统的基本特征：并发、共享、虚拟、异步</p>
</li>
<li><p>操作系统是对计算机资源进行管理的软件（处理机管理、存储器管理、文件管理、设备管理）</p>
</li>
<li><p>分布式操作系统是以实现并行任务分配、并行进程通信、分布控制机构以及实现分散资源管理等功能为目的的系统程序。</p>
</li>
<li><p>网络操作系统是以资源共享和信息交换为目的的操作系统。</p>
</li>
<li><p>分布式操作系统是以计算机网络为基础构成的一个独立的整体，其更突出协同性，它对用户来说是透明的。</p>
</li>
<li><p>分布式操作系统相比网络操作系统本质不同在于：分布式操作系统中若干计算机相互协同完成同一任务</p>
</li>
<li><p>单处理机系统中，处理机与设备、处理机与通道、设备与设备都可以并行执行，但进程与进程不能并行执行</p>
</li>
<li><p>操作系统与用户通信接口不包括缓存管理指令（系统中的缓存全部由操作系统管理，对用户透明，因此不提供管理系统缓存的系统调用）</p>
</li>
</ul>
<blockquote>
<p> 库函数与系统调用</p>
<p> 1.库函数是语言或应用程序的一部分，可以运行在用户空间中。</p>
<p> 2.系统调用是操作系统的一部分，运行在内核空间。</p>
<p> 3.未使用系统调用的库函数，其执行效率比系统调用高（设计上下文切换、状态转换）</p>
</blockquote>
<ul>
<li><p>实时系统的进程调度，通常采用抢占式优先级算法</p>
</li>
<li><p>linux是多任务、多用户的操作系统，因此允许多个用户同时登陆（多用户）、并且允许多个用户端通过一个账号登陆（多任务）</p>
</li>
<li><p>UNIX是多任务、多用户操作系统，支持多种处理器架构，属于分时操作系统</p>
</li>
<li><p>内核：时钟管理、中断处理、进程管理、设备管理</p>
</li>
<li><p>微内核结构设计不会让系统更高效；能够有效支持多处理级运行，非常适合于分布式系统环境</p>
</li>
<li><p>模块化OS结构原则：分解和模块化</p>
</li>
<li><p>多道程序系统的四个特征：并发、共享、虚拟、异步</p>
</li>
</ul>
<h2 id="微内核"><a href="#微内核" class="headerlink" title="微内核"></a>微内核</h2><p>微内核需要频繁在核心态用户态间切换，开销较大</p>
<p>特点：内核足够小；给予C&#x2F;S模式；“机智与策略分离”原理；面向对象技术</p>
<p>功能：进程间通信；低级IO；低级进程管理和调度；中断和陷入处理</p>
<p>Windows是宏内核操作系统</p>
<p>添加系统服务时不用修改内核</p>
<h2 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h2><ul>
<li><p>用户程序通过执行陷入指令（访管指令或trap指令）来发起系统调用，请求操作系统提供服务</p>
</li>
<li><p>中断向量地址是中断服务例行程序的入口地址的地址</p>
</li>
<li><p>CPU处于核心态时，可以执行除了访管指令外的所有指令</p>
</li>
<li><p>访管指令在用户态使用，将程序运行由用户态转换为核心态的指令</p>
</li>
<li><p>用户程序在用户态下使用特权指令引起的中断为访管中断</p>
</li>
<li><p>内部异常检测通常由CPU内部逻辑实现</p>
</li>
<li><p>内部异常通常是CPU执行指令内部的实践，如程序非法操作码、地址越界、算术溢出、虚存系统缺页以及专门的陷入指令</p>
</li>
<li><p>内部异常不能被屏蔽，响应发生在指令执行的过程中</p>
</li>
<li><p>产生内部异常后，对于非法指令、除数为0等异常，无法通过异常处理程序恢复故障的，必须终止进程的执行</p>
</li>
<li><p>处理外部中断时，操作系统（中断服务程序）保存通用寄存器的内容（硬件保护PC值，并找到该中断信号对应的中断向量），保护中断屏蔽字，保护PSW，提供中断服务</p>
</li>
<li><p>子程序调用只需要保存PC值</p>
</li>
<li><p>时钟中断主要工作是处理和时间有关的信息（系统时间、进程时间片、使用CPU时间、各种定时器）及决定是否执行调度程序</p>
</li>
<li><p>用户态转换为核心态的唯一途径：中断或异常（访管指令通过产生一个中断事件切换状态）</p>
</li>
<li><p>缺页产生后，在用户态发生缺页中断，然后进入核心态执行缺页中断服务程序</p>
</li>
<li><p>异常或是中断的产生于现在CPU为用户态还是核心态无关，只看中断是由指令执行时产生还是外部产生</p>
</li>
<li><p>从内存取数和把运算结果放入内存的指令在用户态执行</p>
</li>
<li><p>输入&#x2F;输出指令需要使用IO设备，涉及资源使用，有可能影响其他进程及危害⚠️计算机，所以不能在用户态执行</p>
</li>
<li><p>系统调用：用户程序通过执行陷入指令来发起系统调用，请求操作系统提供服务；操作系统内核程序对系统调用做出相应处理；处理完成后，操作系统内核程序把CPU使用权还给用户程序</p>
</li>
</ul>
<h2 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h2><p>管道是一种特殊的文件，本质上是一种固定大小的缓冲区，且只存在于内存中。一个管道可以实现双向的数据传输，而同一时刻最多有一个方向的传输，不能两个方向同时进行。当管道满时，进程在写管道会被阻塞；当管道空时，进程在读管道会被阻塞</p>
<p> 分层</p>
<ul>
<li><p>第0层为硬件、第N层为用户接口</p>
</li>
<li><p>每一层利用低一层提供的接口为高一层提供服务</p>
</li>
</ul>
<h2 id="模块（可加载内核模块）"><a href="#模块（可加载内核模块）" class="headerlink" title="模块（可加载内核模块）"></a>模块（可加载内核模块）</h2><ul>
<li>内核提供核心服务，其他服务通过模块链入服务</li>
</ul>
<h2 id="操作系统引导"><a href="#操作系统引导" class="headerlink" title="操作系统引导"></a>操作系统引导</h2><ul>
<li>操作系统的生成与配置需要获取计算机硬件系统的特定配置</li>
</ul>
<ol>
<li><p>完全定制（系统管理员修改操作系统源代码副本，重新编译操作系统）</p>
</li>
<li><p>系统描述创建表，并从预先已编译的库中选择模块。将这些模块链接起来生成操作系统</p>
</li>
<li><p>构造完全由表驱动的系统，在执行时动态选择相应的代码模块。系统生成只是创建适当的表</p>
</li>
</ol>
<ul>
<li><p>系统引导：加载内核以启动计算机的过程（通过一个简单的引导程序（ROM）从磁盘掉入更复杂的引导程序，后者再加载内核到内存）</p>
</li>
<li><p>计算机启动过程：CPU加电；跳转到BIOS；登记BIOS中断例程入口地址；硬件自检；进行操作系统引导</p>
</li>
</ul>
<h2 id="虚拟机"><a href="#虚拟机" class="headerlink" title="虚拟机"></a>虚拟机</h2><p><img src="/%5Cimages/clip_image008.gif" alt="图像"></p>
<p>单个计算机的硬件抽象为几个不同的执行部件，通过CPU调度与虚拟内存技术，使进程认为自己拥有独立的处理器与内存</p>
<p>实现方法：提供虚拟磁盘，为用户提供与底层机器完全一样的副本。用户在自己的虚拟机中运行机器上拥有的任何操作系统ISO或软件</p>
<p>虚拟机只能运行在用户态，虚拟机内部也有用户态与内核态</p>
<p>可以用硬件实现也可以用软件实现</p>
<h1 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h1><ul>
<li><p>PCB是进程存在的唯一标志</p>
</li>
<li><p>进程映像：程序段、相关数据段、PCB（静态概念）</p>
</li>
<li><p>线程是程序执行流的最小单元，是系统独立调度和分派的基本单元（处理机的分配单元）；进程是除CPU资源以外的系统资源的分配单元（线程不占有系统资源）</p>
</li>
<li><p>进程间通信（IPC）需要进程同步和互斥，以保证数据一致性；线程间通过直接读写数据段（全局变量）来通信</p>
</li>
<li><p>引入线程可以提升程序并发执行的程度，可进一步提高系统效率。</p>
</li>
<li><p>线程不可以脱离进程独立运行</p>
</li>
</ul>
<p><strong>1.</strong>     c语言中全局赋值变量存放在正文段</p>
<p><strong>2.</strong>    未赋值局部变量存放在栈段</p>
<p><strong>3.</strong>    函数调用实参传递值存放在栈段</p>
<p><strong>4.</strong>    用malloc()要求动态分配的存储区在堆段</p>
<p><strong>5.</strong>    常量值存放在正文段</p>
<p><strong>6.</strong>    进程优先级存放在PCB</p>
<ul>
<li><p>并发进程失去封闭性指：并发进程共享变量，其执行结果与速度有关（不同速度下执行结果不同）</p>
</li>
<li><p>程序代码经过多次创建可对应不同的进程，而同一个系统的进程（线程）可以由系统调用的方法被不同进程（线程）多次使用（而不会为每次调用创建新的系统线程）</p>
</li>
<li><p>父子进程可以共享一部分资源，但不能共享虚拟地址空间</p>
</li>
<li><p>进程间通信一定会共享某些资源：共享存储器系统，共享存储器资源；消息传递系统，共享消息文件；管道通信，共享管道文件</p>
</li>
<li><p>共享内存系统需要通信进程建立共享内存区域（通常驻留在创建共享内存段的进程地址空间中，其他希望使用这个共享内存段进行通信的进程应该将其加入自己的地址空间）</p>
</li>
<li><p>管道是半双工工作，将数据以字节流的形式写入管道。管道（缓冲区）满时，写进程被阻塞；管道空时，读进程被阻塞</p>
</li>
<li><p>中期调度：将暂时不运行的进程调至外存等待（挂起态），降低多道程序程度</p>
</li>
</ul>
<blockquote>
<p>不能进行进程调度与切换的情况</p>
<ol>
<li><p>处理中断(中断处理属于系统工作的一部分，逻辑上不属于某一个进程)</p>
</li>
<li><p>进程在操作系统内核程序临界区（加锁）</p>
</li>
<li><p>其他需要完全屏蔽中断的原子操作</p>
</li>
</ol>
</blockquote>
<ul>
<li><p>FCFS对长作业有利，适合CPU繁忙型作业</p>
</li>
<li><p>SJF对长作业不利，会导致饥饿</p>
</li>
<li><p>分时系统时间片固定，因此用户数越多，响应时间越长</p>
</li>
<li><p>高响应比优先调度不适用于交互式操作系统，高响应比调度需要知道作业预计运行时间，但是作业在交互式情况下，预计运行时间是不确定的，因此计算不出响应比</p>
</li>
<li><p>对于多道程序来说，内存中最多存放n道作业，即处于就绪态、运行态、等待态的作业个数之和最多为n（处于运行态的作业，其程序代码段、数据段都在内存中，在内存视角中与其他内存中作业无异）</p>
</li>
<li><p>阻塞队列中进程的个数最多为n个</p>
</li>
<li><p>唤醒原语是将进程从阻塞态转变为就绪态，需要一个与被唤醒进程合作或被其他相关进程调用实现的</p>
</li>
</ul>
<h2 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h2><p>硬件实现中使用TSL指令实现进程互斥的伪代码如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">do</span>&#123;<span class="comment">//  该实现下，等待进入临界区的进程不会主动放弃CPU，不满足&quot;让权等待&quot;原则</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">while</span>(TSL(&amp;lock));<span class="comment">//忙等待</span></span><br><span class="line"></span><br><span class="line">	critical section <span class="comment">//临界区</span></span><br><span class="line"></span><br><span class="line">	lock = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">&#125;<span class="keyword">while</span>(<span class="literal">true</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>信号量的同步（原子性）是由硬件支持，PV操作也有临界区</li>
</ul>
<blockquote>
<p>wait() 、signal()操作没有完全取消忙等，只是将忙等由整个临界区（无法控制、可能很长，或者总是被占用）转移到了PV操作的临界区上（该临界区经过合理编码，不会超过10条指令，因此忙等很少发生，临界区几乎不被占用）</p>
</blockquote>
<ul>
<li><p>PV操作是一种低级进程通信原语</p>
</li>
<li><p>PV操作时需要根据用户需要自行确定信号量初始值</p>
</li>
</ul>
<h2 id="管程"><a href="#管程" class="headerlink" title="管程"></a>管程</h2><ul>
<li><p>管程是进程同步工具，解决信号量机制大量同步操作分散的问题</p>
</li>
<li><p>管程是被进程调用的，管程是语法范围，无法创建和撤销</p>
</li>
<li><p>管程把对共享资源的操作封装起来</p>
</li>
<li><p>每次仅允许一个进程进入管程</p>
</li>
<li><p>管程使用条件变量condition定义为阻塞原因，不同阻塞原因对于相应条件变量</p>
</li>
<li><p>管程中的signal操作的作用和信号量机制中的V操作不完全相同，signal操作唤醒一个因x条件而阻塞的进程；wait操作会阻塞该进程（x对应的条件不满足时调用）</p>
</li>
<li><p>条件变量没有值，仅实现排队等待功能；信号量有值，反映剩余资源数</p>
</li>
<li><p>管程使用共享数据结构记录剩余资源数</p>
</li>
</ul>
<h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><blockquote>
<p>死锁定理（在资源分配图中检测系统状态是否为死锁状态）：</p>
<p>将资源分配图中既不阻塞又不独立的进程逐个删去。如果能够消去图中所有的边，则不存在死锁    </p>
<p>资源分配方法</p>
<ol>
<li><p>静态分配：执行前获得所有资源</p>
</li>
<li><p>按序分配：进程提出申请分配资源<img src="/%5Cimages/clip_image014.gif" alt="img">后，其他进程只能申请编号大于<img src="/%5Cimages/clip_image016.gif" alt="img">的资源</p>
</li>
<li><p>银行家算法</p>
</li>
</ol>
</blockquote>
<ul>
<li><p>当系统处于不安全状态时，不会立即进入死锁状态。只有所有进程均因申请资源没有得到满足而进入阻塞态，系统才进入死锁状态</p>
</li>
<li><p>在死锁检测的进程-资源图中，如果申请边的申请得到满足，则删去申请边，添加从资源到进程的分配边</p>
</li>
<li><p>银行家算法进行安全🔐序列检查时，不需要的参数是满足系统安全的最少资源数</p>
</li>
</ul>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><p>🔒的本质在内存中的一个整形数，不同数值表示不同状态</p>
<h3 id="锁的分类"><a href="#锁的分类" class="headerlink" title="锁的分类"></a>锁的分类</h3><p>I.    重量级锁：得到锁就加锁，得不到锁立即进入阻塞状态</p>
<p>II.   自适应自旋锁：根据线程最近获得锁的状态来调整循环次数的自旋锁</p>
<p>III.  轻量级锁：进入方法时不加锁，只做一个标志（有人在执行），CAS机制</p>
<p>IV.  偏向锁：没必要加锁，大部分时候只有一个线程在执行该方法</p>
<p>V.   悲观锁：不加锁就会出事，重量级锁、自旋锁、自适应自旋锁</p>
<p>VI.  乐观锁：不加锁，当出现冲突时再想办法解决，CAS机制</p>
<p>VII. 互斥锁（互斥锁）：Barkey锁（对进程编号）、Perterson锁；常用于多处理器系统，等待期间不用切换进程上下文，只有等到时间片用完才下处理级（违反“让权等待”）</p>
<h3 id="条件变量"><a href="#条件变量" class="headerlink" title="条件变量"></a>条件变量</h3><ol>
<li><p>等待队列</p>
</li>
<li><p>条件变量没有值，只有队列</p>
</li>
<li><p>对条件变量操作：wait&#x2F;signal</p>
</li>
<li><p>signal操作时如果一个条件变量上没有等待进程，则signal操作无效</p>
</li>
<li><p>常和锁共同使用（锁实现互斥、配合条件变量实现同步）</p>
</li>
<li></li>
</ol>
<h2 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h2><p>线程的状态与转换与进程的状态基本一致 </p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td><img src="/%5Cimages/clip_image006.gif" alt="图像"></td>
</tr>
</tbody></table>
<h3 id="线程的组织与控制（TCB）"><a href="#线程的组织与控制（TCB）" class="headerlink" title="线程的组织与控制（TCB）"></a>线程的组织与控制（TCB）</h3><p>保存程序计数器PC其他寄存器与线程的堆栈指针</p>
<p>对于不支持内核级线程的操作系统，调度程序处理的对象是进程（进程内的线程由线程库管理）；支持内核级线程的操作系统，调度程序处理对象是内核级线程</p>
<h3 id="用户级线程、内核级线程"><a href="#用户级线程、内核级线程" class="headerlink" title="用户级线程、内核级线程"></a>用户级线程、内核级线程</h3><ol>
<li><p>用户级线程由线程库管理用户线程</p>
</li>
<li><p>用户级线程的调度：代价低，不需要切换完整的上下文；一个线程阻塞整个进程阻塞</p>
</li>
<li><p>内核级线程的调度：代价高，需要切换到内核态，切换完整上下文；一个线程阻塞。其他线程仍可以运行</p>
</li>
</ol>
<h3 id="闲逛进程"><a href="#闲逛进程" class="headerlink" title="闲逛进程"></a>闲逛进程</h3><ol>
<li><p>没有其他就绪进程时，执行闲逛进程</p>
</li>
<li><p>优先级最低</p>
</li>
<li><p>可以是0地址指令，占一个完整的指令周期（指令周期末尾例行检查中断）</p>
</li>
<li><p>能耗低</p>
</li>
</ol>
<h2 id="进程上下文"><a href="#进程上下文" class="headerlink" title="进程上下文"></a>进程上下文</h2><h3 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h3><ul>
<li><p>进程上下文通常用PCB表示，包括CPU寄存器的值、进程状态等</p>
</li>
<li><p>切换CPU到另一个进程需要保存当前进程状态和恢复另一个进程的状态</p>
</li>
</ul>
<h4 id="切换进程"><a href="#切换进程" class="headerlink" title="切换进程"></a>切换进程</h4><ol>
<li><p>需要保存地址空间（页表寄存器）</p>
</li>
<li><p>TLB全部失效</p>
</li>
<li><p>Cache全部失效</p>
</li>
<li><p>新进程运行初期切页率可能高</p>
</li>
</ol>
<h4 id="切换线程"><a href="#切换线程" class="headerlink" title="切换线程"></a>切换线程</h4><p>需要保存程序计数器、寄存器、堆栈</p>
<h1 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h1><ul>
<li><p>存储管理是为了方便用户以及提高内存利用率</p>
</li>
<li><p>页表寄存器存放的是顶级页表的起始物理地址</p>
</li>
<li><p>页式存储方式只能采用动态重定位</p>
</li>
<li><p>空间、时间局部性良好的数据结构和技术适用于虚拟存储系统（数据常在一页中）</p>
</li>
<li><p>虚拟存储器中，程序正在执行时，由操作系统完成地址映射；硬件完成Cache映射</p>
</li>
<li><p>页表应该包含作业页号、状态位、存取方式（执行、读&#x2F;写）、外存页号、内存页号、修改位等</p>
</li>
<li><p>进程在地址变换的过程中，可能因为地址越界而被撤销、也可能因为缺页而被阻塞</p>
</li>
<li><p>处理缺页中断时，会更新TLB表与页表</p>
</li>
<li><p>内存泄露：当以前分配的一片内存不再需要使用或无法访问时，但是并没有释放它，那么对于该进程来说，会因此导致总可用内存的减少，这时就出现了内存泄漏。</p>
</li>
<li><p>内存越界访问：简单地说，进程访问了不属于该进程的内存空间</p>
</li>
</ul>
<h2 id="C语言编译"><a href="#C语言编译" class="headerlink" title="C语言编译"></a>C语言编译</h2><ul>
<li><p>过程中，形成逻辑地址的阶段是链接（将各个目标模块的逻辑地址重定位，形成完整的逻辑地址）</p>
</li>
<li><p>编译阶段形成各个目标模块的独立的逻辑地址（从0开始）</p>
</li>
<li><p>将逻辑地址转换为物理地址的阶段是装载阶段 </p>
</li>
<li><p>使用交换技术时，若一个进程处于IO操作，则不能交换出主存（处于创建、临界区、死锁时都可以）</p>
</li>
<li><p>一个进程中段表只能有一个，页表可以有多个（每个分段对应一个页表）</p>
</li>
<li><p>内存保护完全由硬件完成（重定位寄存器、界地址寄存器）</p>
</li>
<li><p>操作系统通过内存保护实现多进程在主存中彼此互不干扰的环境下运行</p>
</li>
<li><p>分页系统中的页面是为操作系统感知的（由操作系统管理）</p>
</li>
<li><p>整个系统中只有一个重定位寄存器，在切换进程时重制寄存器的内容</p>
</li>
<li><p>使用最佳适应算法、最差适应算法管理动态分区内存时，在每次分配与回收内存后，都会对空闲分区链进行重新排序，按空闲内存大小由小到大排序</p>
</li>
<li><p>操作系统采用分页式存储管理方式时，每个进程拥有一张页表，且进程的页表驻留在内存中（进程使用多级页表时，一开始只将一级页表掉入内存）</p>
</li>
<li><p>多级页表中，要使用几级页表，需要看虚拟地址中虚拟页号的位数</p>
</li>
<li><p>多级页表可以减少页表所占连续内存空间，但增加页表项所占字节数，减慢地址变换速度（多次访存）</p>
</li>
<li><p>在分段存储管理系统中，用共享段表描述所有被共享的段。若进程<img src="/%5Cimages/clip_image018.gif" alt="img">共享段S，则在物理内存中仅保留一份段S的内容；段S在<img src="/%5Cimages/clip_image018.gif" alt="img">中具有相同的段号；<img src="/%5Cimages/clip_image018.gif" alt="img">都不使用段S时才回收段S段内存空间。</p>
</li>
<li><p>虚拟存储只能基于非连续分配技术</p>
</li>
<li><p>虚拟存储的容量<img src="/%5Cimages/clip_image020.gif" alt="img">内存容量+外存容量</p>
</li>
<li><p>虚拟存储的容量<img src="/%5Cimages/clip_image020.gif" alt="img">计算机的地址位数能容纳的最大容量（虚拟存储容量受上式两个条件的制约）</p>
</li>
<li><p>处理缺页错误时，操作系统执行置换页、分配内容等。但❌不会处理越界错误（地址变换前期由硬件检测）</p>
</li>
<li><p>LRU算法实现耗费高的原因：需要对所有页进行排序</p>
</li>
<li><p>使用覆盖、交换可以实现虚拟存储</p>
</li>
<li><p>覆盖技术用于同一个进程、交换技术用于不同进程</p>
</li>
<li><p>产生内存抖动的主要原因是页面置换算法不合理</p>
</li>
<li><p>在多级页表中，快表存放的是完整的页面号，而非某一级的页面号，因此快表命中即可到达物理地址</p>
</li>
<li><p>当进行缺页处理需要置换页时，旧页的物理地址给新页用来写入数据（即物理地址不变）</p>
</li>
<li><p>最高级页表项不能超过一页的大小</p>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td><img src="/%5Cimages/clip_image022.gif" alt="图像"></td>
</tr>
</tbody></table>
<h2 id="页面分配策略"><a href="#页面分配策略" class="headerlink" title="页面分配策略"></a>页面分配策略</h2><ul>
<li><p>固定分配局部置换：每个进程分配固定数量的物理块，运行期间不会改变，发生缺页时，调出该进程分配的页帧</p>
</li>
<li><p>可变分配全局置换：操作系统自身维护一个空闲物理块队列，进程发生缺页时，系统从空闲物理块队列中取出一个物理块分配给该进程，但进程不会自动归还物理块</p>
</li>
<li><p>可变分配局部置换：发生缺页时，只能从该进程已分配的页帧中选择调出，若进程频繁缺页，系统会增加若干物理块；若进程缺页率低，系统适当减少分配的物理块</p>
</li>
</ul>
<h3 id="CLOCK算法"><a href="#CLOCK算法" class="headerlink" title="CLOCK算法"></a>CLOCK算法</h3><p><img src="/%5Cimages/clip_image024.gif" alt="图像"></p>
<p>调入一页则将指针向后移动一块，若命中则不移动指针</p>
<p>注意：若循环链表存在当前访问页时（访问页在某物理块中），直接将其访问位改为1，指针p不移动（命中后指针不移动）；</p>
<p>否则，若当前p指针指向页面的访问位为0，则淘汰该页，调入新页，将其访问位改为 1，指针p移到下一个物理块：若当前p指针指向页面的访问位为1，则将其访问位改为 0，并移动口指针到下一个物理块。</p>
<h3 id="改进型CLOCK算法（使用位u、修改位m）"><a href="#改进型CLOCK算法（使用位u、修改位m）" class="headerlink" title="改进型CLOCK算法（使用位u、修改位m）"></a>改进型CLOCK算法（使用位u、修改位m）</h3><ol>
<li><p>从当前位置开始，扫描帧缓冲区，不修改使用位，寻找（u&#x3D;0，m&#x3D;0）的帧</p>
</li>
<li><p>重新扫描，寻找（u&#x3D;0，m&#x3D;1）的帧，将不符合的帧的使用位u改为0.</p>
</li>
<li><p>重复1、2步</p>
</li>
</ol>
<h2 id="内存共享"><a href="#内存共享" class="headerlink" title="内存共享"></a>内存共享</h2><p>内存共享通过内存映射实现，将多个进程的虚拟地址空间映射到同一片物理地址（可以是“页”映射，也可以是“段”映射）</p>
<p>内存映射文件</p>
<p>将文件页映射到进程页表，进程按内存访问方式读写文件；还可以实现文件共享<img src="/%5Cimages/clip_image010.gif" alt="图像"></p>
<h1 id="文件管理"><a href="#文件管理" class="headerlink" title="文件管理"></a>文件管理</h1><ul>
<li><p>操作系统采用两级内部表记录文件信息，即：每个进程表和整个系统表。</p>
</li>
<li><p>每个进程表跟踪它打开的所有文件，保存进程对文件的使用记录。如：当前文件指针，文件访问权限</p>
</li>
<li><p>单个进程表的每个条目相应的指向整个系统的打开表。</p>
</li>
<li><p>系统表包含与进程无关的信息，包括每个打开文件的FCB的副本及其它信息</p>
</li>
<li><p>文件控制块（FCB）由逻辑文件系统操作，维护文件的相关信息（一个FCB就是一个文件目录项）</p>
</li>
<li><p>文件目录即为文件控制块的有序集合</p>
</li>
<li><p><img src="/%5Cimages/clip_image026.jpg" alt="图像"></p>
</li>
<li><p>创建一个新文件后，系统将分配一个FCB并存放在文件的目录中</p>
</li>
<li><p>FCB必须连续存放</p>
</li>
<li><p>索引节点存放在磁盘中，由文件目录项中的指针指向</p>
</li>
<li><p>索引节点是一块存储文件原信息的磁盘空间为了，为inode。</p>
</li>
<li><p>普通文件由目录块里的一个FCB加上多个数据块组成</p>
</li>
<li><p>目录文件由目录块里的一个FCB加上多个其他多个目录块组成</p>
</li>
<li><p>一个索引节点只能被一个文件（无论是目录文件，还是普通文件）所用，不能同时被其他文件所用。</p>
</li>
</ul>
<blockquote>
<p>执行一条open指令的工作过程:</p>
<p>open指令先根据文件路径找到相应的目录文件（对于目录文件的查找与其他文件查找方式相同），根据目录文件的数据找到文件的目录项。为了增加检索文件时的效率，文件目录中的目录项只记录文件名以及一个指向索引结点的指针，找到该文件后再根据指针找到索引结点，读出该文件的物理地址。文件被打开后，磁盘索引结点（目录）被复制到内存索引结点。对索引结点添加count字段后支持文件的硬链接。</p>
</blockquote>
<ul>
<li><p>文件系统采用多级目录结构的目的：解决命名冲突</p>
</li>
<li><p>逻辑记录是对文件进行存取操作的基本单位</p>
</li>
<li><p>在物理存储器中，文件数据（文件区）与文件控制信息（目录区）分离存储</p>
</li>
<li><p>文件是逻辑记录的一个序列，逻辑记录可以是字节、行或更为复杂的数据项</p>
</li>
<li><p>索引节点的总数表示系统中可拥有文件的最大数量</p>
</li>
</ul>
<h2 id="软链接、硬链接"><a href="#软链接、硬链接" class="headerlink" title="软链接、硬链接"></a>软链接、硬链接</h2><p><img src="/%5Cimages/clip_image028.gif" alt="成组"></p>
<p><img src="/%5Cimages/clip_image030.jpg" alt="图像"></p>
<ul>
<li><p>linux下创建目录后，文件链接数2.因为目录中有上一级目录与当前目录，在该目录中每新加一个文件就会增加目录的链接数</p>
</li>
<li><p>建立符号链接时，引用计数值直接复制；建立硬链接时，引用计数值+1（引用计数值存放在索引节点中，即不在文件目录中）</p>
</li>
<li><p>硬链接通过索引结点进行连接，一个文件在物理存储器上有一个索引结点号。存在多个文件名指向同一个索引结点。共享文件的不同进程各自维护自己的文件描述符（记录进程的读写指针位置）。</p>
</li>
<li><p>软链接可以在目录与文件链接时使用、及其网络文件</p>
</li>
<li><p>多个进程共享一个文件F，则在系统打开表中仅有一个表项包含F的属性（硬链接直接使用指针与索引节点相连；软链接会新建一个链接文件）</p>
</li>
<li><p>访问控制机制必须由系统实现，而且安全性较差，灵活性较强</p>
</li>
<li><p>对一个文件的访问，常由用户访问权限和文件属性共同限制🚫</p>
</li>
<li><p>常使用备份方法保护文件</p>
</li>
<li><p>存取控制矩阵用于多用户间的存取权限保护</p>
</li>
<li><p>将用户访问权限抽象为矩阵，行代表用户；列代表权限</p>
</li>
<li><p>FAT（文件配置表）表项与全部磁盘块一一对应，索引分配将整个文件的盘块号集中构成索引块</p>
</li>
<li><p>链接分配不适合直接存取的外存分配方式</p>
</li>
<li><p>为支持CD-ROM中视频文件的快速播放，播放性能最好的文件数据块组织形式为连续结构</p>
</li>
<li><p>文件系统为每个文件创建一张索引表，存放文件数据块的磁盘存放位置</p>
</li>
<li><p>在FAT中第i项存放第i项的下一项的项号</p>
</li>
<li><p>光盘、U盘、磁盘既可以随机访问又可以顺序</p>
</li>
<li><p>索引顺序文件既可以顺序访问又可以随机访问</p>
</li>
</ul>
<h2 id="虚拟文件系统"><a href="#虚拟文件系统" class="headerlink" title="虚拟文件系统"></a>虚拟文件系统</h2><p><img src="/%5Cimages/clip_image012.gif" alt="图像"></p>
<p>采用面向对象技术（多态技术）同时支持多种类型的文件系统</p>
<ol>
<li><p>提供清晰的VFS接口，将文件系统的通用操作与实现分开，屏蔽底层具体文件系统的实现差异</p>
</li>
<li><p>VFS要求下层文件系统必须实现某些规定的函数功能，一个新的文件系统想要在操作系统上被使用，就必须满足该操作系统的VFS要求</p>
</li>
<li><p>调用open后，VFS将具体文件系统传来的不同的FCB统一转换为vnode（vnode只存在于主存）</p>
</li>
<li><p>函数功能指针：记录对于的文件系统提供的函数</p>
</li>
<li><p>唯一的表示网络上的文件</p>
</li>
</ol>
<h3 id="VFS四个对象"><a href="#VFS四个对象" class="headerlink" title="VFS四个对象"></a>VFS四个对象</h3><p>A.   超级块：一个超级块对应一个文件系统</p>
<p>B.   索引结点inode：保存元数据（文件大小、设备标识符、指向该内容的磁盘区块指针等）</p>
<p>C.  目录项：描述文件的逻辑属性，只存在内存中。目录也是一种文件</p>
<p>D.  文件对象：进程通过文件描述符操作文件</p>
<p>数据有元数据+数据本身</p>
<p>inode也有两种：VFS的inode（内存中）、具体文件系统的inode磁盘中。需要将磁盘inode调进填充内存中的inode，才能使用磁盘inode</p>
<p>一个文件对应一个inode，inode号唯一</p>
<h2 id="文件系统挂载"><a href="#文件系统挂载" class="headerlink" title="文件系统挂载"></a>文件系统挂载</h2><p>挂载：将新的文件系统关联到当前根文件的文件系统</p>
<p>挂载点：要挂载文件系统的访问入口；挂载点必须事先存在；挂载点下的原有文件被暂时隐藏</p>
<ol>
<li><p>在VFS中注册新挂载的文件系统，内存中的挂载表包含每个文件系统的相关信息，包括文件系统类型、容量大小等</p>
</li>
<li><p>新挂载的文件系统，要向VFS提供一个函数地址列表（函数功能指针）</p>
</li>
<li><p>将新文件系统加到挂载点，即将新文件系统挂载到某个父目录下</p>
</li>
</ol>
<h1 id="IO管理"><a href="#IO管理" class="headerlink" title="IO管理"></a>IO管理</h1><ul>
<li><p>共享设备必须是可寻址可随机访问的设备</p>
</li>
<li><p>分享共享设备不会导致进程死锁</p>
</li>
<li><p>实现的功能有：实现外围设备的分配和回收；实现虚拟设备；实现对磁盘的驱动调度</p>
</li>
<li><p>直接存取存储器（磁盘）既不像RAM那样随机访问任何一个存储单元，又不像顺序存取存储器那样完全顺序存取，而是介于两者之间，存取信息时通常先寻找存储器的某个小区域（磁道），再在小区域内顺序查找。</p>
</li>
</ul>
<h2 id="设备控制器"><a href="#设备控制器" class="headerlink" title="设备控制器"></a>设备控制器</h2><ul>
<li><p>为了便于上层软件编制，设备控制器通常要提供控制寄存器（存放CPU来的控制信号）、状态寄存器（设备来的设备状态信息）和控制命令</p>
</li>
<li><p>设备控制器中实现设备控制的是IO逻辑</p>
</li>
<li><p>通道控制设备控制器、设备控制器控制设备工作</p>
</li>
<li><p>设备控制器需要请求通道为其服务。因此，控制器控制表COCT中定有一个表项存放指向相应通道控制表CHCT的指针</p>
</li>
<li><p>一个通道为多个设备控制器服务。因此，CHCT中有一个指针指向一张记录CHCT提供服务的设备控制器的表（CHCT与COCT是一对多的关系）</p>
</li>
<li><p>通道技术是硬件技术</p>
</li>
<li><p>通道指令保存在主存中，是一系列通道指令</p>
</li>
<li><p>IO设备与存储设备使用DMA方式进行数据交换，不经过CPU来完成</p>
</li>
<li><p>堆栈指针寄存器不属于DMA控制器，内存地址寄存器属于（用来存放DMA作业时的源地址与目标地址）</p>
</li>
<li><p>将系统中的每台设备按照某种原则编号，这些编号作为区分硬件和识别设备的代号，该编号称为设备的绝对号</p>
</li>
<li><p>将系统调用的参数翻译成设备操作命令的工作由设备无关的操作系统软件实现</p>
</li>
<li><p>IO层次组织排列为：用户级IO软件、设备无关软件（系统调用处理程序）、设备驱动程序、中断处理程序</p>
</li>
<li><p>用户下达read指令；设备无关软件对read指令进行解析；设备驱动程序针对设备解析为不同的指令；中断服务程序中断CPU正在运行的进程，执行解析后的read命令；最后命令到达硬件设备，硬件设备控制器按照相应命令操控硬件，完成相应功能</p>
</li>
</ul>
<blockquote>
<p>系统将数据从磁盘读入内存包括：</p>
<ol>
<li><p>初始化DMA控制器并启动磁盘</p>
</li>
<li><p>从磁盘传输一块数据到内存缓冲区</p>
</li>
<li><p>DMA控制器发出中断请求</p>
</li>
<li><p>执行DMA结束中断处理程序</p>
</li>
</ol>
</blockquote>
<ul>
<li><p>设备独立性：用户编程时使用的设备与实际设备无关</p>
</li>
<li><p>磁盘属于共享设备</p>
</li>
<li><p>SPOOLing技术将独占设备变成共享设备，但是只是逻辑上改变。实际设备仍是独占设备</p>
</li>
<li><p>SPOOLing系统由预输入程序、预输出程序、井管理程序组成</p>
</li>
<li><p>使用SPOOLing技术时，用户打印结果首先被送到磁盘的固定区域（输入井中）</p>
</li>
<li><p>SPOOLing技术可以当输出设备忙时，减少进程等待时间，加快作业完成速度</p>
</li>
<li><p>图形用户界面使用鼠标、多任务操作系统下磁带驱动器、包含用户文件的磁盘驱动器、使用存储器映射IO，直接和总线相连的图形卡都需要使用缓冲技术（IO速度不相匹配就需要使用缓冲）</p>
</li>
</ul>
<h2 id="磁盘初始化"><a href="#磁盘初始化" class="headerlink" title="磁盘初始化"></a>磁盘初始化</h2><ul>
<li><p>执行顺序：ROM引导程序、磁盘引导程序、分区引导程序、操作系统初始化程序</p>
</li>
<li><p>物理格式化（低级格式化）：对每个磁道划分扇区，安排扇区在磁道中的排列顺序，并对已损坏的磁道和扇区做“坏”标记</p>
</li>
<li><p>分区：将磁盘分为C盘、D盘等相互独立的分区</p>
</li>
<li><p>进行逻辑格式化（高级格式化）：对扇区进行逻辑编号、建立逻辑盘的引导记录、文件分配表、文件目录表和数据区等，还包括建立文件系统根目录</p>
</li>
<li><p>硬盘的操作系统引导扇区产生在对硬盘进行高级格式化时</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>408</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构</title>
    <url>/2022/03/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<p>算法应该是问题求解步骤的描述</p>
<span id="more"></span>

<h1 id="线性表"><a href="#线性表" class="headerlink" title="线性表"></a>线性表</h1><ul>
<li><p>顺序存储方式适用于图、树、线性表</p>
</li>
<li><p>定义一个顺序表需要包含的数据成员为：数组指针*data、表中元素个数n、表的大小MaxSize2 xde</p>
</li>
<li><p>kmp算法中，next数组看next[j],j，nextval数组中看next[i]（i为本位、j为上一位）</p>
</li>
</ul>
<h1 id="树"><a href="#树" class="headerlink" title="树"></a>树</h1><ul>
<li><p>出现树的题要考虑树是一颗空树</p>
</li>
<li><p>树中结点数等于所有结点的度数之和加1</p>
</li>
<li><p>高度为n个结点的m叉树至多有<img src="/%5Cimages/clip_image006.gif" alt="img">个结点</p>
</li>
<li><p>具有n个结点的m叉树最小高度为<img src="/%5Cimages/clip_image008.gif" alt="img">（向上取整）</p>
</li>
<li><p>非空二叉树上的叶子结点数等于度为2的结点数加1（<img src="/%5Cimages/clip_image010.gif" alt="img">）</p>
</li>
<li><p>具有n个结点的完全二叉树的高度为<img src="/%5Cimages/clip_image012.gif" alt="img">或<img src="/%5Cimages/clip_image014.gif" alt="img"></p>
</li>
<li><p>非空二叉树上第k层至多有<img src="/%5Cimages/clip_image016.gif" alt="img">个结点</p>
</li>
<li><p>高度为h的二叉树至多有<img src="/%5Cimages/clip_image018.gif" alt="img">个结点</p>
</li>
<li><p>完全二叉树中按层次编号，则结点i的双亲为<img src="/%5Cimages/clip_image020.gif" alt="img">，左孩子为2i，右孩子为2i+1，所在层次（深度）为<img src="/%5Cimages/clip_image022.gif" alt="img"></p>
</li>
<li><p>红黑树黑高为h时，内部结点数最少的情况<img src="/%5Cimages/clip_image018.gif" alt="img">，内部结点数最多的情况<img src="/%5Cimages/clip_image024.gif" alt="img"><img src="/%5Cimages/clip_image026.gif" alt="图像画廊"></p>
</li>
<li><p>红黑树上任一查找路径的红结点数量不可能超过一半，但整棵树的红结点总数有可能过半</p>
</li>
<li><p>哈夫曼树的WPL计算过程中：路径长度比结点在树中的高度少1</p>
</li>
</ul>
<h1 id="图"><a href="#图" class="headerlink" title="图"></a>图</h1><ul>
<li><p>当带权连通图的任意一个环中包含的边的权值均不同时，其MST是唯一的</p>
</li>
<li><p>非连通的情况下边最多的情况：n-1个结点构成一个完全图，再任意加一条边变成连通图</p>
</li>
<li><p>一个有n条边n个结点的无向图是有环的</p>
</li>
<li><p>连通无向图边数至少是n-1条</p>
</li>
<li><p>有向图强连通情况下边最少的情况：至少需要n条边构成一个环路</p>
</li>
<li><p>在无向图中常讨论连通性，有向图中讨论强连通性</p>
</li>
<li><p>有向图的邻接表存储中，顶点v在边表中出现的次数是顶点v的入度</p>
</li>
<li><p>AOE图中只有关键路径上的活动同时减少时，才能缩短工期</p>
</li>
<li><p>增加任一关键活动的时间都会延长工程的工期</p>
</li>
<li><p>邻接表在更新边的操作时效率优于邻接矩阵（需要搜索所有结点）</p>
</li>
<li><p>广搜、深搜、拓扑排序、prime算法需要更新结点的边，因此选择邻接表表示图更好</p>
</li>
<li><p>一个单独的顶点也可以构成一个强连通分量</p>
</li>
</ul>
<h1 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h1><ul>
<li><p>折半查找判定树即在根据折半查找的过程构造的二叉树，其中mid的选择可以是向上取整、或是向下取整。但是需要在整个查找过程中保持一个取整方向</p>
</li>
<li><p>B+树适用于关系数据库系统的索引</p>
</li>
<li><p>折半查找的平均查找长度为<img src="/%5Cimages/clip_image028.gif" alt="img">。对折半查找进一步优化，可以使用索引顺序查找（将查找元素分块，为每块建立一个索引项，对索引项和块使用折半查找）</p>
</li>
<li><p>索引块的最佳大小是<img src="/%5Cimages/clip_image030.gif" alt="img"></p>
</li>
<li><p>折半查找的判定树高度为<img src="/%5Cimages/clip_image032.gif" alt="img">（查找不存在的元素进行的关键字比较次数、查找存在元素的最多比较次数）</p>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td><img src="/%5Cimages/clip_image034.gif" alt="图像画廊"></td>
</tr>
</tbody></table>
<ul>
<li><p>B树与B+树内部结点的子树个数<img src="/%5Cimages/clip_image036.gif" alt="img">只是结点所含关键字不同（B树中结点的关键字要比子树少1）</p>
</li>
<li><p>装填因子<img src="/%5Cimages/clip_image038.gif" alt="img">（n：表中记录数，m：散列表长度）</p>
</li>
<li><p>选择排序和归并排序时间性能与初始状态无关</p>
</li>
<li><p><img src="/%5Cimages/clip_image040.gif" alt="img">不表示可以避免碰撞（与散列函数有关）</p>
</li>
<li><p>求散列表的平均查找失败次数时，可能的取值是散列函数的取值范围（mod 7，表示散列只能取0-6，因此分母就是7，与散列表长度无关）</p>
</li>
</ul>
<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><ul>
<li><p>向具有n个关键字的堆中插入一个新元素的时间复杂度为<img src="/%5Cimages/clip_image042.gif" alt="img">，删除一个元素的时间复杂度为<img src="/%5Cimages/clip_image042.gif" alt="img"></p>
</li>
<li><p>堆排序适用于关键字较多的情况，建一个大小为n的小（大）根堆，遍历一遍 数据，即可得到最大（小）的n个数（建立小根堆，，而后依次读入余下的数，小于堆顶则舍弃，否则用该数取代堆顶并重新调整堆）<img src="/%5Cimages/clip_image044.jpg" alt="图像"></p>
</li>
<li><p>小根堆堆最大关键字一定在叶子结点上，二叉树最后一个非叶子结点存储在<img src="/%5Cimages/clip_image046.gif" alt="img">，最大关键字存储范围<img src="/%5Cimages/clip_image048.gif" alt="img">～<img src="/%5Cimages/clip_image050.gif" alt="img"></p>
</li>
<li><p>构建堆从n&#x2F;2出开始调整，递减处理其他子堆（n&#x2F;2为最后一个非叶子结点）</p>
</li>
<li><p>将两个各有N个元素的有序表合并为一个有序表，最少比较次数N次，最多比较次数2N-1次</p>
</li>
<li><p>有序顺序表、二叉排序树、堆、平衡二叉树相比，堆的查找效率最低（查找时是无序的）</p>
</li>
<li><p>排序趟数与原始状态无关的有：插入排序、选择排序、基数排序</p>
</li>
<li><p>就地算法要求空间复杂度为O(1),即所用空间大小为常数</p>
</li>
<li><p>元素规模较小时，使用直接插入、冒泡、简单选择排序</p>
</li>
<li><p>元素规模中等时，使用希尔排序</p>
</li>
<li><p>元素规模较大时，使用快排、堆排序、或基数排序；</p>
</li>
<li><p>快速排序算法中，不产生有序子序列，但每趟排序后会将枢轴元素放到最终位置上</p>
</li>
<li><p>外部排序进行多路归并时，能选取的最大归并段数取决于用于归并的内存大小。内存大小为一个输出缓存区+n个输入缓冲区（n即为归并段数）</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>408</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机组成原理</title>
    <url>/2022/03/11/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<span id="more"></span>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="翻译、汇编、编译"><a href="#翻译、汇编、编译" class="headerlink" title="翻译、汇编、编译"></a>翻译、汇编、编译</h2><ul>
<li><p>翻译程序：翻译一句执行一句</p>
</li>
<li><p>编译：把高级语言转化为汇编语言的过程</p>
</li>
<li><p>汇编：把汇编语言翻译成机器语言的过程</p>
</li>
<li><p>将高级语言源程序转换为机器级目标代码文件的程序是编译程序</p>
</li>
</ul>
<blockquote>
<p>翻译程序分有编译程序、解释程序</p>
<ol>
<li><p>编译程序：将高级语言全部翻译为目标程序，生成目标程序</p>
</li>
<li><p>翻译程序：不会生产目标程序（汇编程序也为翻译程序的一种）</p>
</li>
</ol>
</blockquote>
<ul>
<li><p>地址寄存器（MAR）、数据寄存器（MDR）、高速缓存（Cache）都属于存储器的一部分，但存在于CPU中。</p>
</li>
<li><p>系统软件：操作系统OS、数据库管理系统DBMS、语言处理程序、分布式软件系统、网络软件系统、标准库程序、服务性程序等</p>
</li>
<li><p>完整的计算机系统应包括配套的硬件设备与软件设备</p>
</li>
<li><p>冯诺依曼机的基本工作方式是控制流驱动方式</p>
</li>
<li><p>❌软件功能不能被硬件取代</p>
</li>
</ul>
<blockquote>
<p>逻辑等效：某一功能既可以用软件实现，也可以用硬件实现。但并不是说他们在逻辑功能上是等价的。硬件实现可扩展性差、效率高；软件实现效率低、可扩展性强。</p>
</blockquote>
<ul>
<li><p>存放欲执行指令的寄存器是IR</p>
</li>
<li><p>CPU不包括地址译码器</p>
</li>
</ul>
<blockquote>
<p>地址译码器存在主存中，负责将CPU传来的逻辑地址转换为物理地址</p>
</blockquote>
<ul>
<li><p>MAR的位数是地址码长度（可寻址范围）；MDR的位数是存储字长（存储主存的存储单元传来的数据）</p>
</li>
<li><p>在CPU寄存器中，指令寄存器IR、地址寄存器MAR、数据寄存器MDR对用户完全透明</p>
</li>
<li><p>系列机的基本特性是向后兼容</p>
</li>
</ul>
<blockquote>
<p>向后兼容：时间上向后兼容，新机器可以使用以前机器的指令系统</p>
</blockquote>
<ul>
<li>相联寄存器既可以按地址寻址也可以按内容寻址（快表）</li>
</ul>
<blockquote>
<p>存储程序原理：</p>
<p>将指令以代码形式事先输入计算机主存储器，然后按其在主存中的首地址执行程序第一条指令，以后按该程序规定的顺序执行其他指令，直至程序执行结束。</p>
</blockquote>
<blockquote>
<p>计算机按照此原理的五大功能：数据传送功能、数据存储功能、数据处理功能、操作控制功能、操作判断功能</p>
</blockquote>
<ul>
<li><p>兼容：指计算机软件与硬件的通用性，通常在同一系列不同型号的计算机间通用（❌软硬件间的通用性）</p>
</li>
<li><p>平均指令执行速度：MIPS；平均指令周期：<img src="/%5Cimages/clip_image012.gif" alt="img"></p>
</li>
</ul>
<h2 id="机器字长、指令字长、存储字长"><a href="#机器字长、指令字长、存储字长" class="headerlink" title="机器字长、指令字长、存储字长"></a>机器字长、指令字长、存储字长</h2><blockquote>
<p>机器字长、指令字长、存储字长都必须是字节的整数倍</p>
<ol>
<li><p>机器字长：计算机能够直接处理的二进制数据的位数，一般等于内部寄存器的大小。它决定了计算机的运算精度</p>
</li>
<li><p>指令字长：一个指令字包含的二进制代码位数</p>
</li>
</ol>
<p> 指令字长一般为存储字长的整数倍。若指令字长为存储字长的2倍，则需要2次访存取出一条指令。</p>
<ol start="3">
<li>存储字长：一个存储单元存储的二进制代码</li>
</ol>
</blockquote>
<h2 id="多处理器"><a href="#多处理器" class="headerlink" title="多处理器"></a>多处理器</h2><p>SISD：单指令流单数据流</p>
<p>SIMD：每条指令可以处理多个相同的数据（显卡处理图像、for循环对数组元素处理）数据级并行</p>
<p>一个指令控制部件（CU）、多个ALU、多个局部存储器、一个主存储器</p>
<p>每个执行单元有各自的寄存器组、局部存储器、地址寄存器</p>
<p>向量处理器：向量寄存器，处理对象：向量；主存储器应采用“多端口同时读取”的交叉多模块存储器</p>
<p>MISD：现实中不存在</p>
<p>MIMD：线程（进程）级并行</p>
<p>共享存储多处理器系统（SMP）：多处理共享最低级Cache、主存（共享单一物理地址空间）；LOAD、STORE指令访问存储器</p>
<p>多核处理器：一个CPU有多个处理器，（片级多处理器）、共享存储器</p>
<p>多计算机系统：消息传递通信，有独立的主存（物理地址空间独立）</p>
<h2 id="硬件多线程"><a href="#硬件多线程" class="headerlink" title="硬件多线程"></a>硬件多线程</h2><p>单核CPU中使用资源重复，为多个进程分别提供不同的寄存器组，以减少切换进程的开销</p>
<p>细粒度多线程：每个时钟周期切换线程，实现指令级并行</p>
<p>粗粒度多线程：当一个线程出现较大开销阻塞时（Cache缺失），才切换线程。切换线程时需要清空流水线（开销比细粒度大），实现指令级并行</p>
<p>同时多线程：实现指令级并行和线程级并行</p>
<h1 id="数据的表示和运算"><a href="#数据的表示和运算" class="headerlink" title="数据的表示和运算"></a>数据的表示和运算</h1><p><strong>十六进制的运算使用位运算去做，不然会出错</strong></p>
<ul>
<li><p>所有大写英文字母的ASCII码值都小于小写字母”a”的ASCII码值</p>
</li>
<li><p>1PFLOPS&#x3D;每秒一千万亿（10^15）次浮点运算</p>
</li>
<li><p>10^8&#x3D;一亿</p>
</li>
<li><p>算术右移：原码补0，反码补1，补码补符号位</p>
</li>
<li><p>算数左移：反码补1；原码，补码补0</p>
</li>
<li><p>逻辑移位：补0</p>
</li>
<li><p>机器零是指浮点运算结果在最小正数到0以及最大负数到0之间的值，计算机将其当作机器零处理</p>
</li>
<li><p>定点数中的零是实在的零</p>
</li>
<li><p>“addw %bx,%ax”为AT&amp;T格式，目的寄存器为ax</p>
</li>
<li><p>“sub bx,ax”为Inter格式，目的寄存器为bx</p>
</li>
</ul>
<h2 id="大小端"><a href="#大小端" class="headerlink" title="大小端"></a>大小端</h2><ul>
<li><p>现代计算机都采用字节编址方式，一个操作数有可能有多个内存地址对应</p>
</li>
<li><p>小段方案：最低有效字节存储在最小位置（多字节数据存放在连续字节序列中的排列顺序）</p>
</li>
<li><p>大端方案：最高有效字节存储在最小位置</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>机器数：012345H，以小（大）段方案存放在08000H处</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>地址</td>
<td>08000H</td>
<td>08001H</td>
<td>08002H</td>
</tr>
<tr>
<td>机器数（小端）</td>
<td>45H</td>
<td>23H</td>
<td>01H</td>
</tr>
<tr>
<td>机器数（大端）</td>
<td>01H</td>
<td>23H</td>
<td>45H</td>
</tr>
</tbody></table>
<ul>
<li><p>海明码可以发现两位错误并进行以为纠错（<img src="/%5Cimages/clip_image015.gif" alt="img">）</p>
</li>
<li><p>被校验数据位的海明位号等于该数据位的各校验位海明位号之和（D1在H3（011），则由P1、P2进行校验）</p>
</li>
<li><p>模4补码更容易检查加减运算中的溢出问题</p>
</li>
<li><p>模4补码在存储时只需一个符号位（正确的数其两个符号位相同），只有在送入ALU计算时，才在ALU中使用双符号位</p>
</li>
<li><p>双符号位的最高符号位代表真正的符号，低位符号位用于参与位移操作以判断是否发出溢出（”01”正溢出，”10”负溢出）</p>
</li>
<li><p>原码一位乘法，符号位<img src="/%5Cimages/clip_image017.gif" alt="img">，数值位两数绝对值相乘，累加次数n次</p>
</li>
<li><p>补码一位乘法，符号位参与运算，累加次数n+1次</p>
</li>
<li><p>实现N位（不包括符号位）补码一位乘时，乘积为2N+1位（需要再加符号位）</p>
</li>
</ul>
<h2 id="真值、原码、补码、反码转换规律"><a href="#真值、原码、补码、反码转换规律" class="headerlink" title="真值、原码、补码、反码转换规律"></a>真值、原码、补码、反码转换规律</h2><ul>
<li><ol>
<li>真值-&gt;[x]原：数值位不变，符号位正数为0，负数为1</li>
</ol>
</li>
<li><ol start="2">
<li>[x]原-&gt;[x]补：符号位不变，正数数值位不变，负数数值位取反+1</li>
</ol>
</li>
<li><ol start="3">
<li>[x]原&lt;-&gt;[x]反：符号位不变，正数数值位不变，负数数值位取反</li>
</ol>
</li>
<li><ol start="4">
<li>[x]原&lt;-&gt;[-x]原：数值位不变，符号位取反</li>
</ol>
</li>
<li><ol start="5">
<li>[x]补&lt;-&gt;[-x]补：符号位取反，数值位取反+1</li>
</ol>
</li>
<li><ol start="6">
<li>[x]补&lt;-&gt;[x]移：符号位取反</li>
</ol>
</li>
<li><p>真值的移码与补码只差一个符号位</p>
</li>
<li><p>算术位移对象是有符号数，符号位不参与位移</p>
</li>
<li><p>补码不恢复余数法中，异号相除时，够减商0，不够减商1</p>
</li>
<li><p>判断加减法溢出时，如果采用判断进位的方式（符号位进位<img src="/%5Cimages/clip_image019.gif" alt="img">，最高位进位<img src="/%5Cimages/clip_image021.gif" alt="img">），则产生溢出的条件为<img src="/%5Cimages/clip_image023.gif" alt="img"></p>
</li>
<li><p>无符号数的加减计算与有符号计算相同（化为二进制按位运算）：<img src="/%5Cimages/clip_image025.gif" alt="img"></p>
</li>
</ul>
<h2 id="标志位OF、SF、CF（新增考点）"><a href="#标志位OF、SF、CF（新增考点）" class="headerlink" title="标志位OF、SF、CF（新增考点）"></a>标志位OF、SF、CF（新增考点）</h2><ul>
<li><p>溢出标志位OF（Overflow Flag）（有符号数加减运算）：1表示溢出（寄存器中值不是真正结果）</p>
</li>
<li><p>OF&#x3D;最高位产生的进位<img src="/%5Cimages/clip_image027.gif" alt="img">次高位产生的进位</p>
</li>
<li><p>符号标志位SF（有符号数加减运算）：0表示结果为正数，1表示结果为负数</p>
</li>
<li><p>进位标志位CF（Carry Flag）（无符号数加减运算）：1表示最高位有进位，0表示最高位无进位（最高位是否进位与是否溢出无关）</p>
</li>
<li><p>无符号数运算时借位标志<img src="/%5Cimages/clip_image029.gif" alt="img">,(C为进位输出，减法运算：sub&#x3D;1，加法运算：sub&#x3D;0，加法运算时有进位则说明溢出)</p>
</li>
<li><p>乘法运算时，如果高33位不是全0或全1，OF&#x3D;1，表示溢出</p>
</li>
<li><p>当指令执行无符号数比较跳转时，通常对两数进行减法运算，结果小于等于0时跳转（小于0借位符号CF&#x3D;1，等于0零符号ZF&#x3D;1）</p>
</li>
</ul>
<h2 id="浮点数"><a href="#浮点数" class="headerlink" title="浮点数"></a>浮点数</h2><ul>
<li><p>采用规格化浮点数最主要是为了增加数据的表示精度</p>
</li>
<li><p>在IEEE 754标准下，尾数全部为隐藏最高位”1”的正数原码(临时浮点数无隐含位)</p>
</li>
<li><p>规格化浮点数就是让尾数<img src="/%5Cimages/clip_image031.gif" alt="img"></p>
</li>
<li><p>（基数为2时）原码规格化数的尾数最高位一定是1；补码规格化数的尾数最高位一定与尾数符号相反（0.11 1、1.011 1（最大负数形式））</p>
</li>
<li><p>基数为<img src="/%5Cimages/clip_image033.gif" alt="img">时，若浮点数为正数，数值位前n位不全为0；若浮点数为负数，数值位前n位不全为1</p>
</li>
</ul>
<blockquote>
<p>根据数值x求浮点数二进制值时。先将x转换为二进制表示，再对其规格化，得到规格化尾数（IEEE 754标准下只需要把尾数转换为1.xxx形式即可）与阶数。按照IEEE 754标准将数符、移码表示的阶数、规格化尾数填入相应字段</p>
</blockquote>
<table>
<thead>
<tr>
<th>类型</th>
<th>数符</th>
<th>阶码</th>
<th>尾数数值</th>
<th>总位数</th>
<th>偏置值</th>
</tr>
</thead>
<tbody><tr>
<td>短浮点数float</td>
<td>1</td>
<td>8</td>
<td>23</td>
<td>32</td>
<td>127（7FH）</td>
</tr>
<tr>
<td>长浮点数</td>
<td>1</td>
<td>11</td>
<td>52</td>
<td>64</td>
<td>1023（3FFH）</td>
</tr>
<tr>
<td>临时浮点数</td>
<td>1</td>
<td>15</td>
<td>64</td>
<td>80</td>
<td>16383(3FFFH)</td>
</tr>
</tbody></table>
<ul>
<li><p>float类型最小正数值：<img src="/%5Cimages/clip_image035.gif" alt="img">（阶码不能取到全0）</p>
</li>
<li><p>float类型最大正数值:<img src="/%5Cimages/clip_image037.gif" alt="img"></p>
</li>
<li><p>double类型最小正数值：<img src="/%5Cimages/clip_image039.gif" alt="img"></p>
</li>
<li><p>double类型最大正数值：<img src="/%5Cimages/clip_image041.gif" alt="img"></p>
</li>
<li><p>阶码全为1时表示无穷大，全为0时表示非规格化数</p>
</li>
<li><p>右规和尾数舍入过程，阶码可能上溢</p>
</li>
<li><p>浮点数乘法任何情况下最多进行一次右归，可能进行多次左归</p>
</li>
<li><p>最简单的截断方法为直接截断</p>
</li>
<li><p>加法器进位信号<img src="/%5Cimages/clip_image043.gif" alt="img"></p>
</li>
<li><p>加法器进位传递信号<img src="/%5Cimages/clip_image045.gif" alt="img"></p>
</li>
<li><p>相同字长下，定点数比浮点数精度更高（浮点数部分字段用作阶码表示）；浮点数表示范围更大</p>
</li>
<li><p>unsigned类型为无符号整数，直接用二进制位对数值进行编码而得。（一般为补码表示）</p>
</li>
<li><p>原码一位乘算法过程中，所有移位均是逻辑移位</p>
</li>
</ul>
<h2 id="补码加减运算器"><a href="#补码加减运算器" class="headerlink" title="补码加减运算器"></a>补码加减运算器</h2><table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td><img src="/%5Cimages/clip_image006.gif" alt="图像"></td>
</tr>
</tbody></table>
<p>加减运算器处理有符号数与无符号数的处理过程是相同的，但是判断是否溢出的方法不同</p>
<p>加法器的低位进位信息，减法运算时为1（被减数取反加1），加法运算时为0</p>
<h2 id="乘法电路和除法电路的基本结构"><a href="#乘法电路和除法电路的基本结构" class="headerlink" title="乘法电路和除法电路的基本结构"></a>乘法电路和除法电路的基本结构</h2><p>部分积和被乘数X做无符号数加法时，可能产生进位，因此需要一个专门的进位位C。乘积奇存器P初始时置0。计数器C，初值为 32，每循环一次减1。 ALU 是乘法核心部件，对乘积寄存器P和被乘数奇存器X的內容做“无符号加法” 运算，运算结果送回奇存器P，进位存放在C中。每次循环都对进位位C，乘积寄存器P和乘数奇存器Y 实现同步 “逻辑右移”，此时，进位位 C移入寄存器P的最高位，寄存器Y的最低位移出。每次寄存器Y的最低位都被送到控制逻辑，以决定被乘数是否“加”到部分积上。</p>
<p><img src="/%5Cimages/clip_image008.jpg" alt="图像画廊"></p>
<p>无符号乘法溢出判断：前n比特有不是0，则发生了溢出</p>
<p>有符号乘法溢出判断：高n+1位全1或全0说明没有溢出</p>
<p>需要部件：支持加减法ALU、移位功能的寄存器（无符号乘法逻辑右移、有符号算术乘法右移、除法左移）、控制逻辑（加减法控制、左右移控制、写使能）、计数器</p>
<h1 id="存储系统"><a href="#存储系统" class="headerlink" title="存储系统"></a>存储系统</h1><p><img src="/%5Cimages/clip_image047.gif" alt="图像"></p>
<ul>
<li><p>主存使用RAM和ROM实现，控制存储器使用ROM实现，主存主要使用DRAM，Cache主要使用SRAM</p>
</li>
<li><p>主存和控存都是按地址访问</p>
</li>
<li><p>存放一个二进制位的物理器件称为存储元，地址码相同的多个存储元构成一个存储单元（字节编址即八个存储元使用一个存储单元），若干个存储单元集合构成存储体</p>
</li>
<li><p>编址方式属于计算机组成，与机器字长（计算机体系结构）没有关系</p>
</li>
<li><p>存取周期<img src="/%5Cimages/clip_image049.gif" alt="img">：存储芯片进行连续两次读、写操作所必须间隔的时间（存取时间+恢复时间）</p>
</li>
<li><p>存取时间<img src="/%5Cimages/clip_image051.gif" alt="img">：执行一次读操作或写操作的时间（分有读出时间、写入时间）</p>
</li>
</ul>
<ol>
<li><p>读出时间<img src="/%5Cimages/clip_image053.gif" alt="img">：从主存接收到有效地址开始，到读出所选中单元的内容并在外部数据总线上稳定地出现所需的时间（还需要一个总线周期才能将数据传入CPU）</p>
</li>
<li><p>写入时间：从主存接收到有效地址开始到数据写入被写入单元为止</p>
</li>
</ol>
<ul>
<li>采用DMA方式传递数据时，每传递一个数据就要占用一个存取周期</li>
</ul>
<h2 id="SRAM、DRAM"><a href="#SRAM、DRAM" class="headerlink" title="SRAM、DRAM"></a>SRAM、DRAM</h2><ul>
<li><p>主存储器由DRAM实现；Cache由SRAM实现</p>
</li>
<li><p>CDROM是只读型光盘存储器，不属于只读存储器ROM，使用串行存取方式</p>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>DRAM</th>
<th>SRAM</th>
</tr>
</thead>
<tbody><tr>
<td>特点</td>
<td>需要刷新、集成度高</td>
<td>速度较快、成本较高、功耗较大</td>
</tr>
<tr>
<td>存储元</td>
<td>晶体管（电容）</td>
<td>双稳态触发器（六晶体管MOS）</td>
</tr>
<tr>
<td>送行列地址</td>
<td>分两次送（地址复用）</td>
<td>同时送</td>
</tr>
</tbody></table>
<blockquote>
<p>DRAM刷新</p>
<ol>
<li><p>刷新对CPU是透明的，不依赖外部访问</p>
</li>
<li><p>刷新单位是行</p>
</li>
<li><p>刷新操作类似于读操作（将信息通过刷新放大器放大后重新存回存储单元）</p>
</li>
<li><p>一次刷新只占用一个存取周期</p>
</li>
</ol>
</blockquote>
<ul>
<li><p>低位交叉编址中低位地址表示该字节存储的芯片编号。若是连续占多位字节的数据字（如double）即从该芯片开始存储。</p>
</li>
<li><p>一个存储周期可以对所有芯片各读取一个字节</p>
</li>
<li><p>芯片引脚数目N&#x3D;数据线<img src="/%5Cimages/clip_image055.gif" alt="img"> + 地址线<img src="/%5Cimages/clip_image057.gif" alt="img">（DRAM采用地址复用技术，因此地址线是原来的1&#x2F;2）+片选线（1根）+读写控制线（2根）（读写控制线有时候也可以共用一根）</p>
</li>
<li><p>地址的编码是由低位向高位编码，先将片内地址由最低位填入，再填入片选地址（最高位可以空闲）</p>
</li>
<li><p>CPU与Cache间的数据交换以字为单位；Cache与主存间的交换以块为单位</p>
</li>
</ul>
<h2 id="固态硬盘SSD"><a href="#固态硬盘SSD" class="headerlink" title="固态硬盘SSD"></a>固态硬盘SSD</h2><ol>
<li><p>基于闪存Flash（芯片中的一块相当于磁盘中的一条磁道，磁道中还有若干页（最基本的读写单位））</p>
</li>
<li><p>可以随机存储、用and门实现</p>
</li>
<li><p>动态磨损：偏向使用较新的内存颗粒进行擦除写入（优化不够）</p>
</li>
<li><p>静态磨损：将长时间不用的数据写入较老的内存颗粒中，将新数据写入新的内存颗粒（磨损均衡、主控压力较大）<img src="/%5Cimages/clip_image010.gif" alt="图像"></p>
</li>
</ol>
<h2 id="三级Cache"><a href="#三级Cache" class="headerlink" title="三级Cache"></a>三级Cache</h2><ul>
<li><p>指令Cache与数据Cache分离位于L1级，通常使用写分配法与写回法</p>
</li>
<li><p>L1对L2使用全写法，L2对L3使用写回法（非全部情况）</p>
</li>
<li><p>Cache写命中策略：全写法、写回法</p>
</li>
<li><p>Cache未命中策略：写分配法、非写分配法</p>
</li>
<li><p>全写法（write-through）：将数据同时写入Cache与主存</p>
</li>
<li><p>写回法（write-back）：在块被换出时，将更新的块写回缓存</p>
</li>
<li><p>写分配法（write-allocate）：加载主存中的块到Cache</p>
</li>
<li><p>非写分配法（not-write-allocate）：只写入主存，不调块</p>
</li>
<li><p>每行Cache对应一个标记项，项中包括有效位、标记位tag（地址总长度-块内偏移地址-Cache组偏移地址）、一致性维护位（写回法时使用）、替换算法位（替换算法时使用）</p>
</li>
<li><p>Cache缺失由硬件完成；缺页由软件完成；TLB缺失既可以用硬件也可以用软件完成</p>
</li>
<li><p>LRU算法中替换算法位长度与Cache组大小有关，2路组相联使用1位LRU位，4路组相联使用2位LRU位</p>
</li>
<li><p>语句<img src="/%5Cimages/clip_image059.gif" alt="img">，需要访存两次。第一次读取a[k]的值；第二次将新值写回a[k]</p>
</li>
<li><p>Cache的效率公式：Cache访问时间&#x2F;实际访存的平均访问时间</p>
</li>
<li><p><img src="/%5Cimages/clip_image061.gif" alt="图像画廊"></p>
</li>
</ul>
<h2 id="CPU使用虚拟内存过程"><a href="#CPU使用虚拟内存过程" class="headerlink" title="CPU使用虚拟内存过程"></a>CPU使用虚拟内存过程</h2><p>CPU使用的是虚拟地址，由辅助硬件（TLB、页表）找到虚地址与实地址间的对应关系，并判断该虚地址对应的存储单元是否已装入主存（有效位为1）。若已在主存中，通过地址变换，CPU可直接访问主存指示的存储单元（或直接访问Cache获得数据）；若不在主存，通过缺页中断，把包含该字的一页或是一段掉入主存后再由CPU访问。若主存已满，采用替换算法置换主存中的一页或一段</p>
<ul>
<li><p>TLB缺失则需要访存一次访问页表；页表缺失需要访问磁盘；Cache缺失需要访存一次获取数据</p>
</li>
<li><p>段页式在地址变换时需要两次查表，开销较大</p>
</li>
<li><p>虚拟存储管理系统的基础是程序访问的局部性原理，该理论的基本含义是：在程序执行的过程中，程序对主存的访问是不均匀的</p>
</li>
<li><p>Flash半导体存储器的物理结构不需要考虑寻道时间和旋转延迟，可以直接按IO请求的先后顺序服务</p>
</li>
</ul>
<h1 id="指令系统"><a href="#指令系统" class="headerlink" title="指令系统"></a>指令系统</h1><ul>
<li><p>零地址指令：空操作指令、停机指令、关中断指令、弹栈压栈指令</p>
</li>
<li><p>要注意隐操作数的情况，一地址指令中有将目的地址隐藏的双操作数指令（先按指令地址码给出的地址读操作数，另一个操作数由ACC提供，运算结果也存放在ACC中）</p>
</li>
<li><p>执行一条三地址指令需要访问4次存储器（取指令1次、取两个操作数2次、存放结果1次）</p>
</li>
<li><p>程序控制类指令功能：改变程序的执行顺序（即转移地址的指令），使程序有测试、分析、判断、循环执行的能力。如：无条件转移指令、条件转移指令、循环指令（中断隐指令指令为硬件实现，不存在于指令系统中）</p>
</li>
<li><p>微操作信号发生器的设计与寄存器数量无关</p>
</li>
<li><p>CISC控制器大多数采用微程序控制</p>
</li>
<li><p>RISC采用指令流水线技术（有利于编译程序代码优化），以硬布线控制为主</p>
</li>
<li><p>RISC只有Load\Store指令访存，其余指令的操作都在寄存器间进行</p>
</li>
</ul>
<p>微程序控制中，确定一条指令的地址</p>
<ol>
<li><p>增量计数法：由<img src="/%5Cimages/clip_image063.gif" alt="img">确定下一条微指令地址</p>
</li>
<li><p>下地址法（断定法）：由微指令的下地址字段给出后续指令地址</p>
</li>
<li><p>硬件法：由专门硬件电路或外部直接向CMAR输入微指令地址</p>
</li>
</ol>
<ul>
<li><p>基址寻址时，程序员操作偏移地址，基址寄存器内容由操作系统控制（如在中断向量表寻找中断向量，基地址为中断向量表起始地址）</p>
</li>
<li><p>变址寻址时，程序员操作变址寄存器，偏移地址（数据结构首地址）不变</p>
</li>
<li><p>简化地址结构的基本方法是尽量使用隐含取值</p>
</li>
<li><p>如果一条指令由两字节组成，每取一字节PC值+1（每次PC自加的值由指令字长决定）<img src="/%5Cimages/clip_image065.gif" alt="图像"></p>
</li>
<li><p>对按字寻址的机器，程序计数器取决于存储器字数、指令寄存器取决于指令字长</p>
</li>
<li><p>内存地址都为无符号数，寻址时对补码操作数需要一定转换</p>
</li>
<li><p>执行<img src="/%5Cimages/clip_image067.gif" alt="img">指令时，通过<img src="/%5Cimages/clip_image069.gif" alt="img">实现对a与b的比较</p>
</li>
</ul>
<h1 id="中央处理器"><a href="#中央处理器" class="headerlink" title="中央处理器"></a>中央处理器</h1><ul>
<li><p>控制器的全部功能：从主存中取出指令、分析指令、并产生有关的操作控制信号</p>
</li>
<li><p>程序状态字寄存器存放计算机系统表征程序和机器状态的部件</p>
</li>
<li><p>间址周期的作用是取操作数的有效地址，间址周期结束后，MDR中的内容为操作数地址</p>
</li>
<li><p>对于间接寻址的指令，先访存一次取出有效地址，再访存取出操作数（间址周期介于取址周期与执行周期之间）</p>
</li>
<li><p>MDR通常与存储字长有关，数据字长是一次存取数据的长度（可能是存储字长的n倍）</p>
</li>
</ul>
<h2 id="数据通路"><a href="#数据通路" class="headerlink" title="数据通路"></a>数据通路</h2><ul>
<li><p>指令执行过程中数据所经过的路径，包括路径上的部件，称为数据通路</p>
</li>
<li><p>ALU、通用寄存器、状态寄存器、Cache、MMU、浮点运算逻辑、异常和中断处理逻辑等，都属于数据通路的一部分</p>
</li>
</ul>
<h2 id="多核技术"><a href="#多核技术" class="headerlink" title="多核技术"></a>多核技术</h2><ul>
<li><p>多核处理器指单芯片处理器，在一个芯片中集成两个或多个完整且并行工作的处理器核心而构成的处理</p>
</li>
<li><p>核心指指令部件、算术&#x2F;逻辑部件、寄存器堆、一二级缓存处理单元</p>
</li>
<li><p>多核处理三大技术：维持Cache一致性、核间通信技术、对软件设计的挑战</p>
</li>
<li><p>多个CPU共享统一的地址空间，且独自拥有属于自己的L1Cache</p>
</li>
</ul>
<h2 id="机器周期、指令周期、时钟周期"><a href="#机器周期、指令周期、时钟周期" class="headerlink" title="机器周期、指令周期、时钟周期"></a>机器周期、指令周期、时钟周期</h2><ul>
<li><p>指令周期：CPU每取出并执行一条指令所需的全部时间</p>
</li>
<li><p>机器周期是指令执行中每步操作（取值、存储器读、存储器写等）所需要的时间</p>
</li>
<li><p>每个机器周期的节拍数可以不等（同一个操作（取值、写回等）的节拍数必须相同）</p>
</li>
<li><p>各指令功能不同，所以各指令执行所需的机器周期数也是可变的</p>
</li>
<li><p>指令的执行周期结束后进入中断周期，用来响应中断</p>
</li>
<li><p>CPU根据指令周期的不同阶段判断从存储器中取出的二进制代码是指令还是数据</p>
</li>
<li><p>CPU硬件中使用专门的MUX（二路选择器）进行PC操作</p>
</li>
<li><p>通常以存取周期作为基准周期，即内存中读取一个指令字的最短时间作为机器周期（指令字长为2倍存储字长的取值周期为2个机器周期）</p>
</li>
<li><p>控制存储器CM使用ROM存放微程序，是CPU的一部分，因此控存不属于存储系统的一部分</p>
</li>
<li><p>在组合逻辑控制器中，微操作控制信号的形成主要与指令译码信号与时钟信号有关</p>
</li>
<li><p>硬布线控制器需要结合各微操作的节拍安排，综合分析，写出逻辑表达式，再设计成逻辑电路图。因此时序系统较为复杂</p>
</li>
<li><p>微指令在直接编码方式下，其操作控制字段位数等于微命令数；在字段直接编码方式下，每个字段要预留一个不进行任何操作的状态</p>
</li>
<li><p>一个微程序周期对应一个指令周期，一个微指令周期对应一个时钟周期（一条指令对应一个微程序，一个微程序由许多微指令构成，一条微指令会发出许多不同的微命令）</p>
</li>
<li><p>流水线是时间上并行（空间并行是资源重复）</p>
</li>
<li><p>超标量流水线能结合动态调度技术提高指令执行的并行性（拓展Tomasulo算法:支持双流出超标量流水线）</p>
</li>
<li><p>一个m段流水线稳定流出时CPU的吞吐能力，与m个并行部件的CPU吞吐能力相等</p>
</li>
</ul>
<h1 id="总线"><a href="#总线" class="headerlink" title="总线"></a>总线</h1><p><img src="/%5Cimages/clip_image071.gif" alt="图像"></p>
<ul>
<li><p>猝发传送：一个总线周期内传输存储地址连续的n个数据字，<img src="/%5Cimages/clip_image073.gif" alt="img">(t_1传输地址，t_2传输一个数据字)</p>
</li>
<li><p>一个总线的时钟周期可以传输一个存储字（长度为总线位宽）</p>
</li>
<li><p>总线宽度有称总线位宽，是总线上能够同时传输的数据位数，通常是指总线的数据总线的根数</p>
</li>
<li><p>数据总线宽度由总线的功能特性定义</p>
</li>
<li><p>系统总线中地址线传输CPU想访问的存储单元或IO端口地址</p>
</li>
<li><p>采用分离事务通信方式（总线复用）可以提高总线利用率</p>
</li>
<li><p>靠近CPU的总线速度快（连接高速设备）</p>
</li>
<li><p><img src="/%5Cimages/clip_image075.gif" alt="img">采用并行传输方式</p>
</li>
<li><p>USB是连接外部设备的IO总线，用于设备与设备控制器（IO接口）间互连的接口标准</p>
</li>
<li><p>USB特性：即插即用、热插拔、采用菊花链形式将众多外设连接起来（拓展坞）、可扩展性强、高速传输、串行总线（不能传输多位数据）</p>
</li>
<li><p>系统总线：ISA、EISA</p>
</li>
<li><p>局部总线：VESA、PCI、AGP、PCI-Express（取代PCI、AGP）</p>
</li>
<li><p>PCI总线是一个与处理器无关的高速外围总线，其基本传输机制是猝发式传输</p>
</li>
</ul>
<h1 id="输入、输出系统"><a href="#输入、输出系统" class="headerlink" title="输入、输出系统"></a>输入、输出系统</h1><h2 id="IO接口"><a href="#IO接口" class="headerlink" title="IO接口"></a>IO接口</h2><ul>
<li><p>IO设备通过设备控制器与主板的系统总线相连接（控制IO设备的具体动作）</p>
</li>
<li><p>IO接口：外设与主机间传输数据时进行各种协调工作的逻辑部件（速度匹配、数据缓存、电平和格式转换、地址译码、传送控制信号和状态信息）</p>
</li>
<li><p>执行IO指令时，CPU通过地址总线选择所请求的IO端口、通过数据总线在通用寄存器与IO端口之间进行数据传送</p>
</li>
<li><p>IO接口的控制线与地址线都是从CPU到IO接口的单向传送。IO接口中的命令字、状态字、中断类型号都是通过IO总线的数据线由IO接口传送到CPU</p>
</li>
<li><p>若干端口加相应的控制逻辑组成接口</p>
</li>
<li><p>IO统一编址执行速度慢；IO独立编址控制复杂</p>
</li>
<li><p>磁盘驱动器是由磁头、磁盘和读写电路等组成即磁盘本身</p>
</li>
<li><p>U盘本质上来说是一种只读存储器</p>
</li>
<li><p>RAID技术将多个独立的物理磁盘组成一个独立的逻辑磁盘，提升存储性能、系统的可靠性</p>
</li>
<li><p>RAID0把连续多个数据块交替存放在不同的物理磁盘扇区中，几个磁盘交叉并行读写，不仅扩大了存储容量，而且提高了磁盘数据存取速度</p>
</li>
<li><p>RAID1使两个磁盘同时进行读写，互为备份</p>
</li>
<li><p>磁盘非格式化容量：磁盘可利用磁化单元数</p>
</li>
<li><p>磁盘格式化容量：按照某种特定的记录格式所能存储信息的总量（格式化后要比非格式化小）</p>
</li>
<li><p>采用定长数据块记录格式，直接寻址的最小单元为扇区</p>
</li>
<li><p>一个磁盘的读写操作是串行的，不可能同一时刻即读又写，也不可能同一时刻读或写两组数据</p>
</li>
<li><p>VRAM（显示存储器）：将一帧图像信息存储其中，存储容量由图像分辨率、灰度级决定</p>
</li>
<li><p>在字符显示的VRAM中存放ASCII码用以显示字符</p>
</li>
<li><p>总线仲裁中，计数器定时查询需要一根总线请求BR，和<img src="/%5Cimages/clip_image077.gif" alt="img">根设备地址线</p>
</li>
<li><p>总线仲裁一般是IO设备争用总线的判优方式，而中断判优方式一般是IO设备争用CPU的判优方式</p>
</li>
<li><p>通道和中断是软硬件相结合实现方式</p>
</li>
</ul>
<h2 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h2><ul>
<li><p>中断处理方式：在IO设备输入每个数据的过程中，无须CPU干预。仅当传输完一个数据时，才需要CPU进行中断处理。</p>
</li>
<li><p>中断数据传送是在软件控制下完成的</p>
</li>
<li><p>指令执行结构出现异常而引起的中断（运算溢出等）为程序性中断</p>
</li>
<li><p>IO中断为外部中断</p>
</li>
<li><p>机器校验中断为终止类中断</p>
</li>
<li><p>对于故障类异常，其断电是发生故障时的指令地址，要重新计算PC值</p>
</li>
<li><p>中断的断点为下条指令地址，无需重新计算</p>
</li>
<li><p>中断响应由高到低的优先级宜用访管-程序性-重新启动</p>
</li>
<li><p>主存故障引起的中断是机器校验中断，属于内中断（只能由CPU自身完成）；外中断一般指主存和CPU外的中断，如外设引起的中断。此时需要CPU从总线获取中断源的标志信息，进行下一步处理</p>
</li>
<li><p>缺页、溢出等异常事件是特定指令执行过程中产生的，中断不和任何指令相关联，不阻止任何指令的完成（在指令周期的中断周期有效）</p>
</li>
<li><p>配有通道的计算机系统中，用户程序需要输入&#x2F;输出时，引起的中断时访管中断，系统由用户态转为核心态</p>
</li>
<li><p>访管指令即为Trap指令</p>
</li>
<li><p>中断优先级包含响应优先级与处理优先级，处理优先级由屏蔽字实现（0为该中断开放、1为该中断被屏蔽）</p>
</li>
<li><p>CPU收到多个中断请求时，根据响应优先级响应中断</p>
</li>
<li><p>响应优先级为CPU响应中断的优先级，当存在中断屏蔽字情况下。可能出现的是，处理机响应D1，D1再被D2打断</p>
</li>
<li><p>中断屏蔽是在打断中断时使用，谁先得到响应要看响应优先级</p>
</li>
<li><p>中断服务程序的最后指令通常是中断返回指令（RETI），该指令在中断恢复后，此时CPU所有寄存器已经恢复到中断前的状态。因此该指令不需要进行无条件转移，只需要通知CPU开始从PC中取值，进入取值周期即可。</p>
</li>
<li><p>在多重中断中，CPU只有在检测到中断请求信号后（中断优先级更低的中断请求信号检测不到）才会进入中断响应周期</p>
</li>
</ul>
<h2 id="DMA方式"><a href="#DMA方式" class="headerlink" title="DMA方式"></a>DMA方式</h2><ul>
<li><p>DMA传送过程中，DMAC将接管CPU的地址总线、数据总线、控制总线，CPU主存控制信号被禁止使用</p>
</li>
<li><p>DMA传输的是数据块</p>
</li>
<li><p>DMA请求，请求的是总线使用权。</p>
</li>
<li><p>DMA数据传输在控制器的控制下完成的</p>
</li>
<li><p>对DMA请求的响应可以发生在每个机器周期结束时，只要CPU不占总嫌就可被响应（即DMA响应发生在一个总线事务完成后）</p>
</li>
<li><p>DMA请求不会导致被中断指令重新执行</p>
</li>
</ul>
<p><img src="/%5Cimages/clip_image079.jpg" alt="图像"></p>
<h2 id="通道"><a href="#通道" class="headerlink" title="通道"></a>通道</h2><ul>
<li><p>通道程序存放在主存中，由通道从主存中取出并执行（通道执行）</p>
</li>
<li><p>CPU通过执行IO指令负责开启关闭通道，以及处理来自通道的中断实现对通道的管理</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>408</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络</title>
    <url>/2022/03/11/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<span id="more"></span>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><ul>
<li><p>计算机网络资源：计算机硬件、软件、数据</p>
</li>
<li><p>局域网与广域网差异不仅在覆盖范围，还主要在于所使用协议不同（局域网广播技术、广域网点对点交换技术）</p>
</li>
<li><p>局域网与广域网的互联是通过路由器来实现的</p>
</li>
<li><p>广播式网络（通常为局域网通信方式，局域网工作在数据链路层）可以不要网络层，但需要服务访问点（链路层与物理层）</p>
</li>
<li><p>定义功能执行的方法不是对网络模型进行分层的目标</p>
</li>
<li><p>OSI模型精确定义了服务、协议、接口三个概念，TCP&#x2F;IP模型没有</p>
</li>
<li><p>ISO&#x2F;OSI模型中，网络层可同时提供无连接服务与面向链接服务（TCP&#x2F;IP中传输层提供）</p>
</li>
<li><p>ISO&#x2F;OSI模型中，传输层只提供面向连接的服务</p>
</li>
<li><p>OSI模型中，表示层的功能是表示出用户看得懂的数据格式。主要完成数据字符集的转换、数据格式化和文本压缩、数据加密解密等</p>
</li>
<li><p>TCP&#x2F;IP模型中，传输层处理关于可靠性、流量控制、错误校正等问题</p>
</li>
<li><p>TCP&#x2F;IP协议族：TCP,IP,ICMP,IGMP,ARP,RARP,UDP,DNS,FTP,HTTP</p>
</li>
<li><p>以太网的MAC数据帧的首部和尾部长度为18字节</p>
</li>
<li><p>以太网前导码8字节，第一个字段7字节（前同步码）；第二个字段1字节（帧开始定界符）</p>
</li>
<li><p>IPv4常用首部长度为20字节</p>
</li>
<li><p>TCP首部开销为20字节，UDP首部开销为8字节 </p>
</li>
<li><p><img src="/%5Cimages/clip_image006.gif" alt="图像"></p>
</li>
</ul>
<h1 id="物理层"><a href="#物理层" class="headerlink" title="物理层"></a>物理层</h1><ul>
<li><p>物理层规定了电气特性，因此能够识别所传送的比特流</p>
</li>
<li><p>在数值上，波特率等于比特率与每符号所含比特数的比值</p>
</li>
<li><p>信道不等同于通信电路，一条可双向通信的电路往往包含两个信道，一条是发送信道，一条是接受信道。多个通信用户公用通信电路时，每个用户在该通信电路上都有一条信道（时分复用）</p>
</li>
<li><p>波特率等于每秒可能发生的信号变化次数</p>
</li>
<li><p>报文交换不能用于语音数据交换</p>
</li>
<li><p>虚电路对网络中的故障敏感，因此不能在出错率高（设备故障率高）的传输系统中使用（可以使用数据报方式）</p>
</li>
<li><p>电路交换不支持差错控制</p>
</li>
<li><p>电缆采用屏蔽技术的好处是减少电磁干扰辐射</p>
</li>
<li><p>描述物理层接口引脚处于高电位的含义属于功能描述</p>
</li>
<li><p>利用中继器扩大网络传输距离就是将衰弱信号进行整形再生</p>
</li>
<li><p>曼彻斯特编码的编码效率为50%，4B&#x2F;5B编码的编码效率为80%</p>
</li>
</ul>
<p><img src="/%5Cimages/clip_image008.gif" alt="图像"></p>
<ul>
<li><p>非归零编码（NRZ）：高电平为1，低电平为0，不用归零</p>
</li>
<li><p>反向非归零编码（NRZI）：信号翻转代表0，信号保持不变代表1</p>
</li>
<li><p>曼彻斯特编码（以太网使用）：一个码元分为两个相等间隔，每个码元位中间跳变，作为时钟信号；码元为1时，前一间隔高电平，后一间隔低电平；</p>
</li>
<li><p>差分曼彻斯特编码（局域网使用）：码元为1时，前半码元电平与上一码元的后半个码元电平相同</p>
</li>
<li><p>转发器作用是放大信号</p>
</li>
<li><p>奈奎斯特定理：<img src="/%5Cimages/clip_image010.gif" alt="img">（V为每个码元离散电平数目，W理想低通信道带宽）</p>
</li>
<li><p>香农定理：<img src="/%5Cimages/clip_image012.gif" alt="img">（S&#x2F;N为信噪比）</p>
</li>
<li><p>两个公式中取较小的一个指固定带宽后取较小速率的值为实际最高理论速率</p>
</li>
<li><p>同步TDM方式复用要求复用线路的数据率相同，对于数据传输率低的复用线路采用脉冲填充方式</p>
</li>
<li><p>语音信号需要128个量化级，每次采样需要<img src="/%5Cimages/clip_image014.gif" alt="img">来标识，语音频率4kHz，每秒需采样8000次。则一路话音需要的数据传输速率为<img src="/%5Cimages/clip_image016.gif" alt="img"></p>
</li>
</ul>
<h1 id="数据链路层"><a href="#数据链路层" class="headerlink" title="数据链路层"></a>数据链路层</h1><ul>
<li>通过提高信噪比可以减弱随机差错对数据传输的影响</li>
</ul>
<blockquote>
<p>通信信道噪声可以分为：热噪声与冲击噪声</p>
<p>热噪声：信道固有噪声，随即差错，提高信噪比可以降低它对数据传输的影响</p>
<p>冲击噪声：外界电磁干扰，突发错差</p>
</blockquote>
<ul>
<li><p>海明码纠错d位需要码距为2d+1的编码方案；检错d位需要码距为d+1的编码方案</p>
</li>
<li><p>海明码能纠一位错应该满足<img src="/%5Cimages/clip_image018.gif" alt="img">（k为校验码位数、n为数据码位数）</p>
</li>
<li><p>循环冗余码的帧检验序列与帧数据一同发出，在接受端对这m+r位数据与多项式做模2除法</p>
</li>
<li><p>带r个校验位的多项式编码可以检测到所有长度小于等于r的突发性错误</p>
</li>
<li><p>TDM所用传输介质的性质是：介质的位速率大于单个信号的位速率</p>
</li>
<li><p>DBN协议中，接收端在收到不合要求的数据帧需要全部抛弃，但是会重复返回最后一个确认帧（防止已发送的ACK丢失）</p>
</li>
<li><p>拥塞控制中的选择重传协议接受窗口大小必须满足发送窗口大小<img src="/%5Cimages/clip_image020.gif" alt="img">接受窗口大小<img src="/%5Cimages/clip_image022.gif" alt="img">，且<img src="/%5Cimages/clip_image024.gif" alt="img">（m为帧序号位数）；接受窗口的最大值为<img src="/%5Cimages/clip_image026.gif" alt="img"></p>
</li>
<li><p>信道效率：指发送方在一个发送周期（发送方开始发送数据到收到第一个ACK）内，有效发送数据所需要的时间占整个发送周期的比率</p>
</li>
<li><p>信道吞吐率：信道利用率<img src="/%5Cimages/clip_image028.gif" alt="img">发送方发送速率</p>
</li>
<li><p>以太网中，当数据传输速率提高时，帧的发送时间相应地缩短。为了能有效地检测冲突，可以减少电缆介质的长度或增加最短帧长</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>滑动窗口协议</th>
<th>一比特滑动窗口</th>
<th>Go back n协议</th>
<th>选择重传协议</th>
</tr>
</thead>
<tbody><tr>
<td>发送窗口大小</td>
<td>1</td>
<td>n（小于序号范围）</td>
<td>n（小于序号范围的一半）</td>
</tr>
<tr>
<td>接受窗口大小</td>
<td>1</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>ACK</td>
<td>每次都需要返回ACK</td>
<td>累计ACK</td>
<td>NAK或ACK定时器</td>
</tr>
<tr>
<td>超时重传的帧</td>
<td>未收到ACK的帧</td>
<td>i号帧以后的所有帧</td>
<td>未收到ACK的帧</td>
</tr>
</tbody></table>
<h2 id="码分复用"><a href="#码分复用" class="headerlink" title="码分复用"></a>码分复用</h2><ul>
<li><p>A、B同时向C发送数据，则A、B的码序列内积为0</p>
</li>
<li><p>C读取A发送的数据就要将接收到的数据与A的码片序列进行内积（&gt;0表示1；&lt;0表示0）</p>
</li>
</ul>
<h2 id="CSMA-x2F-CA"><a href="#CSMA-x2F-CA" class="headerlink" title="CSMA&#x2F;CA"></a>CSMA&#x2F;CA</h2><ol>
<li><p>DIFS（分布式协调IFS）：最长的IFS，优先级最低，用于异步帧竞争访问的时延。即载波监听到信道空闲，等待DIFS后发送RTS预约信道</p>
</li>
<li><p>PIFS（点协调式IFS）：PCF操作使用</p>
</li>
<li><p>SIFS（短IFS）：最短的IFS，最高优先级，目的站等待SIFS时间返回ACK</p>
</li>
</ol>
<p>A.   CSMA&#x2F;CA协议的退避算法需要等待一个DIFS，而且要进入争用窗口，计算随机退避时间以便再次试图接入信道</p>
<p>B.   CSMA&#x2F;CA协议只有当检测到信道空闲且该数据帧是要发送的第一条数据帧才不使用退避算法，当（1）发送第一帧前检测到信道忙；（2）每次重传；（3）每次成功发送后再发送下一帧时都需要使用退避算法</p>
<p>C.  CSMA&#x2F;CD协议当发生冲突后会，收发端检测到冲突后会发送干扰信号，干扰信号需要<img src="/%5Cimages/clip_image030.gif" alt="img">时间在网络内传播，而退避算法是在检测到冲突后就开始执行</p>
<p>D.  以太网中可以发送数据后，还需要再等待96比特时间（最小帧间隔时间）</p>
<h2 id="CSMA-x2F-CA算法"><a href="#CSMA-x2F-CA算法" class="headerlink" title="CSMA&#x2F;CA算法"></a>CSMA&#x2F;CA算法</h2><p>I.    如果最初有数据要发送，且信道空闲，在等待DIFS后，就发送整个数据帧</p>
<p>II.   当检测到信道忙，站点执行CSMA&#x2F;CA退避算法，选取一个随机回退值。一旦检测到信道忙，退避计时器就保持不变；只要信道空闲，退避计时器就进行倒计时</p>
<p>III.  当退避计时器减到0时，站点发送整个帧并等待确认</p>
<p>IV.  发送站收到确认，说明发送帧被目的站正确接收。如果发送第二帧，就从步骤2开始</p>
<p>V.   若发送站没有收到ACK，必须重传该帧</p>
<ul>
<li>MAC帧不需要帧结束符（有IFS保障帧之间有间隙），但是以太网MAC帧，在数据链路层，帧既要加首部，也要加尾部</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>10BASE5</th>
<th>10BASE2</th>
<th>10BASE-T</th>
<th>10BASE-FL</th>
</tr>
</thead>
<tbody><tr>
<td>传输媒体</td>
<td>基带同轴电缆（粗缆）</td>
<td>基带同轴电缆（细缆）</td>
<td>非屏蔽双绞线</td>
<td>光线对（850nm）</td>
</tr>
<tr>
<td>编码</td>
<td>曼彻斯特编码</td>
<td>曼彻斯特编码</td>
<td>曼彻斯特编码</td>
<td>曼彻斯特编码</td>
</tr>
<tr>
<td>拓扑结构</td>
<td>总线形</td>
<td>总线形</td>
<td>星形</td>
<td>点对点</td>
</tr>
<tr>
<td>最大段长</td>
<td>500m</td>
<td>185m</td>
<td>100m</td>
<td>2000m</td>
</tr>
<tr>
<td>最多结点数目</td>
<td>100个</td>
<td>30个</td>
<td>2个</td>
<td>2个</td>
</tr>
<tr>
<td>使用协议</td>
<td>CSMA&#x2F;CD</td>
<td>CSMA&#x2F;CD</td>
<td>半双工方式下CSMA&#x2F;CD</td>
<td>半双工方式下CSMA&#x2F;CD</td>
</tr>
</tbody></table>
<p>A.   允许在1Gb&#x2F;s下<a href="https://baike.baidu.com/item/%E5%85%A8%E5%8F%8C%E5%B7%A5/310007">全双工</a>和<a href="https://baike.baidu.com/item/%E5%8D%8A%E5%8F%8C%E5%B7%A5/309852">半双工</a>两种方式工作</p>
<p>B.   100Base-T的设备线路传输速率为100Mbps</p>
<ul>
<li><p>如果同一局域网的两台设备具有相同的静态MAC地址，则在网络上这两个设备无法正确通信</p>
</li>
<li><p>p坚持CSMA协议适用于时隙信道</p>
</li>
<li><p>p坚持CSMA协议如果监听到信道忙会持续监听（推迟到下一个时隙再监听），直到信道空闲，并以p概率发送数据，1-p概念推迟到下一个时隙</p>
</li>
<li><p>快速以太网仍然使用CSMA&#x2F;CD协议，采用保持最短帧长不变，而将最大电缆长度减少到100m的方法，使以太网的数据传输速率提高至100Mb&#x2F;s</p>
</li>
<li><p>吉比特以太网支持流量控制机制，其中IEEE 802.3z采用光纤通道；IEEE 802.3ab采用4对UTP5类线</p>
</li>
<li><p>IEEE802.11 在MAC层使用CSMA&#x2F;CA协议</p>
</li>
<li><p>令牌环网在源站进行差错控制</p>
</li>
<li><p>广域网使用存储转发式的传输方式</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>PPP协议</th>
<th>HDLC协议</th>
</tr>
</thead>
<tbody><tr>
<td>面向字节（字节填充法）</td>
<td>面向比特</td>
</tr>
<tr>
<td>提供差错控制，不使用序号和确认机制</td>
<td>信息帧使用序号和确认机制</td>
</tr>
<tr>
<td>全双工通信、点对点、面向连接</td>
<td>全双工通信、点对点、面向连接</td>
</tr>
<tr>
<td>PPP帧比HDLC帧多一个2字节的协议字段（0x0021表示IP数据报）</td>
<td>信息帧传输数据及其捎带确认，监督帧流量控制和差错控制，无编号帧建立链路</td>
</tr>
</tbody></table>
<ul>
<li><p>局域网交换机实现的功能主要是在物理层与数据链路层</p>
</li>
<li><p>在本地通信量较大的局域网内主要使用交换机，以降低冲突域</p>
</li>
<li><p>交换机按MAC地址转发，可以实现多端口并行传输</p>
</li>
<li><p>以太网MAC协议提供的是无连接不可靠的协议（不对发送的数据帧进行编号，不要求对方发回ACK确认）</p>
</li>
<li><p>以太网使用曼彻斯特编码，总线形拓扑，</p>
</li>
<li><p>以太网交换机直通交换，在输入端口检测到一个数据帧时，检查帧首部，获取帧的目的地址，启动内部动态查找表转换为相应的输出端口，在输入端与输出端交叉处接通，把数据帧直通到相应的端口，实现交换功能。直通交换只检查帧的目的地址（6Ｂ），最短传输延迟为<img src="/%5Cimages/clip_image032.gif" alt="img"></p>
</li>
<li><p>交换机所连主机可以同时连通多个端口，使每对相互通信的主机像独占信道一样，进行无碰撞💥的数据传输</p>
</li>
<li><p>交换机所连主机能达到的带宽是每个端口能达到的带宽最大值，集线器所连接主机所能达到的带宽是端口带宽的1&#x2F;n（n为所连主机数）</p>
</li>
</ul>
<h1 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h1><ul>
<li><p>在路由器连接的异构网络中，物理层、数据链路层、网络层的协议可以不相同，而网络层以上的协议必须相同（特定路由器可以连接IPv4与IPv6网络）</p>
</li>
<li><p>路由器分有直接交付与间接交付；当发送站与目的站处于同一网段时，使用直接交付；反之使用间接交付</p>
</li>
<li><p>距离-向量路由协议中，慢收敛导致路由器接受了无效的路由信息最可能导致路由回路问题</p>
</li>
</ul>
<blockquote>
<p>路由环路的产生：</p>
<p>当A路由器一侧的X网络发生故障，则A路由器收到故障信息，并把X网络设置为不可达，等待更新周期来通知相邻的B路由器。但是，如果相邻的B路由器的更新周期先来了，则A路由器将从B路由器那学习了到达X网络的路由，就是错误路由，因为此时的X网络已经损坏，而A路由器却在自己的路由表内增加了一条经过B路由器到达X网络的路由。然后A路由器还会继续把该错误路由通告给B路由器，B路由器更新路由表，认为到达X网络须经过A路由，然后继续通知相邻的路由器，至此路由环路形成，A路由器认为到达X网络经过B路由器，而B则认为到达X网络进过A路由器。</p>
</blockquote>
<ul>
<li>IPv4数据报中首部长度单位4B，总长度单位1B，片偏移单位8B（IPv6的首部长度是8B的整数倍）</li>
</ul>
<blockquote>
<h2 id="TTL"><a href="#TTL" class="headerlink" title="TTL"></a>TTL</h2><p>TTL字段由IP数据包的发送者设置，在IP数据包从源到目的的整个转发路径上，每经过一个路由器，路由器都会修改这个TTL字段值，具体的做法是把该TTL的值减1，然后再将IP包转发出去。如果在IP包到达目的IP之前，TTL减少为0，路由器将会丢弃收到的TTL&#x3D;0的IP包并向IP包的发送者发送 ICMP time exceeded消息。</p>
</blockquote>
<ul>
<li><p>ICMP报文作为IP层数据报的数据，加上IP数据报的首部，组成IP数据报发送出去（主要供网络层设备使用），即ICMP报文封装在数据链路层帧中发送</p>
</li>
<li><p>NAT表项需要管理员添加，以便控制一个内网到外网的网络连接。如果发送分组的IP：端口对在NAT表项中找不到，服务器不会转发该分组</p>
</li>
<li><p>DCHP服务器使用主机的以太网地址（MAC地址）标识主机</p>
</li>
<li><p>位于不同子网的主机相互通信时，路由器在转发IP数据报时，重新封装硬件源MAC地址（本路由器）与目的MAC地址（下一条路由器）</p>
</li>
<li><p>处于不同网段的主机必须通过路由器才能进行通信</p>
</li>
<li><p>RIP中每个网络的子网掩码必须相同，RIP2支持CIDR</p>
</li>
<li><p>OSPF协议使用Hello分组来保持与其邻居的连接</p>
</li>
<li><p>BGP交换的可达性信息是到达某个网络所经过的路径</p>
</li>
<li><p>网络地址不同的说明网络不同，需要使用路由器进行连接</p>
</li>
<li><p>IP网关等同于IP路由器</p>
</li>
<li><p>在一个广域网内的所有节点事先知道该广域网能通过的最大分组，因此广域网没有必要进行分片。但当数据报进入某个网络后，MTU可能发生变化，此时可能需要分片。</p>
</li>
<li><p>如果一台主机有两个以太网卡，那么它可以同时连接两个不同的网络（网络号不能相同，否则会发生冲突），这样它需要两个IP地址</p>
</li>
<li><p>IPv6的通信量类字段区分不同的IPv6数据报的类别或优先级（0最低），0-7表示允许延迟，8-15表示高优先级</p>
</li>
<li><p>IPv6流标号字段，所有属于同一个流的数据报都具有同样的流标号</p>
</li>
<li><p>IP组播地址映射为MAC地址方法：将IP地址的后23位转换为十六进制（第24位取0）组成后24位MAC，前24位MAC地址使用MAC地址的组播 </p>
</li>
<li><p>在设计组播路由时，为了避免路由环路，构造组播转发树</p>
</li>
<li><p>一个D类地址标志一个组播组</p>
</li>
<li><p>在组播情况下，是适配器NIC而不是CPU决定是否接受一个帧</p>
</li>
<li><p>NIC接受每一个广播帧，然后交付操作系统，由CPU决定是否接收</p>
</li>
<li><p>OSPF协议规定Area0是主干区域，区域路由器是与不同区域相连的路由器</p>
</li>
<li><p>不同局域网的两台主机若想通信，只需将数据包发给路由器即可，由路由器处理其他操作。（不用主机发送ARP报文）</p>
</li>
</ul>
<h1 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a>传输层</h1><ul>
<li><p>TCP拥塞控制的慢启动算法中，发送端每收到一个确认段就将拥塞窗口加一；这样在经过一个RTT后拥塞窗口的大小会加倍（cwnd大小指数式增长）</p>
</li>
<li><p>TCP拥塞控制的拥塞避免算法中，每经过一轮RTT只增加一个cwnd（线性增加）</p>
</li>
<li><p>排序工作由传输层实现；重组工作由网络层实现</p>
</li>
</ul>
<h2 id="端口"><a href="#端口" class="headerlink" title="端口"></a>端口</h2><p>网络数据进入主机后，首先到达网卡，然后进入内核，由网络协议栈处理（使用socket）</p>
<p>每个进程在内核中都有一个表，保存该进程申请并占用的所有soket描述符。</p>
<p>socket：源IP+port，目的IP+port，建立起进程与端口间的联系。内核根据传输层数据报中的端口找到相应的进程实现进程间的通信</p>
<p>SOcket本质上是一种资源，理论上能够通过sendmsg将socket描述符传递到其他进程。同时，父子进程间，线程间也会进行socket共享。</p>
<ul>
<li><p>TCP，UDP分别拥有自己的端口号，它们互不干扰，可以共存于同一台主机</p>
</li>
<li><p>TCP协议规定HTTP服务器进程的端口号为80</p>
</li>
<li><p>TCP采用对报文段确认的确认机制</p>
</li>
<li><p>TCP将收到的报文段组成字节流交给上层</p>
</li>
<li><p>TCP将应用层交付的数据看作一串字节流</p>
</li>
<li><p>MSS是TCP报文的有效载荷长度</p>
</li>
<li><p>UDP不需要处理RTT</p>
</li>
<li><p>TCP、UDP报头都有目的端口号、源端口号、校验号</p>
</li>
<li><p>TCP第三次握手如果不携带数据则不消耗序号</p>
</li>
<li><p>TCP每次收到比期望序号大的失序报文就发送一个冗余ACK</p>
</li>
<li><p>传输层分用：接收方发传输层剥去报文首部后，能把这些数据正确交付到目的进程（目的端口号是在终点交付报文时使用，源端口号是需要对方回信时使用）</p>
</li>
</ul>
<h1 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h1><table>
<thead>
<tr>
<th>DNS</th>
<th>FTP</th>
<th>电子邮件📧</th>
<th>WWW</th>
</tr>
</thead>
<tbody><tr>
<td>UDP（53端口）</td>
<td>TCP（控制连接21端口、数据连接20端口）</td>
<td>TCP（SMTP  25端口、POP3 110端口、IMAP）</td>
<td>TCP（HTTP  80端口）</td>
</tr>
<tr>
<td>递归查询、迭代查询</td>
<td>主动模式、被动模式</td>
<td></td>
<td>持久化连接、流水线</td>
</tr>
<tr>
<td>根域名服务器、顶级域名服务器、授权域名服务器、本地域名服务器</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<ul>
<li><p>客户机是面向用户的，服务器是面向任务的</p>
</li>
<li><p>多个不同的域名可以共用一个IP地址，访问一台服务器</p>
</li>
<li><p>匿名FTP访问通常使用anonymous作为用户名，该用户ID的密码可以是任何字符串</p>
</li>
</ul>
<blockquote>
<h2 id="FTP工作"><a href="#FTP工作" class="headerlink" title="FTP工作"></a>FTP工作</h2><p>FTP服务器运行一个主进程，负责接收新的请求；以及若干个从属进程，负责处理单个请求。</p>
<p>服务器主进程接收新的请求后（第一次登陆请求，第二次读取文件请求），服务器使用20号端口创建数据传输进程和TCP数据连接到客户端发送的接收文件的随机端口（实际的文件传输连接）。</p>
<p>数据传输进程实际完成对文件的传输。传输完毕后关闭“数据传送连接”，并结束运行</p>
<p>FTP客户端发送的控制连接发送给服务器端控制进程（建立TCP链接到服务器的21端口，发送登录账号与密码），并在整个会话期间一直保持打开。</p>
<p>收到服务器返回的登陆成功信息后，客户端打开一个随机端口，并将该端口发送给服务器，从这个端口接收文件。</p>
</blockquote>
<ul>
<li><p>POP3协议在传输层使用明文传输密码，并不对密码进行加密🔐</p>
</li>
<li><p>SMTP协议用于用户代理向邮件服务器发送邮件、邮件服务器间发送邮件（不支持邮件服务器向用户代理发送邮件）</p>
</li>
<li><p>POP3协议用于用户代理从邮件服务器读取邮件</p>
</li>
<li><p>SMTP协议只支持7比特的ASCII码内容</p>
</li>
<li><p>MIME邮件支持非ASCII码的编码规则（图片、视频等）</p>
</li>
<li><p>请求一个万维网文档所需的时间&#x3D;该文档传输时间+两倍的RTT（一次RTT建立TCP连接，另一个RTT用于请求文档和接收文档，即主机的第三次握手携带请求信息）</p>
</li>
<li><p>浏览器只会在先前访问过的网站上留下Cookie</p>
</li>
<li><p>Cookie是服务器产生的</p>
</li>
<li><p>使用浏览器访问WWW服务器的第一步是DNS解析，获取IP地址</p>
</li>
</ul>
<p>客户端的 www浏览器获得 www服务器的主页并显示在客户端的屏幕上的过程如下(假设访问天勤论坛，域名为 <a href="http://www.csbji.com)：">www.csbji.com)：</a></p>
<ol>
<li><p>WWW 浏览器直接使用名称 <a href="http://www.csbiji.com/">www.csbiji.com</a> 访问该www 服务器，首先需要完成对该服务器的域名解析，并最终获得天勤论坛服务器对应的IP 地址 116.255.187.175。</p>
</li>
<li><p>www 浏览器将通过TCP 协议与服务器建立一条TCP 连接。当 TCP 连接建立之后，wwW 浏览器就向 www 服务器发送要求获取其主页的 HTTP请求。</p>
</li>
<li><p>www 服务器在接收到浏览器的 HTTP 请求之后，将构建所请求的 web 页面必需的各种信息，并将信息通过 Internet 传送给客户端的浏览器。</p>
</li>
<li><p>浏览器将收到的信息进行解释，然后将web页面显示在用户的屏幕上。</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>408</tag>
      </tags>
  </entry>
</search>
